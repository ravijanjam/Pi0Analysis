2a3
> 
4a6
> #include "FWCore/Framework/interface/EDAnalyzer.h"
6d7
< #include "FWCore/Framework/interface/Event.h"
8c9
< #include "FWCore/ParameterSet/interface/ParameterSet.h"   
---
> #include "FWCore/ParameterSet/interface/ParameterSet.h"
20d20
< #include "CommonTools/UtilAlgos/interface/TFileService.h"
21a22,25
> #include "DataFormats/Candidate/interface/Candidate.h"
> #include "DataFormats/ParticleFlowCandidate/interface/PFCandidate.h"
> #include "DataFormats/ParticleFlowCandidate/interface/PFCandidateFwd.h"
> #include "CommonTools/UtilAlgos/interface/TFileService.h"
28c32
< #include "Pi0Analysis/EcalFlowNtp/src/EcalFlowNtpCharlie.h"
---
> #include "Pi0Analysis/EcalFlowNtp/src/EcalFlowNtpMonika.h"
33a38,40
> //#include "DataFormats/HeavyIonEvent/interface/EvtPlane.h"
> //#include "CondFormats/DataRecord/interface/RPFlatParamsRcd.h"
> //#include "CondFormats/RPFlatParams/interface/RPFlatParams.h"
36d42
< #include "DataFormats/EcalRecHit/interface/EcalRecHitCollections.h"
38c44
< #include "DataFormats/DetId/interface/DetId.h"  
---
> #include "DataFormats/DetId/interface/DetId.h"
42d47
< #include "FWCore/Framework/interface/EventSetup.h"
49c54,55
< 
---
> /// EgammaCoreTools
> //#include "RecoEcal/EgammaCoreTools/interface/PositionCalc.h"
50a57,62
> #include "RecoEcal/EgammaCoreTools/interface/EcalTools.h"
> #include "Geometry/Records/interface/CaloGeometryRecord.h"
> #include "Geometry/CaloGeometry/interface/CaloGeometry.h"
> #include "Geometry/CaloGeometry/interface/CaloSubdetectorGeometry.h"
> 
> 
55c67
< /// Monte Carlo
---
> /// montecarlo
63,68d74
< #include "SimDataFormats/TrackingAnalysis/interface/TrackingParticle.h"
< #include "SimDataFormats/TrackingAnalysis/interface/TrackingParticleFwd.h"
< #include "SimDataFormats/TrackingAnalysis/interface/TrackingVertex.h"
< #include "SimDataFormats/TrackingAnalysis/interface/TrackingVertexContainer.h"
< 
< #include <DataFormats/Math/interface/deltaPhi.h>
70c76
< const double TWOPI = M_PI + M_PI; // change from #define value of 6.283185308
---
> #define TWOPI 6.283185308
75a82
> 
83,85d89
< typedef edm::RefVector< std::vector<TrackingParticle> > TrackingParticleContainer;
< typedef std::vector<TrackingParticle>                   TrackingParticleCollection;
< 
89,147d92
< const bool mergedTrackTruthDebug = false;
< const bool trackEcalMatchDebug = false;
< const bool simTrackDebug = false;
< 
< const double rPrimaryCut = 0.1;
< const double zPrimaryCut = 0.1;
< const double ptPrimaryCut = 0.01;
< 
< const double etaCutForMerge = 1.60;  // used to reduce the size of the output tree
< const double ptCutForMerge = 0.30;   // used to reduce the size of the output tree
< 
< const bool printPairContributors = false;
< 
< //
< //
< // PDG codes
< //   22 is a gamma
< //   11 or -11 is a positron or an electron
< //  111 is a pi0
< //  130 is a K0-long
< //  211 or -211 is a pi+ or a pi-
< //  213 is rho(770)+, -213 is rho(770)-
< //  221 is an eta (548 MeV)
< //  223 is an omega (782 MeV, pi+pi-pi0 at 89%, pi0-g at 8%)
< //  310 is a K0-short
< //  311 is a K0
< //  313 is a K0*(892), should be neutral?
< //  321 is a K+
< //  323 is a K0*(892)+, should be charged
< //  331 is an eta-prime
< //  421 is a D0
< //  433 is a D*s+
< //  2112 is a neutron
< //  2212 is a proton
< //  3122 is a Lambda0
< //  3212 is a Sigma0 (1385 MeV, decays to Lambda + pi0, or Sigma + pi)
< //
< 
< //
< // Code for reco track matching with ECAL, originally developed in September 2010
< //
< const double minimumTrackPtForMatch = 1.5;             // GeV/c, only tracks with have recconstructed pT above this value are considered for ECAL matching
< const double phiDeflectionPerInversePt = 0.789;        // radians/(GeV/c)^-1, azimuthal deflection angle per inverse pT in CMS magnetic field, positive for electrons
< const int specialEvent = 0;                            // printing for selected event
< const bool matchOnlyHighPurity = false;                // switch to restrict track matching to only high purity tracks
< 
< const bool useTrackProjectionAzimuthalCorrection = true;
< const double trackProjectionAzimuthalCorrectionFactor = 0.0055; // radians per unit of dxy
< const bool useTrackProjectionThetaCorrection = true;
< const double trackProjectionThetaCorrectionFactor = -0.008; // radians per unit of dz
< 
< const double zEcalCut = 60.0;  // Delta-Theta correction grows linearly as a function of zEcal until this Z value, reaching a saturation value
< const bool usezEcalCorrection = true;
< const double zEcalSaturationValue = 0.01;
< const double zEcalCorrectionFactor = zEcalSaturationValue/zEcalCut;
< 
< //
< // Constructor
< //
150c95,97
<   clustEnrCut(0.3),
---
>   clustEnrCut(0.4),
>   clustS49Cut(0.74),
>   clustPtCut(0.0),
152c99
<   clustS25Cut(1.0),
---
>   clustS25Cut(0.20),
161c108
<   maximumPi0MassForHistogram(0.80),
---
>   maximumPi0MassForHistogram(0.30),
163,164c110,111
<   lowPtCut(0.7),
<   highPtCut(8.0),
---
>   //  lowPtCut(1.0),
>   // highPtCut(12.0),
172,173c119,120
<   etaMin_trg_(-1.5),
<   etaMax_trg_(1.5),
---
>   etaMin_trg_(-2.5),
>   etaMax_trg_(2.5),
176,177c123,124
<   ptMin_trg_(0.3),
<   ptMax_trg_(8.0),
---
>   ptMin_trg_(1.0),
>   ptMax_trg_(3.0),
179a127
>   _pi(3.1415927),
181,183c129
<   eventCounter_(0),
<   countPairContributors_(0)
< 
---
>   eventCounter_(0)
185c131
< 	
---
>   
188a135
>   particleFlow_ = ps.getParameter<edm::InputTag>("pfCandidatesTag");
191,196d137
< 
<   clustS49Cut_ =  ps.getParameter<double>("clustS49Cut");  // introduced into python file as of April 30, 2014
< 
<   //
<   // Parameters from Monika's EcalFlowNtp code
<   //
202a144
>   doEffCorrections_ = ps.getParameter<bool>("doEffCorrections");
205d146
< 
210,216c151,156
< 
<   cout << "\n Cuts used for pair correlations:";
<   cout << "\n Trigger (pi0) particle from " << ptMin_trg_ << " to " << ptMax_trg_ << " GeV/c";
<   cout << "\n Associated charged particle from " << ptMin_ass_ << " to " << ptMax_ass_ << " GeV/c";
<   cout << endl;
< 
<   doSwissThreshold_ = ps.getParameter<bool>("doSwissThreshold");
---
>   cutByLeadingTrackPt_ = ps.getParameter<bool>("cutByLeadingTrackPt");
>   leadingTrackPtMin_ = ps.getParameter<double>("leadingTrackPtMin");
>   leadingTrackPtMax_ = ps.getParameter<double>("leadingTrackPtMax");
>   cutByLeadingPhotonPt_ = ps.getParameter<bool>("cutByLeadingPhotonPt");
>   leadingPhotonPtMin_ = ps.getParameter<double>("leadingPhotonPtMin");
>   leadingPhotonPtMax_ = ps.getParameter<double>("leadingPhotonPtMax");
218,260c158,160
<   if(doSwissThreshold_) {
<     cout << "\n Swiss cross cut threshold enabled at a value " << swissThreshold_ << endl;
<   }
< 
<   doOneDimensionTimeCut_ = ps.getParameter<bool>("doOneDimensionTimeCut");
<   oneDimensionTimeCut_ = ps.getParameter<double>("oneDimensionTimeCut");
<   if(doOneDimensionTimeCut_) {
<     cout << "\n One dimensional (fixed window) time cut enabled at a value " << oneDimensionTimeCut_ << endl;
<   }
< 
<   doTwoDimensionTimeCut_ = ps.getParameter<bool>("doTwoDimensionTimeCut");
<   twoDimensionTimeCutFactor_ = ps.getParameter<double>("twoDimensionTimeCutFactor");
<   if(doOneDimensionTimeCut_ && doTwoDimensionTimeCut_) {
<     cerr <<"\n\n Input parameters conflict: asking for both a one-dimensional and a two-dimensional time cut" << endl << endl;
<     return;
<   }
<   if(doTwoDimensionTimeCut_) {
<     cout << "\n Two dimensional (Energy vs time) cut enabled at a value " << twoDimensionTimeCutFactor_ << endl;
<   }
< 
<   doWeightedTimeCut_ = ps.getParameter<bool>("doWeightedTimeCut");
<   if(doWeightedTimeCut_) {
<     if(!doTwoDimensionTimeCut_) {
<       cerr <<"\n\n Input parameters conflict: asking for a weighted time cut but not asking for a two-dimensional time cut" << endl << endl;
<     }
<     else {
<       cout << "\n The two dimensional weighted time cut (weighted time - seed time) is enabled" << endl;
<     }
<   }
< 
<   lowInvMassCut_ = ps.getParameter<double>("lowInvMassCut");
<   highInvMassCut_ = ps.getParameter<double>("highInvMassCut");
< 
<   cout << "\n The low invariant mass cut is " << lowInvMassCut_ << " GeV/c^2";
<   cout << "\n The high invariant mass cut is " << highInvMassCut_ << " GeV/c^2" << endl;
< 
<   if(lowInvMassCut_ >= highInvMassCut_) {
<     cerr << "\n Invalid values for the invariant mass cuts" << endl;
<     return;
<   } // safety check
< 
<   cout << "\n The cluster S4/S9 cut is " << clustS49Cut_ << endl;
< 
---
>   timeThreshold_ = ps.getParameter<double>("timeThreshold");
>   avoidIeta85_ = ps.getParameter<double>("avoidIeta85");
>   
264c164
< 	
---
>   
269c169
< 	
---
>   
273c173
< 	
---
>   
276c176,177
< 	
---
>   //maximumNumberAcceptedCluster = 1000;
>   
279c180
< 	
---
>   
284c185
< 	
---
>   
293,318c194
<   
<   //
<   // 99 MC events have 538 reco tracks above 1.5 GeV/c and an |eta| < 1.49
<   //                   150 of these tracks have at least one cluster match (~28%)
<   //                   19 of these tracks have two cluster matches (no track has 3 or more matches)
<   //
<   // 99 MC events have 122 reco tracks above 2.5 GeV/c and an |eta| < 1.49
<   //                   49 of these tracks have at least one cluster match (~40%)
<   //                   9 of these tracks have two cluster matches (no track has 3 or more matches)
<   //
<   // 500 MC events have 224 reco tracks above 2.5 GeV/c and an |eta| < 1.49
<   //                    97 of these tracks have at least one cluster match (~40%)
<   //                    15 of these tracks have two cluster matches (no track has 3 or more matches)
<   //
< 	
<   goodAngleMatch_ = ps.getParameter<double> ("goodAngleMatch");
<   goodPhiMatch_ = ps.getParameter<double> ("goodPhiMatch");
<   goodThetaMatch_ = ps.getParameter<double> ("goodThetaMatch");
< 	
<   cout << "\n The goodAngleMatch opening angle criterion for reco track-cluster matching is " << goodAngleMatch_ << " radians" << endl;
<   cout << "\n The goodPhiMatch residual angle criterion for reco track-cluster matching is " << goodPhiMatch_ << " radians" << endl;
<   cout << "\n The goodThetaMatch residual angle criterion for reco track-cluster matching is " << goodThetaMatch_ << " radians" << endl;
< 	
<   //
<   // Control parameter to do energy re-calibration based on number of crystals in a cluster
<   // Energy re-calibration parameterizations were derived from pPb HIJING events
---
> 
320c196
< 	
---
> 
325c201
< 	
---
> 
330,331c206,208
<   lowCrystalLimit_ = ps.getParameter<int> ("lowCrystalLimit");    // used only if useClusterCrystalLimit is true
<   highCrystalLimit_ = ps.getParameter<int> ("highCrystalLimit");  // used only if useClusterCrystalLimit is true
---
>   lowCrystalLimit_ = ps.getParameter<int> ("lowCrystalLimit");    // used only if useClusterCrystalLimit is true     
>   highCrystalLimit_ = ps.getParameter<int> ("highCrystalLimit");  // used only if useClusterCrystalLimit is true       
> 
333c210
<     if(!useClusterCrystalLimitLowPtOnly_) {
---
>     if(useClusterCrystalLimitLowPtOnly_) {
341,378c218,246
<   } // check on useClusterCrystalLimit
< 	
<   //
<   // Control parameter to suppress clusters with a charged particle tracking match
<   //
<   suppressTrackMatchedClusters_ =  ps.getParameter<bool> ("suppressTrackMatchedClusters");
< 	
<   if(suppressTrackMatchedClusters_)
<     cout << "\n Cluster with a charged particle tracking match will not be used" << endl;
<   else
<     cout << "\n Cluster with charged particle tracking matches are accepted" << endl;
< 	
<   makeOutputTree_ =  ps.getParameter<bool> ("makeOutputTree");
<   if(makeOutputTree_)
<     cout << "\n An output tree will be generated according to the xxxStore parameters" << endl;
<   else
<     cout << "\n No output tree will be generated" << endl;
< 	
<   // Control parameters to limit the size of the output hTree
<   recoTrackStore_ = ps.getParameter<bool> ("recoTrackStore");
<   clusterStore_ = ps.getParameter<bool> ("clusterStore");
<   clusterRecoTrackStore_ = ps.getParameter<bool> ("clusterRecoTrackStore");
<   crystalStore_ = ps.getParameter<bool> ("crystalStore");
<   mcParticleStore_ = ps.getParameter<bool> ("mcParticleStore");
<   simTrackStore_ = ps.getParameter<bool> ("simTrackStore");
<   simSlimTrackStore_ = ps.getParameter<bool> ("simSlimTrackStore");
<   mergedTrackTruthStore_ = ps.getParameter<bool> ("mergedTrackTruthStore");
<   mergedTrackTruthPhotonOnly_ = ps.getParameter<bool> ("mergedTrackTruthPhotonOnly");
<   genParticleStore_ = ps.getParameter<bool> ("genParticleStore");
<   mesonStore_ = ps.getParameter<bool> ("mesonStore");  
<   photonStore_ = ps.getParameter<bool> ("photonStore");  
<   chmesonStore_ = ps.getParameter<bool> ("chmesonStore");
<   pairCorrTracksStore_ = ps.getParameter<bool> ("pairCorrTracksStore");
< 	
<   minimumHITracksCut_ = ps.getParameter<int> ("minimumHITracksCut");
<   maximumHITracksCut_ = ps.getParameter<int> ("maximumHITracksCut");
< 	
<   // Initialization of track histograms [Monika Sharma]                                                                 
---
>   } // check on useClusterCrystalLimit   
> 
>   doOneDimensionTimeCut_ = ps.getParameter<bool>("doOneDimensionTimeCut");
>   oneDimensionTimeCut_ = ps.getParameter<double>("oneDimensionTimeCut");
>   if(doOneDimensionTimeCut_) {
>     cout << "\n One dimensional (fixed window) time cut enabled at a value " << oneDimensionTimeCut_;
>       }
> 
>   doTwoDimensionTimeCut_ = ps.getParameter<bool>("doTwoDimensionTimeCut");
>   twoDimensionTimeCutFactor_ = ps.getParameter<double>("twoDimensionTimeCutFactor");
>   if(doOneDimensionTimeCut_ && doTwoDimensionTimeCut_) {
>     cerr <<"\n\n Input parameters conflict: asking for both a one-dimensional and a two-dimensional energy cut to be true";
>     return; }
> 
>   if(doTwoDimensionTimeCut_) {
>     cout << "\n Two dimensional (Energy vs time) cut enabled at a value " << twoDimensionTimeCutFactor_;
>       }
> 
>   doWeightedTimeCut_ = ps.getParameter<bool>("doWeightedTimeCut");
>   if(doWeightedTimeCut_) {
>     if(!doTwoDimensionTimeCut_) {
>       cerr <<"\n\n Input parameters conflict: asking for a weighted time cut but not asking for ...";
>     }
>     else {
>       cout << "\n The two dimensional weighted time cut (weighted time - seed time) is enabled";
> 	}
>   }
> 
>   // Initilization of track histograms [Monika Sharma]                                                                       
381a250
>   //dbe_ = Service<DQMStore>().operator->();
386c255
< 	
---
>   
405c274
< 	
---
>   
414c283
<   // do anything here that needs to be done at destruction time
---
>   // do anything here that needs to be done at desctruction time
419c288
< // ------------ method called to analyze each event  ------------
---
> // ------------ method called to for each event  ------------
431c300
< 	
---
>   
435c304
< 	
---
>   
441,446c310,313
< 	
<   vector<TVector3> pVect_trg;  // these are for the reconstructed pi0
<   vector<TVector3> pVect_ass;  // these are for the charged particle tracks
< 
<   vector<TVector3> pGenVect_trg;  // these are for the generated pi0
<   vector<TVector3> pGenVect_ass;  // these are for the generated charged particles
---
>   
>   vector<TVector3> pVect_trg;
>   vector<TVector3> pVect_ass;
>   
451d317
<   edm::Handle<EcalRecHitCollection> rhEBeta;
454d319
<   iEvent.getByLabel(productMonitoredEBeta_, rhEBeta);
457a323
>   //  const CaloSubdetectorGeometry *geometryEE_p;
459a326
>   //  const CaloSubdetectorTopology *topology_ee;
467c334
< 
---
>   
471c338
< 	
---
>   
474c341
< 	
---
>   
482a350,351
>   //  const CaloGeometry* caloGeom = geoHandle.product();
> 
483a353
>   //  geometryEE_p = geoHandle->getSubdetectorGeometry(DetId::Ecal,EcalEndcap);
486c356,360
< 	
---
>   // topology_ee = theCaloTopology->getSubdetectorTopology(DetId::Ecal,EcalEndcap);
>   
>   // CaloSubdetectorTopology *topology_es=0;
>   // if (geometryES_p) topology_es  = new EcalPreshowerTopology(geoHandle);
>   
493,497c367
<   nMesonSize = 0;
<   nPhotonSize = 0;
<   nChMesonSize = 0;
< 	
<   if (rhEBpi0.isValid() && (rhEBpi0->size() > 0)){
---
>   
506c376
<     if(nHITracks > maxTracksPerJob) {  // should check what is the value of this maximum (June 24)
---
>     if(nHITracks > maxTracksPerJob) {
511,519c381
< 		
<     nTracksSize = nHITracks;
< 		
<     if(nTracksSize < minimumHITracksCut_ || nTracksSize > maximumHITracksCut_)
<       return;
< 		
<     if(nTracksSize < 1)
<       nTracksSize = 1;
< 		
---
>     
521c383
<     // sort the vertices by number of tracks in descending order
---
>     // sort the vertcies by number of tracks in descending order
524c386
< 		
---
>     
527d388
< 		
530d390
< 		
532c392
< 		
---
>     
553c413
<         if( leadingTrackPt < leadingTrackPtMin_ ) return;
---
> 	if( leadingTrackPt < leadingTrackPtMin_ ) return;
556a417,435
> 
>     ////////////// Particle Flow Objects ////////////////////
>     edm::Handle<reco::PFCandidateCollection> pfCandidates;   
>     iEvent.getByLabel(particleFlow_, pfCandidates);
> 
>     for( unsigned ic1=0; ic1<pfCandidates->size(); ic1++ ) {
> 
>       const reco::PFCandidate& cand = (*pfCandidates)[ic1];
>      
>       if(cand.particleId() != PFCandidate::gamma) continue;
>       float _pfpt = cand.pt();
>       if(_pfpt < 0.4) continue;
>       if(fabs(cand.eta()) > 1.5) continue;
> 
>       PFPhotonPt->Fill(_pfpt);
>       }
> 
>     /////////////////////////////////////////////////////////
> 
565c444
< 		
---
>     
567,577c446,453
<     // for(unsigned int i =1; i<vsorted.size(); i++)
<     // {
<     //
<     // These variables are not used?
<     //
<     // double dz = fabs( vsorted[i].z() - vsorted[0].z() );
<     // double dx = fabs( vsorted[i].x() - vsorted[0].x() );
<     // double dy = fabs( vsorted[i].y() - vsorted[0].y() );
<     // double dxy  = sqrt ( dx*dx + dy*dy );
<     // }
< 		
---
>     /*    for(unsigned int i =1; i<vsorted.size(); i++)
>       {
> 	double dz = fabs( vsorted[i].z() - vsorted[0].z() );
> 	double dx = fabs( vsorted[i].x() - vsorted[0].x() );
> 	double dy = fabs( vsorted[i].y() - vsorted[0].y() );
> 	double dxy  = sqrt ( dx*dx + dy*dy );
> 	}*/
>     
580d455
< 		
583,585d457
<     xPrimaryVertex = -999.0;
<     yPrimaryVertex = -999.0;
<     zPrimaryVertex = -999.0;
592,595d463
< 			
< 	xPrimaryVertex = (vsorted.begin()->position()).X();
< 	yPrimaryVertex = (vsorted.begin()->position()).Y();
< 	zPrimaryVertex = (vsorted.begin()->position()).Z();
597,605c465,466
< 		
<     rPrimaryVertex = sqrt(xPrimaryVertex*xPrimaryVertex + yPrimaryVertex*yPrimaryVertex);
< 		
<     int countAllTracks = 0;
< 		
<     for( const auto & track : *tracks ) //de-referencing the pointer "tracks" to track and auto will automatically know the type of tracks.
<       //
<       // This is a new way of looping over the tracks. It is guaranteed to run over all the tracks. 
<       //
---
>     
>     for( const auto & track : *tracks ) //de-referencing the pointer "tracks" to track and auto will automatically know the type of tracks. This is a new way of looping over the tracks. It is guaranteed to run over all the tracks. 
612,619c473,475
< 			
< 	recoPurityTrack[countAllTracks] = 1;  // default that the track is high purity
< 	countAllTracks++;                                 // increment the tracks counter
< 	if( !TrackQualityCuts(track, vsorted[0]) ) {
< 	  recoPurityTrack[countAllTracks - 1] = 0; // above track was actually not high purity, must reset it
< 	  continue;
< 	}
< 			
---
> 	
> 	if( !TrackQualityCuts(track, vsorted[0])) continue;
> 	
621c477
< 			
---
> 	
625c481
< 			
---
> 	
627c483
< 			
---
> 	
629c485
< 		
---
>     
631c487
< 		
---
>     
634,665c490,519
<     nHighPurityTracks = tHighPurityTracks_;
< 		
<     int nPairTracks = 0;
<     for( const auto & track : *tracks) {
<       if( !TrackQualityCuts(track, vsorted[0])) continue;
<       
<       TVector3 pvector;
<       pvector.SetPtEtaPhi(track.pt(),track.eta(),track.phi());
<       
<       if(track.eta()<=etaMax_ass_ && track.eta()>=etaMin_ass_
< 	 && track.pt()<=ptMax_ass_ && track.pt()>=ptMin_ass_) {
< 	pVect_ass.push_back(pvector); // store the three charged particle kinematic variables
< 
< 	tPt_->Fill(track.pt());
< 	tEta_->Fill(track.eta());
< 	tPhi_->Fill(track.phi());
< 
< 	if(pairCorrTracksStore_) {
< 	  pairTrack[nPairTracks] = nPairTracks;
< 	  recoPairPtTrack[nPairTracks] = track.pt();
< 	  recoPairEtaTrack[nPairTracks] = track.eta();
< 	  recoPairPhiTrack[nPairTracks] = track.phi();
< 	  nPairTracks++;
< 	} // storing partial reco track information for the pair correlations analysis
< 
<       } // check kinematics of the associated charged particles
<       
<     } // loop over tracks
<     nPairTracksSize = nPairTracks;
<     if(pairCorrTracksStore_) {
<       cout << "\n nPairTracksSize = " << nPairTracksSize << endl;
<     }
---
>     
>     for( const auto & track : *tracks)
>       {
> 	if( !TrackQualityCuts(track, vsorted[0])) continue;
> 	
> 	TVector3 pvector;
> 	pvector.SetPtEtaPhi(track.pt(),track.eta(),track.phi());
> 	
> 	if(track.eta()<=etaMax_ass_ && track.eta()>=etaMin_ass_
> 	   && track.pt()<=ptMax_ass_ && track.pt()>=ptMin_ass_)
> 	  {
> 	    pVect_ass.push_back(pvector);
> 	    tPt_->Fill(track.pt());
> 	    tEta_->Fill(track.eta());
> 	    tPhi_->Fill(track.phi());
> 	  }
> 	
> 	if(diHadronCorrelations_) {
> 	  TVector3 pvector1;
> 	  pvector1.SetPtEtaPhi(track.pt(),track.eta(),track.phi());
> 	  
> 	  if(track.eta()<=etaMax_trg_ && track.eta()>=etaMin_trg_
> 	     && track.pt()<=ptMax_trg_ && track.pt()>=ptMin_trg_)
> 	    {
> 	      pVect_trg.push_back(pvector);
> 	      tPt_trg_->Fill(track.pt());
> 	      tEta_trg_->Fill(track.eta());
> 	      tPhi_trg_->Fill(track.phi());
> 	    }
> 	}
667,712d520
<     bool recoPtTrackAboveMinimum = false;
<     int kRecoTrackAbovePtMinimum = 0;
< 		
<     unsigned int kTrack = 0;
<     unsigned int countRecoTrackPtAboveMinimum = 0;
< 		
<     for( const auto & track : *tracks ){ // de-referencing the pointer "tracks" to track and auto will automatically know the type of tracks.
< 			
<       double track_eta = track.eta();
<       double track_phi = track.phi();
<       double track_pt  = track.pt();
<       double dxy = track.dxy(vtxPoint);
<       double dz = track.dz(vtxPoint);
<       double dxysigma = sqrt(track.d0Error()*track.d0Error()+vxErr*vyErr);
<       double dzsigma = sqrt(track.dzError()*track.dzError()+vzErr*vzErr);
< 			
<       if(!recoPtTrackAboveMinimum && track_pt >= minimumTrackPtForMatch &&
< 	 (!matchOnlyHighPurity || (matchOnlyHighPurity && recoPurityTrack[kTrack]))) {
< 	recoPtTrackAboveMinimum = true;
< 	kRecoTrackAbovePtMinimum = kTrack; // the first track in the collection which has a pT >= minimumTrackPtForMatch
<       }
<       if(recoPtTrackAboveMinimum)
< 	countRecoTrackPtAboveMinimum++;
<       int qCharge = track.charge();
<       
<       recoEcalTrack[kTrack] = -999;   // default value for no match
<       recoNMatchTrack[kTrack] = 0;    // counts the number of good matches for this track
<       recoChargeTrack[kTrack] = qCharge;
< 			
<       if(qCharge < 0)
< 	recoPhiDTrack[kTrack] = track_phi + phiDeflectionPerInversePt/track_pt;
<       else
< 	recoPhiDTrack[kTrack] = track_phi - phiDeflectionPerInversePt/track_pt;
< 			
<       if(useTrackProjectionAzimuthalCorrection) {
< 	recoPhiDTrack[kTrack] += trackProjectionAzimuthalCorrectionFactor*dxy;  // projection correction factor derived from simulation studies
<       }
< 			
<       mTrack[kTrack] = kTrack;
<       recoPtTrack[kTrack] = track_pt;
<       recoEtaTrack[kTrack] = track_eta;
<       float track_theta = 2.0*atan(exp(-track_eta));
<       recoThetaTrack[kTrack] = track_theta;
< 			
<       if(useTrackProjectionThetaCorrection) {
< 	recoThetaTrack[kTrack] += trackProjectionThetaCorrectionFactor*dz;  // projection correction factor derived from simulation studies
714,730c522,523
< 			
<       recoPhiTrack[kTrack] = track_phi;
<       recoVxTrack[kTrack] = track.vx();
<       recoVyTrack[kTrack] = track.vy();
<       recoVzTrack[kTrack] = track.vz();
<       recoDxyTrack[kTrack] = dxy;
<       recoDzTrack[kTrack] = dz;
<       recoSdxyTrack[kTrack] = dxysigma;
<       recoSdzTrack[kTrack] = dzsigma;
<       recoOxTrack[kTrack] = track.outerX();
<       recoOyTrack[kTrack] = track.outerY();
<       recoOzTrack[kTrack] = track.outerZ();
<       recoOuterPtTrack[kTrack] = track.outerPt();
<       kTrack++;
<     } // loop over found tracks
< 		
< 		
---
>     
>     
734c527
< 		
---
>     
739c532
< 			
---
>       
747c540
< 		
---
>     
753c546,547
<     /////////////////// End new addition for Et of HF ///////////////
---
>     /////////////////////////////////////////////////////////
> 
755d548
< 		
766c559
< 		
---
>     
770,799d562
< 		
<     for(itb=rhEBpi0->begin(); itb!=rhEBpi0->end(); ++itb){
< 
<       double energy = itb->energy();
< 
<       // double  swissCrx = EcalTools::swissCross  (itb->id(), *hitCollection_p, 0., avoidIeta85_);
<       // SwissCrossCut->Fill(swissCrx);
< 
<       if( energy > seleXtalMinEnergy_) {
< 	TimingBefore->Fill(itb->time());
< 	if(energy < 5.0) {
< 	  TimingBeforeEvsT->Fill(itb->time(), energy);
< 	}
< 	if(abs(itb->time()) <= oneDimensionTimeCut_)
< 	  TimingAfter->Fill(itb->time());
<       }
< 
<       /*
<       //
<       // One or two dimensional time cuts are done at the cluster level, below
<       //
<       if(doOneDimensionTimeCut_) {
<       if(oneDimensionTimeCut_ < 0) {
<       if(abs(itb->time()) < -oneDimensionTimeCut_) continue;
<       } // reverse cut
<       if(doOneDimensionTimeCut_ > 0) {
<       if(abs(itb->time()) > oneDimensionTimeCut_) continue;
<       } // normal cut
<       }
<       */
801,803c564
< 		
<       EBDetId id(itb->id());
<       if( energy < seleXtalMinEnergy_) continue; 
---
>     if (rhEBpi0.isValid() && (rhEBpi0->size() > 0)){
805,809c566,595
<       EBDetId det = itb->id();
< 			
<       detIdEBRecHits.push_back(det);
<       EBRecHits.push_back(*itb);	  
<       if ( energy > clusSeedThr_ ) seeds.push_back(*itb);
---
>       //      double rhEt;
>       for(itb=rhEBpi0->begin(); itb!=rhEBpi0->end(); ++itb){
> 	
> 	////////////// Applying the swiss-cross and timing cuts/////
> 	//      const GlobalPoint &position = caloGeom->getPosition(itb->id());
> 	//      rhEt = itb->energy()/cosh(position.eta()); // Not using at the moment 
> 	double  swissCrx = EcalTools::swissCross  (itb->id(), *hitCollection_p, 0., avoidIeta85_);
> 	SwissCrossCut->Fill(swissCrx);
> 	Timing->Fill(abs(itb->time()));
> 	
> 	//	if(    (swissCrx > swissThreshold_)     ||     ( abs(itb->time()) > timeThreshold_) ) continue;
> 	//	if( swissCrx > swissThreshold_ ) continue;
> 	//	if( abs(itb->time()) > timeThreshold_ ) continue;
> 	
> 	////////////////////////////////////////////////////////////
> 	
> 	EBDetId id(itb->id());
> 	double energy = itb->energy();
> 	if( energy < seleXtalMinEnergy_) continue; 
> 	
> 	EBDetId det = itb->id();
> 	
> 	detIdEBRecHits.push_back(det);
> 	EBRecHits.push_back(*itb);	  
> 	if ( energy > clusSeedThr_ ) seeds.push_back(*itb);
> 	
> 	//htimeEB_->Fill(itb->time());	  
> 	etot+= itb->energy();	 
> 	
>       } // Eb rechits
811,812c597
<       //htimeEB_->Fill(itb->time());	  
<       etot+= itb->energy();	 
---
>       iso = 0;
814,823c599,600
<     } // Eb rechits
<     
<     iso = 0;
< 		
<     // Make own simple clusters (3x3, 5x5 or clusPhiSize_ x clusEtaSize_)
<     sort(seeds.begin(), seeds.end(), ecalRecHitLess());
<     
<     for (std::vector<EcalRecHit>::iterator itseed=seeds.begin(); itseed!=seeds.end(); itseed++) {
<       EBDetId seed_id = itseed->id();
<       std::vector<EBDetId>::const_iterator usedIds;
---
>       // Make own simple clusters (3x3, 5x5 or clusPhiSize_ x clusEtaSize_)
>       sort(seeds.begin(), seeds.end(), ecalRecHitLess());
825,846c602
<       int nCryinclu(0);
<       bool seedAlreadyUsed=false;
<       for(usedIds=usedXtals.begin(); usedIds!=usedXtals.end(); usedIds++){
< 	if(*usedIds==seed_id){
< 	  seedAlreadyUsed=true;
< 	  //cout<< " Seed with energy "<<itseed->energy()<<" was used !"<<endl;
< 	  break; 
< 	}
<       }
<       if(nClu>=NCLUMAX) continue;
<       if(nCry>=NCRYMAX) continue;
< 
<       double seedTime = itseed->time();
<       double seedEnergy = itseed->energy();
<       double weightedTime = 0.0;
< 			
<       if(seedAlreadyUsed)continue;
<       std::vector<DetId> clus_v = topology_p->getWindow(seed_id,clusEtaSize_,clusPhiSize_);       
<       std::vector<std::pair<DetId,float> > clus_used;
< 			
<       vector<EcalRecHit> RecHitsInWindow;
<       vector<EcalRecHit> RecHitsInWindow5x5;
---
>       //int seedcount(0);
848,853c604,609
<       double simple_energy = 0;
< 			
<       for (std::vector<DetId >::iterator det=clus_v.begin(); det!=clus_v.end(); det++) {
< 	EBDetId EBdet = *det;
< 	//      cout<<" det "<< EBdet<<" ieta "<<EBdet.ieta()<<" iphi "<<EBdet.iphi()<<endl;
< 	bool  HitAlreadyUsed=false;
---
>       for (std::vector<EcalRecHit>::iterator itseed=seeds.begin(); itseed!=seeds.end(); itseed++) {
> 	EBDetId seed_id = itseed->id();
> 	std::vector<EBDetId>::const_iterator usedIds;
> 	
> 	int nCryinclu(0);
> 	bool seedAlreadyUsed=false;
855,857c611,643
< 	  if(*usedIds==*det){
< 	    HitAlreadyUsed=true;
< 	    break;
---
> 	  if(*usedIds==seed_id){
> 	    seedAlreadyUsed=true;
> 	    //cout<< " Seed with energy "<<itseed->energy()<<" was used !"<<endl;
> 	    break; 
> 	  }
> 	}
> 	if(nClu>=NCLUMAX) continue;
> 	if(nCry>=NCRYMAX) continue;
> 
> 	double seedTime = itseed->time();
> 	TimingInClustering->Fill(seedTime);
> 	//	if( seedTime > timeThreshold_ ) continue;
> 	double weightedTime = 0.0;
> 
> 	if(seedAlreadyUsed)continue;
> 	std::vector<DetId> clus_v = topology_p->getWindow(seed_id,clusEtaSize_,clusPhiSize_);       
> 	std::vector<std::pair<DetId,float> > clus_used;
> 	//Reject the seed if not able to build the cluster around it correctly
> 	//if(clus_v.size() < clusEtaSize_*clusPhiSize_){cout<<" Not enough RecHits "<<endl; continue;}
> 	vector<EcalRecHit> RecHitsInWindow;
> 	vector<EcalRecHit> RecHitsInWindow5x5;
> 	
> 	double simple_energy = 0;
> 	
> 	for (std::vector<DetId >::iterator det=clus_v.begin(); det!=clus_v.end(); det++) {
> 	  EBDetId EBdet = *det;
> 	  //      cout<<" det "<< EBdet<<" ieta "<<EBdet.ieta()<<" iphi "<<EBdet.iphi()<<endl;
> 	  bool  HitAlreadyUsed=false;
> 	  for(usedIds=usedXtals.begin(); usedIds!=usedXtals.end(); usedIds++){
> 	    if(*usedIds==*det){
> 	      HitAlreadyUsed=true;
> 	      break;
> 	    }
858a645,687
> 	  if(HitAlreadyUsed)continue;
> 	  
> 	  std::vector<EBDetId>::iterator itdet = find( detIdEBRecHits.begin(),detIdEBRecHits.end(),EBdet);
> 	  if(itdet == detIdEBRecHits.end()) continue; 
> 	  
> 	  int nn = int(itdet - detIdEBRecHits.begin());
> 	  usedXtals.push_back(*det);
> 	  RecHitsInWindow.push_back(EBRecHits[nn]);
> 	  clus_used.push_back(std::make_pair(*det,1));
> 	  simple_energy = simple_energy + EBRecHits[nn].energy();
> 	  
> 	}
> 	
> 	if(simple_energy <= 0) continue;
> 	
> 	math::XYZPoint clus_pos = posCalculator_.Calculate_Location(clus_used,hitCollection_p,geometry_p,geometryES_p);
> 	
> 	float theta_s = 2. * atan(exp(-clus_pos.eta()));
> 	
> 	// eta correction according to Z
> 	double etaForZEqualsZero = clus_pos.eta();  // initial eta value of cluster without correcting for event Z-vertex;
> 	double zCorrectedEta = etaForZEqualsZero; // placeholder for correction result
> 	double zAtECal = 0.0;
> 	double thetaForZEqualsZero = -1000.0;
> 	if(etaForZEqualsZero != 0.0) {
> 	  thetaForZEqualsZero = 2.0*atan(exp(-etaForZEqualsZero));
> 	  zAtECal = rECal/tan(thetaForZEqualsZero);
> 	} // check for non-zero value of uncorrected eta
> 	
> 	//
> 	// Correction for zVertex using the zVertexEventSelected value
> 	//
> 	double zCorrected = zAtECal - 0.01*zVertexEventSelected;  // convert to meters
> 	double thetaCorrected = -1000.0;
> 	if(zCorrected != 0.0) {
> 	  
> 	  thetaCorrected = atan(rECal/zCorrected);
> 	  if(thetaCorrected < 0.0)
> 	    thetaCorrected += TMath::Pi();  // convert to 0 to pi range for theta
> 	  
> 	  theta_s = thetaCorrected;  // corrected value of theta
> 	  
> 	  zCorrectedEta = -log(tan(thetaCorrected/2.0));
860,973c689,722
< 	if(HitAlreadyUsed)continue;
< 				
< 	std::vector<EBDetId>::iterator itdet = find( detIdEBRecHits.begin(),detIdEBRecHits.end(),EBdet);
< 	if(itdet == detIdEBRecHits.end()) continue; 
< 				
< 	int nn = int(itdet - detIdEBRecHits.begin());
< 	usedXtals.push_back(*det);
< 	RecHitsInWindow.push_back(EBRecHits[nn]);
< 	clus_used.push_back(std::make_pair(*det,1));
< 	simple_energy = simple_energy + EBRecHits[nn].energy();
< 				
<       }
<       
<       if(simple_energy <= 0) continue;
< 			
<       math::XYZPoint clus_pos = posCalculator_.Calculate_Location(clus_used,hitCollection_p,geometry_p,geometryES_p);
<       
<       float theta_s = 2. * atan(exp(-clus_pos.eta()));
< 			
<       // eta correction according to Z
<       double etaForZEqualsZero = clus_pos.eta();  // initial eta value of cluster without correcting for event Z-vertex;
<       double zCorrectedEta = etaForZEqualsZero; // placeholder for correction result
<       double zAtECal = 0.0;
<       double thetaForZEqualsZero = -1000.0;
<       if(etaForZEqualsZero != 0.0) {
< 	thetaForZEqualsZero = 2.0*atan(exp(-etaForZEqualsZero));
< 	zAtECal = rECal/tan(thetaForZEqualsZero);
<       } // check for non-zero value of uncorrected eta
< 			
<       //
<       // Correction for zVertex using the zVertexEventSelected value
<       //
<       double zCorrected = zAtECal - 0.01*zVertexEventSelected;  // convert to meters
<       double thetaCorrected = -1000.0;
<       if(zCorrected != 0.0) {
< 				
< 	thetaCorrected = atan(rECal/zCorrected);
< 	if(thetaCorrected < 0.0)
< 	  thetaCorrected += TMath::Pi();  // convert to 0 to pi range for theta
< 				
< 	theta_s = thetaCorrected;  // corrected value of theta
< 				
< 	zCorrectedEta = -log(tan(thetaCorrected/2.0));
<       }
<       else {
< 	zCorrectedEta = 0.0;
<       } // check for non-zero value of Z baseline
< 			
<       if(iPrintEtaCorrection < nPrintEtaCorrection) {
< 	cout << "\n First pass: zVertexEventSelected = " << 0.01*zVertexEventSelected;  // convert to meters
< 	cout << ", zAtECal = " << zAtECal;
< 	cout << ", zCorrected = " << zCorrected;
< 	cout << ", thetaForZEqualsZero = " << thetaForZEqualsZero;
< 	cout << ", thetaCorrected = " << thetaCorrected;
< 	cout << ", zCorrectedEta = " << zCorrectedEta;
< 	cout << ", uncorrected Eta = " << etaForZEqualsZero;
< 				
< 	iPrintEtaCorrection++;
< 	if(iPrintEtaCorrection >= nPrintEtaCorrection)
< 	  cout << endl;
< 				
<       }
< 			
<       float et_s = simple_energy * sin(theta_s);
< 			
<       float s4s9_tmp[4];
<       for(int i=0;i<4;i++)s4s9_tmp[i]= 0;
<       
<       int seed_ieta = seed_id.ieta();
<       int seed_iphi = seed_id.iphi();
< 			
<       convxtalid( seed_iphi,seed_ieta);  // for ECAL barrel this method converts the iphi index range to 0 -> 359, and the ieta range to -85 -> -1 (negative eta) or 0 -> 84 (positive eta)
<       
<       //
<       // Check on hot channel in this cluster (based on pPb 2013 data)
<       //
<       if((seed_ieta == -75 && seed_iphi == 199) ||
< 	 (seed_ieta ==  67 && seed_iphi == 74)) {
< 	hotChannelSeedsDiscarded++;
< 	continue;
<       }
< 			
<       float e3x3 = 0; 
<       float e5x5 = 0;
< 			
<       for(unsigned int j=0; j<9; j++) {
< 	//
< 	// This array gives the sequential crystal number (starting at 0) for each member of the 3x3 cluster
< 	//
< 	indexCryClu[nClu][j] = -1;  // this array was never initialized before (June 23, 2013)
<       }
<       
<       float s9WidthXSum = 0.0;
<       float s9WidthYSum = 0.0;
<       float s25WidthXSum = 0.0;
<       float s25WidthYSum = 0.0;
< 
<       float enSum3x3Sq = 0.0;
<       float enSum5x5Sq = 0.0;
< 
<       for(unsigned int j=0; j<RecHitsInWindow.size();j++){
< 	EBDetId det = (EBDetId)RecHitsInWindow[j].id(); 
< 				
< 	int ieta = det.ieta();
< 	int iphi = det.iphi();
< 				
< 	convxtalid(iphi,ieta);
< 				
< 	//
< 	// Check on hot channel in this cluster (based on pPb 2013 data)
< 	//
< 	if((ieta == -75 && iphi == 199) ||
< 	   (ieta ==  67 && iphi == 74)) {
< 	  hotChannelSatellitesDiscarded++;
---
> 	else {
> 	  zCorrectedEta = 0.0;
> 	} // check for non-zero value of Z baseline
> 	
> 	if(iPrintEtaCorrection < nPrintEtaCorrection) {
> 	  cout << "\n First pass: zVertexEventSelected = " << 0.01*zVertexEventSelected;  // convert to meters
> 	  cout << ", zAtECal = " << zAtECal;
> 	  cout << ", zCorrected = " << zCorrected;
> 	  cout << ", thetaForZEqualsZero = " << thetaForZEqualsZero;
> 	  cout << ", thetaCorrected = " << thetaCorrected;
> 	  cout << ", zCorrectedEta = " << zCorrectedEta;
> 	  cout << ", uncorrected Eta = " << etaForZEqualsZero;
> 	  
> 	  iPrintEtaCorrection++;
> 	  if(iPrintEtaCorrection >= nPrintEtaCorrection)
> 	    cout << endl;
> 	  
> 	}
> 	
> 	float et_s = simple_energy * sin(theta_s);
> 	
> 	float s4s9_tmp[4];
> 	for(int i=0;i<4;i++)s4s9_tmp[i]= 0;
> 	
> 	int seed_ieta = seed_id.ieta();
> 	int seed_iphi = seed_id.iphi();
> 	
> 	convxtalid( seed_iphi,seed_ieta);
> 	
> 	// Getting rid of hot channels 
> 	// for ECAL barrel this method converts the iphi index range to 0 -> 359, and the ieta range to -85 -> -1 (negative eta) or 0 -> 84 (positive eta)      
> 	if((seed_ieta == -75 && seed_iphi == 199) ||
> 	   (seed_ieta ==  67 && seed_iphi == 74)) {
> 	  hotChannelSeedsDiscarded++;
976,1014c725,743
< 				
< 	float en = RecHitsInWindow[j].energy(); 
< 				
< 	int dx = diff_neta_s(seed_ieta,ieta);
< 	int dy = diff_nphi_s(seed_iphi,iphi);//
< 
< 	float xWidth = float(dx*dx)*en*en;
< 	float yWidth = float(dy*dy)*en*en;
< 
< 	if(abs(dx)<=1 && abs(dy)<=1) {
< 	  s9WidthXSum += xWidth;
< 	  s9WidthYSum += yWidth;
< 	  enSum3x3Sq += en*en;
< 	} // check on 3x3
< 				
< 	if(abs(dx)<=1 && abs(dy)<=1) {
< 	  e3x3 += en; 
< 	  if(dx <= 0 && dy <=0) s4s9_tmp[0] += en; 
< 	  if(dx >= 0 && dy <=0) s4s9_tmp[1] += en; 
< 	  if(dx <= 0 && dy >=0) s4s9_tmp[2] += en; 
< 	  if(dx >= 0 && dy >=0) s4s9_tmp[3] += en; 
< 	  if(nCry>=NCRYMAX) continue;
< 	  kCry[nCry] = nCry;
< 	  eCry[nCry] = RecHitsInWindow[j].energy();
< 	  ptCry[nCry] =  RecHitsInWindow[j].energy() * sin(2. * atan(exp(-geometry_p->getGeometry(det)->getPosition().eta())));
< 	  timeCry[nCry] = RecHitsInWindow[j].time();
< 	  flagCry[nCry] = RecHitsInWindow[j].recoFlag();
< 	  ietaCry[nCry] = ieta;
< 	  iphiCry[nCry] = iphi;
< 	  weightedTime += eCry[nCry]*timeCry[nCry];
< 					
< 	  iCry[nCry] = det.ic();
< 	  iSM[nCry] = det.ism();
< 	  etaCry[nCry] = geometry_p->getGeometry(det)->getPosition().eta();
< 	  phiCry[nCry] = geometry_p->getGeometry(det)->getPosition().phi();
< 	  indexCryClu[nClu][nCryinclu] = nCry;
< 	  if(dx == 0 && dy == 0)  {
< 	    S1Clu[nClu] = RecHitsInWindow[j].energy();
< 	    timeClu[nClu] = RecHitsInWindow[j].time();
---
> 	
> 	float e3x3 = 0; 
> 	float e5x5 = 0;
> 	double e4_e1 = 0;
> 	//	double Swiss_cross;
> 	
> 	for(unsigned int j=0; j<RecHitsInWindow.size();j++){
> 	  EBDetId det = (EBDetId)RecHitsInWindow[j].id(); 
> 	  
> 	  int ieta = det.ieta();
> 	  int iphi = det.iphi();
> 	  
> 	  convxtalid(iphi,ieta);
> 	  
> 	  //Getting rid of the hot channel	
> 	  if((ieta == -75 && iphi == 199) ||
> 	     (ieta ==  67 && iphi == 74)) {
> 	    hotChannelSatellitesDiscarded++;
> 	    continue;
1016,1066c745,811
< 	  nCryinclu++;
< 	  indexCluCry[nCry] = nClu;
< 	  nCry++;      
< 	} // check that |dx| <= 1  and  |dy| <= 1
<       }
< 			
<       if(e3x3 <= clustEnrCut) continue;
<       
<       if(enSum3x3Sq > 0.0) {
< 	s9WidthX[nClu] = sqrt(s9WidthXSum/enSum3x3Sq);
< 	s9WidthY[nClu] = sqrt(s9WidthYSum/enSum3x3Sq);
<       }
<       else {
< 	s9WidthX[nClu] = -999.0;
< 	s9WidthY[nClu] = -999.0;
<       }
<  
<       float s4s9_max = *max_element( s4s9_tmp,s4s9_tmp+4)/e3x3; 
<       
<       //calculate e5x5
<       std::vector<DetId> clus_v5x5 = topology_p->getWindow(seed_id,5,5); 
<       for( std::vector<DetId>::const_iterator idItr = clus_v5x5.begin(); idItr != clus_v5x5.end(); idItr++){
< 	EBDetId det = *idItr;
< 				
< 	//inside collections
< 	std::vector<EBDetId>::iterator itdet = find( detIdEBRecHits.begin(),detIdEBRecHits.end(),det);
< 	if(itdet == detIdEBRecHits.end()) continue; 
< 				
< 	int nn = int(itdet - detIdEBRecHits.begin());
< 				
< 	RecHitsInWindow5x5.push_back(EBRecHits[nn]);
< 	e5x5 += EBRecHits[nn].energy();
<       }
< 			
<       if(e5x5 <= 0) continue;
<  
<       for(unsigned int j=0; j<RecHitsInWindow5x5.size();j++){
< 	EBDetId det = (EBDetId)RecHitsInWindow5x5[j].id(); 
< 				
< 	int ieta = det.ieta();
< 	int iphi = det.iphi();
< 				
< 	convxtalid(iphi,ieta);
< 				
< 	//
< 	// Check on hot channel in this cluster (based on pPb 2013 data)
< 	//
< 	if((ieta == -75 && iphi == 199) ||
< 	   (ieta ==  67 && iphi == 74)) {
< 	  hotChannelSatellitesDiscarded++;
< 	  continue;
---
> 	  
> 	  float en = RecHitsInWindow[j].energy(); 
> 	  
> 	  int dx = diff_neta_s(seed_ieta,ieta);
> 	  int dy = diff_nphi_s(seed_iphi,iphi);
> 	  
> 	  double eRight = 0;
> 	  double eTop = 0;
> 	  double eLeft = 0;
> 	  double eBottom = 0; 	
> 	  /////////// adding swiss-cross cut ////
> 	  
> 	  if(dx == 1) eRight =  en;
> 	  if(dy == 1) eTop =  en;
> 	  if(dy == -1) eLeft =  en;
> 	  if(dx == -1) eBottom =  en;
> 	  
> 	  e4_e1 += (eRight + eTop + eLeft + eBottom);
> 	  //	  Swiss_cross = 1 - e4_e1;
> 	  
> 	  //	if(Swiss_cross > 0.87) continue;	//Not applying the swiss-cross cut
> 	  ///////////////////////////////////////
> 	  if(abs(dx)<=1 && abs(dy)<=1) {
> 	    e3x3 += en; 
> 	    if(dx <= 0 && dy <=0) s4s9_tmp[0] += en; 
> 	    if(dx >= 0 && dy <=0) s4s9_tmp[1] += en; 
> 	    if(dx <= 0 && dy >=0) s4s9_tmp[2] += en; 
> 	    if(dx >= 0 && dy >=0) s4s9_tmp[3] += en; 
> 	    if(nCry>=NCRYMAX) continue;
> 	    eCry[nCry] = RecHitsInWindow[j].energy();
> 	    ptCry[nCry] =  RecHitsInWindow[j].energy() * sin(2. * atan(exp(-geometry_p->getGeometry(det)->getPosition().eta())));
> 	    timeCry[nCry] = RecHitsInWindow[j].time();
> 	    flagCry[nCry] = RecHitsInWindow[j].recoFlag();
> 	    ietaCry[nCry] = ieta;
> 	    iphiCry[nCry] = iphi;
> 	    weightedTime += eCry[nCry]*timeCry[nCry];
> 	    iCry[nCry] = det.ic();
> 	    iSM[nCry] = det.ism();
> 	    etaCry[nCry] = geometry_p->getGeometry(det)->getPosition().eta();
> 	    phiCry[nCry] = geometry_p->getGeometry(det)->getPosition().phi();
> 	    indexCryClu[nClu][nCryinclu] = nCry;
> 	    if(dx == 0 && dy == 0)  {
> 	      S1Clu[nClu] = RecHitsInWindow[j].energy();
> 	      timeClu[nClu] = RecHitsInWindow[j].time();
> 	    }
> 	    nCryinclu++;
> 	    nCry++;      
> 	  }//
> 	}
> 	
> 	if(e3x3 <= 0) continue;
> 	
> 	float s4s9_max = *max_element( s4s9_tmp,s4s9_tmp+4)/e3x3; 
> 	
> 	//calculate e5x5
> 	std::vector<DetId> clus_v5x5 = topology_p->getWindow(seed_id,5,5); 
> 	for( std::vector<DetId>::const_iterator idItr = clus_v5x5.begin(); idItr != clus_v5x5.end(); idItr++){
> 	  EBDetId det = *idItr;
> 	  
> 	  //inside collections
> 	  std::vector<EBDetId>::iterator itdet = find( detIdEBRecHits.begin(),detIdEBRecHits.end(),det);
> 	  if(itdet == detIdEBRecHits.end()) continue; 
> 	  
> 	  int nn = int(itdet - detIdEBRecHits.begin());
> 	  
> 	  RecHitsInWindow5x5.push_back(EBRecHits[nn]);
> 	  e5x5 += EBRecHits[nn].energy();
1068,1123c813,818
< 				
< 	float en = RecHitsInWindow5x5[j].energy(); 
< 				
< 	int dx = diff_neta_s(seed_ieta,ieta);
< 	int dy = diff_nphi_s(seed_iphi,iphi);//
< 
< 	float xWidth = float(dx*dx)*en*en;
< 	float yWidth = float(dy*dy)*en*en;
< 
< 	if(abs(dx)<=2 && abs(dy)<=2) {
< 	  s25WidthXSum += xWidth;
< 	  s25WidthYSum += yWidth;
< 	  enSum5x5Sq += en*en;
< 	} // check on 5x5
< 
<       } // sum over j
< 
<       if(enSum5x5Sq > 0.0) {
< 	s25WidthX[nClu] = sqrt(s25WidthXSum/enSum5x5Sq);
< 	s25WidthY[nClu] = sqrt(s25WidthYSum/enSum5x5Sq);
<       }
<       else {
< 	s25WidthX[nClu] = -999.0;
< 	s25WidthY[nClu] = -999.0;
<       }
<   
<       kClu[nClu] = nClu;
<       S9Clu[nClu] = e3x3;
<       ptClu[nClu] =  et_s;
<       etaClu[nClu] = zCorrectedEta;
<       phiClu[nClu] = clus_pos.phi();
<       S4Clu[nClu] =  s4s9_max * simple_energy; // s4s9_max is a ratio with e3x3 as the denominator
<       S25Clu[nClu] = e5x5;
<       nCryClu[nClu] = nCryinclu;
<       seedTimeClu[nClu] = seedTime;
<       seedEnergyClu[nClu] = seedEnergy;
<       recEnergySum[nClu] = e3x3;
<       weightedTimeClu[nClu] = weightedTime/e3x3;
<  
<       if(doEnergyRecalibration_) {
< 	//
< 	// Energy re-calibration method derived from a study of HIJING pPb events (2013 production)
< 	// The energy discrepancy in MC was found to be a function of the number of crystals in the cluster
< 	// For crystal numbers 1 and 2, there was also a linear correction
< 	// After these first order corrections were made, a small second order constant fractional increase was done
< 	// These corrections were checked for the results of the pi0 and the eta(547.5 MeV) masses
< 	//
< 	if(nCryinclu < 1 || nCryinclu > 9) {
< 	  cerr << "\n\n Programming error with nCryinclu = " << nCryinclu << endl;
< 	  return;
< 	}
< 	float totalCorrection = crystalCorrectionFunction(nCryinclu - 1, e3x3);
< 				
< 	e3x3 *= totalCorrection;
< 	et_s *= totalCorrection;
< 				
---
> 	
> 	if(e5x5 <= 0) continue;
> 	
> 	RecHitsCluster.push_back(RecHitsInWindow);
> 	RecHitsCluster5x5.push_back(RecHitsInWindow5x5);
> 	
1126,1129c821,824
< 				
< 	S4Clu[nClu] *= totalCorrection;
< 				
< 	e5x5 *= totalCorrection;
---
> 	// etaClu[nClu] = clus_pos.eta();
> 	etaClu[nClu] = zCorrectedEta;
> 	phiClu[nClu] = clus_pos.phi();
> 	S4Clu[nClu] =  s4s9_max * simple_energy;
1131,1150c826,834
< 				
<       } // check for doing energy re-calibration
<       
<       if(useClusterCrystalLimit_ && !useClusterCrystalLimitLowPtOnly_  && (nCryinclu < lowCrystalLimit_ || nCryinclu > highCrystalLimit_)) {
< 	//
< 	// Cluster limits option was specified, there is no requirement for low pair pT, and this cluster is outside of the limits
< 	// Cluster will be rejected
< 	//
< 	continue; // do not use this cluster, crystal number not in range
<       }
< 
<       //
<       // Check the timing information
<       //
<       bool goodTimingCheck = true;
< 
<       if(doOneDimensionTimeCut_) {
< 	if(oneDimensionTimeCut_ < 0) {
< 	  if(fabs(seedTimeClu[nClu]) < -oneDimensionTimeCut_) {
< 	    goodTimingCheck = false;
---
> 	nCryClu[nClu] = nCryinclu;
> 	seedTimeClu[nClu] = seedTime;
> 	weightedTimeClu[nClu] = weightedTime/e3x3;	
> 
> 	if(doEnergyRecalibration_) {
> 	  
> 	  if(nCryinclu < 1 || nCryinclu > 9) {
> 	    cerr << "\n\n Programming error with nCryinclu = " << nCryinclu << endl;
> 	    return;
1152,1154c836,893
< 	} // reverse cut
< 	if(doOneDimensionTimeCut_ > 0) {
< 	  if(fabs(seedTimeClu[nClu]) > oneDimensionTimeCut_) {
---
> 	  float totalCorrection = crystalCorrectionFunction(nCryinclu - 1, e3x3);
> 	  
> 	  e3x3 *= totalCorrection;
> 	  et_s *= totalCorrection;
> 	  
> 	  S9Clu[nClu] = e3x3;
> 	  ptClu[nClu] =  et_s;
> 	  
> 	  S4Clu[nClu] *= totalCorrection;
> 	  e5x5 *= totalCorrection;
> 	  S25Clu[nClu] = e5x5;
> 	  
> 	} // check for doing energy re-calibration
> 
> 	if(useClusterCrystalLimit_ && useClusterCrystalLimitLowPtOnly_  && (nCryinclu < lowCrystalLimit_ || nCryinclu > highCrystalLimit_)) {
> 	  //                                                                                                                      
> 	  // Cluster limits option was specified, there is no requirement for low pair pT, and this cluster is outside of the limits                                                                                                                             
> 	  // Cluster will be rejected                                                                                             
> 	  //                                                                                                                      
> 	  continue; // do not use this cluster, crystal number not in range
> 	  cout<<"-X-X-X My condition is not satisfied... You are fine... "<<endl;
> 	}
> 	
> 
> 	//                                                                                                                    
> 	// Check the timing information                                                                                       
> 	//                                                                                                                    
> 	bool goodTimingCheck = true;
> 
> 	if(doOneDimensionTimeCut_) {
> 	  if(oneDimensionTimeCut_ < 0) {
> 	    if(fabs(seedTimeClu[nClu]) < -oneDimensionTimeCut_) {
> 	      goodTimingCheck = false;
> 	    }
> 	  } // reverse cut                                                                                                    
> 	  if(doOneDimensionTimeCut_ > 0) {
> 	    if(fabs(seedTimeClu[nClu]) > oneDimensionTimeCut_) {
> 	      goodTimingCheck = false;
> 	    }
> 	  } // normal cut                                                                       
> 	} // check for doing one dimensional  timing cuts on the seed crystal of the cluster
> 
> 	if(doTwoDimensionTimeCut_) {
> 
> 	  //                                                                                                          
>           // The default 2D cut has a base width of 20 ns and a minimum value of 8 ns                              
> 	  // The rescaled (better) 2D cut has these dimensions reduced by the factor twoDimensionTimeCutFactor           
> 	  //                                                                                                     
>      
> 	  float energyInverse = 1.0/S9Clu[nClu];
> 
> 	  float tCut = 4.0 - 10.8452*energyInverse + 14.9102*energyInverse*energyInverse -3.065*energyInverse*energyInverse*energyInverse;
> 
> 	  if(S9Clu[nClu] > 1.123)
> 	    tCut = 4.0;  // minimum value for the default time cut                                                  
> 	  tCut *= twoDimensionTimeCutFactor_;  // rescale the size of the default 2D cut                             
> 	  
> 	  if(fabs(seedTimeClu[nClu]) > tCut) {
1157,1158c896,904
< 	} // normal cut
<       } // check for doing one dimensional  timing cuts on the seed crystal of the cluster
---
> 	  //                                                                                                           
> 	  // Check timing for clusters with 2 or more crystals                                                     
> 	  //                                                                                                            
> 	  if(doWeightedTimeCut_ && nCryinclu > 1 && nCryinclu <= 9) {
> 	    if(fabs(weightedTimeClu[nClu] - seedTimeClu[nClu]) > tCut) {
> 	      goodTimingCheck = false;
> 	    }
> 	  } // check weighted time for clusters with two or more crystals                                             
> 	} // check for doing two dimensional timing cuts on the seed crystal of the cluster                           
1160,1167c906,927
<       if(doTwoDimensionTimeCut_) {
< 	//
< 	// The default 2D cut has a base width of 20 ns and a minimum value of 8 ns
< 	// The rescaled (better) 2D cut has these dimensions reduced by the factor twoDimensionTimeCutFactor
< 	//
< 	float energyInverse = 1.0/S9Clu[nClu];
<        
< 	float tCut = 4.0 - 10.8452*energyInverse + 14.9102*energyInverse*energyInverse -3.065*energyInverse*energyInverse*energyInverse;
---
> 	if(goodTimingCheck) {
> 	  etaCluUncorrected[nClu] = etaForZEqualsZero;
> 	  double thetaUncorrected = 2.0*atan(exp(-etaCluUncorrected[nClu]));
> 	  zClu[nClu] = 100.0*rECal/tan(thetaUncorrected);  // Z value of cluster in cm                            
> 	  nClu++;
> 	} // accept this cluster as having good timing                                                                
>       } // loop over seeds
>       
>     }            // rhEBpi0.valid() ends
>     
>     
>     if(nClu > maxClustersPerJob) {
>       maxClustersPerJob = nClu;
>       eventMaxClustersPerJob = thisEvent;
>       runMaxClustersPerJob = thisJob;
>     }
>     
>     if(nCry > maxCryPerJob) {
>       maxCryPerJob = nCry;
>       eventMaxCryPerJob = thisEvent;
>       runMaxCryPerJob = thisJob;
>     }
1169,1170d928
< 	if(S9Clu[nClu] > 1.123)
< 	  tCut = 4.0;  // minimum value for the default time cut
1172c930,931
< 	tCut *= twoDimensionTimeCutFactor_;  // rescale the size of the default 2D cut
---
>     ///////////// For selecting events based on leading photon pt 
>     double leadingPhotonPt = 0.0;
1174,1176c933
< 	if(fabs(seedTimeClu[nClu]) > tCut) {
< 	  goodTimingCheck = false;
< 	}
---
>     for(int kCluster=0; kCluster<nClu; kCluster++) {
1178,1185c935,944
< 	//
< 	// Check timing for clusters with 2 or more crystals
< 	//
< 	if(doWeightedTimeCut_ && nCryinclu > 1 && nCryinclu <= 9) {
< 	  if(fabs(weightedTimeClu[nClu] - seedTimeClu[nClu]) > tCut) {
< 	    goodTimingCheck = false;
< 	  }
< 	} // check weighted time for clusters with two or more crystals
---
>       float clustrEnr = S9Clu[kCluster];
>       float clustrPt = ptClu[kCluster];
>       float clustrS49 = S4Clu[kCluster]/clustrEnr;
>       float clustrS1 = S1Clu[kCluster];
>       float clustrEta = etaClu[kCluster];
>       float clustrS25 = S25Clu[kCluster];
> 
>       if(clustrEnr > clustEnrCut && clustrPt > clustPtCut &&
>          clustrS1 > clustS1Cut &&
>          fabs(clustrEta) < 1.49 && (fabs(1.0 - clustrS25/clustrEnr) < clustS25Cut)) {
1187,1194c946,960
<       } // check for doing two dimensional timing cuts on the seed crystal of the cluster
< 	
<       if(goodTimingCheck) {
< 	etaCluUncorrected[nClu] = etaForZEqualsZero;
< 	double thetaUncorrected = 2.0*atan(exp(-etaCluUncorrected[nClu]));
< 	zClu[nClu] = 100.0*rECal/tan(thetaUncorrected);  // Z value of cluster in cm
< 	nClu++;
<       } // accept this cluster as having good timing
---
>         if( clustrPt > leadingPhotonPt ) leadingPhotonPt = clustrPt;
>       }
>     }
> 
>     EventsLeadPhotonPt->Fill(leadingPhotonPt);
> 
>     if (cutByLeadingPhotonPt_ )
>       {
>         if( leadingPhotonPt < leadingPhotonPtMin_ ) return;
>         if( leadingPhotonPt > leadingPhotonPtMax_ ) return;
>       }
> 
>     ////////////////////////////////////////////////////////////////////
>     
>     for(int kCluster=0; kCluster<nClu; kCluster++) {
1196,1224c962,977
<     } // loop over seeds
< 		
<     //
<     // Check for an angular match between a cluster and a reco track
<     // Also initialize the Simtracks-Ecal correspondence
<     //
<     for(int iFound=0; iFound<nClu; iFound++) {
< 
<       bestNoConvertSimIndexEcal[iFound] = -1;
<       countNoConvertSimMatchEcal[iFound] = 0;
<       bestNoConvertSimAngleEcal[iFound] = -999.0;
< 
<       double eta1 = etaClu[iFound];
<       double phi1 = phiClu[iFound];
<       double theta1 = 2.0*atan(exp(-eta1));
< 			
<       if(usezEcalCorrection) {
< 	float zCalValue = zClu[iFound];
< 				
< 	if(zCalValue >= zEcalCut)
< 	  theta1 += zEcalSaturationValue;
< 				
< 	if(zCalValue <= -zEcalCut)
< 	  theta1 -= zEcalSaturationValue;
< 				
< 	if(zCalValue > -zEcalCut && zCalValue < zEcalCut)
< 	  theta1 += zEcalCorrectionFactor*zCalValue;
< 				
<       } // check for using zEcal correction for cluster theta value
---
>       float clustrEnr = S9Clu[kCluster];
>       float clustrPt = ptClu[kCluster];
>       float clustrS49 = S4Clu[kCluster]/clustrEnr;
>       float clustrS1 = S1Clu[kCluster];
>       float clustrEta = etaClu[kCluster];
>       float clustrS25 = S25Clu[kCluster];
> 
>       if(clustrEnr > clustEnrCut && clustrPt > clustPtCut &&
> 	 clustrS1 > clustS1Cut &&
> 	 fabs(clustrEta) < 1.49 && (fabs(1.0 - clustrS25/clustrEnr) < clustS25Cut)) {
> 
> 	PhotonClusterPt->Fill(clustrPt);      
> 	
>       }
>       // These cuts are used as the global cuts below for the pi0 mass histograms
>       ShowerShapeCut->Fill(clustrS49);
1226,1311c979,984
<       //
<       // Check for best angular position match with reconstructed tracks
<       //
<       vector<unsigned int> indexGoodMatches;
<       vector<double> valueGoodMatches;
<       int nGoodMatches = 0;
<       float minimumAngularSeparation = 999.0;
<       int indexBestTrackMatch = -1;
< 			
<       nGoodRecoMatches[iFound] = -1;
<       valueBestAngleMatch[iFound] = -999.0;
<       momentumBestTrackMatch[iFound] = -999.0;
<       dxyVertexBestTrackMatch[iFound] = -999.0;
<       dzVertexBestTrackMatch[iFound] = -999.0;
<       sdxyVertexBestTrackMatch[iFound] = -999.0;
<       sdzVertexBestTrackMatch[iFound] = -999.0;
<       dPhiBestAngleMatch[iFound] = -999.0;
<       dThetaBestAngleMatch[iFound] = -999.0;
<       outerRadiusTrackMatch[iFound] = -999.0;
< 			
<       if(recoPtTrackAboveMinimum) {  // check for at least one track above the minimum
< 	float cosPhotonTheta = cos(theta1);  // cluster cosine
< 	float sinPhotonTheta = sin(theta1);  // cluster sine
< 	indexBestTrackMatch = kRecoTrackAbovePtMinimum;  // first track with pT above the minimum
< 	float trkTheta =  recoThetaTrack[kRecoTrackAbovePtMinimum];
< 				
< 	double phiDelta = deltaPhi(phi1, recoPhiDTrack[kRecoTrackAbovePtMinimum]);
< 	minimumAngularSeparation = acos(cosPhotonTheta*cos(trkTheta) + sinPhotonTheta*sin(trkTheta)*cos(phiDelta));
< 	//
< 	// Check good matching criteria
< 	//
< 	if(minimumAngularSeparation < goodAngleMatch_ &&
< 	   fabs(phiDelta) < goodPhiMatch_ && fabs(theta1 - trkTheta) < goodThetaMatch_) {
< 	  indexGoodMatches.push_back(indexBestTrackMatch);
< 	  valueGoodMatches.push_back(minimumAngularSeparation);
< 	  nGoodMatches++;
< 	}
< 				
< 	if(eventn == specialEvent) {
< 	  cout << "\n For special event " << eventn;
< 	  cout << ",  kRecoTrackAbovePtMinimum = " << kRecoTrackAbovePtMinimum;
< 	  cout << ",  nTracksSize = " << nTracksSize;
< 	  cout << ",  phi1 = " << phi1;
< 	  cout << ",  eta1 = " << eta1;
< 	  cout << ",  recoEta = " << recoEtaTrack[kRecoTrackAbovePtMinimum];
< 	  cout << ",  recoPhi = " << recoPhiDTrack[kRecoTrackAbovePtMinimum];
< 	  cout << ",  First angular separation for this cluster = " << minimumAngularSeparation;
< 	}
< 				
< 	for(int jTrack=0; jTrack<nTracksSize; jTrack++) {
< 	  if(jTrack != kRecoTrackAbovePtMinimum &&
< 	     recoPtTrack[jTrack] >= minimumTrackPtForMatch &&
< 	     (!matchOnlyHighPurity || (matchOnlyHighPurity && recoPurityTrack[jTrack]))) {
< 	    trkTheta = recoThetaTrack[jTrack];
< 						
< 	    phiDelta = deltaPhi(phi1, recoPhiDTrack[jTrack]);
< 						
< 	    float testAngularSeparation = acos(cosPhotonTheta*cos(trkTheta) + sinPhotonTheta*sin(trkTheta)*cos(phiDelta));
< 	    if(testAngularSeparation < goodAngleMatch_ &&
< 	       fabs(phiDelta) < goodPhiMatch_ && fabs(theta1 - trkTheta) < goodThetaMatch_) {
< 	      indexGoodMatches.push_back(indexBestTrackMatch);
< 	      valueGoodMatches.push_back(testAngularSeparation);
< 	      nGoodMatches++;
< 	    }
< 	    if(testAngularSeparation < minimumAngularSeparation) {
< 	      minimumAngularSeparation = testAngularSeparation;
< 	      indexBestTrackMatch = jTrack;
< 	    } // check for new best angular match
< 						
<             if(eventn == specialEvent) {
< 	      cout << "\n  jTrack = " << jTrack;
< 	      cout << ",   recoEta = " << recoEtaTrack[jTrack];
< 	      cout << ",   recoPhi = " << recoPhiDTrack[jTrack];
< 	      cout << ",   Current angular separation for this cluster = " << minimumAngularSeparation;
< 	    }
< 						
< 	  } // check for jTrack value and for minimum number of tracks
< 					
< 	} // loop over tracks
< 				
< 	//
< 	// Safety check
< 	//
< 	if(indexBestTrackMatch < 0) {
< 	  cerr << "\n\n Programming error, negative value for indexBestTrackMatch " << indexBestTrackMatch << endl;
< 	  cerr << "\n Event loop ending abnormally" << endl << endl;
---
>       if(clustrEnr > clustEnrCut && clustrPt > clustPtCut &&
> 	 clustrS49 > clustS49Cut && clustrS1 > clustS1Cut &&
> 	 fabs(clustrEta) < 1.49 && (fabs(1.0 - clustrS25/clustrEnr) < clustS25Cut)) {
> 	
> 	if(currentAcceptedClusterNumber >= maximumNumberAcceptedCluster) {
> 	  cerr << "\n currentAcceptedClusterNumber is too large " << currentAcceptedClusterNumber << endl;
1313,1371c986
< 	}
< 				
< 	nGoodRecoMatches[iFound] = nGoodMatches;
< 	indexBestRecoMatch[iFound] = indexBestTrackMatch;
< 	valueBestAngleMatch[iFound] = minimumAngularSeparation;
< 	momentumBestTrackMatch[iFound] = recoPtTrack[indexBestTrackMatch]; 
< 	dxyVertexBestTrackMatch[iFound] = recoDxyTrack[indexBestTrackMatch];
< 	dzVertexBestTrackMatch[iFound] = recoDzTrack[indexBestTrackMatch];
< 	sdxyVertexBestTrackMatch[iFound] = recoSdxyTrack[indexBestTrackMatch];
< 	sdzVertexBestTrackMatch[iFound] = recoSdzTrack[indexBestTrackMatch];
< 				
< 	phiDelta = deltaPhi(phi1, recoPhiDTrack[indexBestTrackMatch]);
< 	dPhiBestAngleMatch[iFound] = phiDelta;
< 	double thetaDelta = theta1 - recoThetaTrack[indexBestTrackMatch]; 
< 	dThetaBestAngleMatch[iFound] = thetaDelta; 
< 	outerRadiusTrackMatch[iFound] = sqrt(recoOxTrack[indexBestTrackMatch]*recoOxTrack[indexBestTrackMatch] +
< 					     recoOyTrack[indexBestTrackMatch]*recoOyTrack[indexBestTrackMatch]);
< 				
< 	outerPtTrackMatch[iFound] = recoOuterPtTrack[indexBestTrackMatch];
< 				
< 	if( minimumAngularSeparation <= goodAngleMatch_ &&
< 	    fabs(phiDelta) < goodPhiMatch_ && fabs(thetaDelta) < goodThetaMatch_) {
< 	  recoNMatchTrack[indexBestTrackMatch]++;
< 	  if(recoEcalTrack[indexBestTrackMatch] == -999) {
< 	    //
< 	    // This reco track has not had a previous good match with an ECAL cluster
< 	    //
< 	    recoEcalTrack[indexBestTrackMatch] = iFound;  // map the matched ECAL cluster to the reco track information
< 	    if(eventn <= 60 && trackEcalMatchDebug) {
< 	      cout << "\n\n Initial Track-ECAL match for track index " << indexBestTrackMatch;
< 	      cout << "\n   Cluster index number is " << iFound;
< 	      cout << "\n   Angle matching value is " << valueBestAngleMatch[iFound];
< 	      cout << endl << endl;
< 	    }
< 	  }
< 	  else {
< 	    //
< 	    // This reco track has had a previous good cluster match
< 	    //
< 	    int oldValue = recoEcalTrack[indexBestTrackMatch];
< 	    if(oldValue < NCLUMAX) {
< 	      if(eventn <= 60 && trackEcalMatchDebug) {
< 		cout << "\n\n Double Track-ECAL match for track index " << indexBestTrackMatch;
< 		cout << "\n   Old cluster index number is " << oldValue;
< 		cout << "\n   New cluster index number is " << iFound;
< 		cout << "\n   Angle matching value is " << valueBestAngleMatch[iFound];
< 		cout << endl << endl;
< 	      }
< 	      recoEcalTrack[indexBestTrackMatch] = iFound*NCLUMAX + oldValue;  // one layer of multiplexing for a double match
< 	    }
< 	  }
< 					
< 	} // check on good value for the angular separation
< 				
<       } // check for recoPtTrackAboveMinimum
< 			
<     } // loop over found clusters
<     
<   } // rhEBpi0.valid() ends
---
> 	} // safety check on too many clusters
1373,1377c988,998
<   if(nClu > maxClustersPerJob) {
<     maxClustersPerJob = nClu;
<     eventMaxClustersPerJob = thisEvent;
<     runMaxClustersPerJob = thisJob;
<   }
---
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].thisEvent = thisEvent;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].kCluster = kCluster;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustEta = clustrEta;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustPhi = phiClu[kCluster];
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustPt = clustrPt;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustEnr = clustrEnr;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustS49 = clustrS49;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustS25 = clustrS25;
> 	acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].hfAllAngle = HFAngle;
> 		
> 	currentAcceptedClusterNumber++;
1379,1383c1000,1001
<   if(nCry > maxCryPerJob) {
<     maxCryPerJob = nCry;
<     eventMaxCryPerJob = thisEvent;
<     runMaxCryPerJob = thisJob;
<   }
---
> 	if(currentAcceptedClusterNumber > maximumClustersInSingleEvent)
> 	  maximumClustersInSingleEvent = currentAcceptedClusterNumber;
1385,1417c1003
<   for(int kCluster=0; kCluster<nClu; kCluster++) {
<     
<     if(suppressTrackMatchedClusters_ && nGoodRecoMatches[kCluster] > 0)
<       continue;
< 		
<     float clustrEnr = S9Clu[kCluster];
<     float clustrPt = ptClu[kCluster];
<     float clustrS49 = S4Clu[kCluster]/clustrEnr;
<     float clustrS1 = S1Clu[kCluster];
<     float clustrEta = etaClu[kCluster];
<     float clustrS25 = S25Clu[kCluster];
<     
<     // These cuts are used as the global cuts below for the pi0 mass histograms
< 		
<     if(clustrEnr > clustEnrCut &&
<        clustrS49 > clustS49Cut_ && clustrS1 > clustS1Cut &&
<        fabs(clustrEta) < 1.49 && (fabs(1.0 - clustrS25/clustrEnr) < clustS25Cut)) { // can change to allow only |eta| < 1.30, was 1.49 originally
<       
<       if(currentAcceptedClusterNumber >= maximumNumberAcceptedCluster) {
< 	cerr << "\n currentAcceptedClusterNumber is too large " << currentAcceptedClusterNumber << endl;
< 	return;
<       } // safety check on too many clusters
<       
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].thisEvent = thisEvent;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].kCluster = kCluster;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].nCryClu = nCryClu[kCluster];
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustEta = clustrEta;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustPhi = phiClu[kCluster];
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustPt = clustrPt;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustEnr = clustrEnr;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustS49 = clustrS49;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].clustS25 = clustrS25;
<       acceptedClusterInformationArray[currentBufferEventIndexCluster][currentAcceptedClusterNumber].hfAllAngle = HFAngle;
---
>       } // check for good cluster
1419c1005,1009
<       currentAcceptedClusterNumber++;
---
>     } // loop over good clusters=======================end loop filling array with current clusters=========================
>     
>     if(currentAcceptedClusterNumber >= minimumClustersPerEvent) {
>       totalEventsWithClusters++;
>       countAcceptedCluster[currentBufferEventIndexCluster] = currentAcceptedClusterNumber; // clusters accepted in the current event
1421,1422c1011
<       if(currentAcceptedClusterNumber > maximumClustersInSingleEvent)
< 	maximumClustersInSingleEvent = currentAcceptedClusterNumber;
---
>       // Calculate same-event and mixed-event mass spectra
1424,1426c1013
<     } // check for good cluster
<     
<   } // loop over good clusters=======================end loop filling array with current clusters=========================
---
>       for(int jCluster1=0; jCluster1<currentAcceptedClusterNumber; jCluster1++) {//=====loop over clusters in current event====
1428,1432c1015,1030
<   if(currentAcceptedClusterNumber >= minimumClustersPerEvent) {
<     totalEventsWithClusters++;
<     countAcceptedCluster[currentBufferEventIndexCluster] = currentAcceptedClusterNumber; // clusters accepted in the current event
<     
<     // Calculate same-event and mixed-event mass spectra
---
> 	Long64_t currentEvent = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].thisEvent;
> 	
> 	float ptCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustPt;
> 	float etaCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustEta;
> 	float phiCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustPhi;
> 	float enrCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustEnr;
> 	
> 	float p1x = ptCluster1*cos(phiCluster1);
> 	float p1y = ptCluster1*sin(phiCluster1);
> 	float p1z = enrCluster1*cos(2.0*atan(exp(-etaCluster1)));
> 	
> 	double clust1Theta = 2.0*atan(exp(-etaCluster1));
> 	
> 	float xCluster1 = rECal*cos(phiCluster1);
> 	float yCluster1 = rECal*sin(phiCluster1);
> 	float zCluster1 = rECal/tan(clust1Theta);
1434,1485c1032,1045
<     if(printPairContributors) {
<       cout << "\n At event " << acceptedClusterInformationArray[currentBufferEventIndexCluster][0].thisEvent  << " which has " <<  currentAcceptedClusterNumber << " accepted clusters";
<       cout << ", nClu " << nClu;
<       cout << " with nHITracks " << nHITracks << " and tHighPurityTracks " << tHighPurityTracks_ << "     [printContributors]";
<     }    
<     for(int jCluster1=0; jCluster1<currentAcceptedClusterNumber; jCluster1++) {//=====loop over clusters in current event====
<       
<       Long64_t currentEvent = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].thisEvent;
<       
<       float ptCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustPt;
<       float etaCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustEta;
<       float phiCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustPhi;
<       float enrCluster1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].clustEnr;
<       
<       float p1x = ptCluster1*cos(phiCluster1);
<       float p1y = ptCluster1*sin(phiCluster1);
<       float p1z = enrCluster1*cos(2.0*atan(exp(-etaCluster1)));
<       
<       double clust1Theta = 2.0*atan(exp(-etaCluster1));
<       
<       float xCluster1 = rECal*cos(phiCluster1);
<       float yCluster1 = rECal*sin(phiCluster1);
<       float zCluster1 = rECal/tan(clust1Theta);
< 
<       int nCryClu1 = acceptedClusterInformationArray[currentBufferEventIndexCluster][jCluster1].nCryClu;
< 
<       for(int kBuffer=0; kBuffer<bufferDepth; kBuffer++) {//=======Loop over OTHER events====================
< 	bool sameEventCheck = false;
< 	if(currentEvent == eventNumberCluster[kBuffer]) {
< 	  sameEventCheck = true;
< 	}
< 				
< 	int previousAcceptedNumber = countAcceptedCluster[kBuffer];
< 	if(sameEventCheck && currentAcceptedClusterNumber != previousAcceptedNumber) {
< 	  cerr << "\n Programming error, same event cluster numbers are not the same";
< 	  cerr << ";  currentAcceptedClusterNumber " << currentAcceptedClusterNumber;
< 	  cerr << ",  previousAcceptedNumber " << previousAcceptedNumber;
< 	  cerr << ",  currentEvent = " << currentEvent;
< 	  cerr << endl;
< 	  return;
< 	}
< 				
< 	for(int jCluster2=0; jCluster2<previousAcceptedNumber; jCluster2++) {//=============loop over clusters in kbuffer==
< 					
< 	  Long64_t previousEvent = acceptedClusterInformationArray[kBuffer][jCluster2].thisEvent;
< 	  if(previousEvent == currentEvent && !sameEventCheck) {
< 	    cerr << "\n Programming error: trying to mix clusters with the same event number " << currentEvent;
< 	    cerr << ",  kBuffer = " << kBuffer << ", clusters in previous event " << previousAcceptedNumber;
< 	    for(int jBuffer=0; jBuffer<bufferDepth; jBuffer++) {
< 	      cout << "\n jBuffer " << jBuffer << ",  eventNumber " << eventNumberCluster[jBuffer];
< 	      cout << ", clusters in event " << countAcceptedCluster[jBuffer];
< 	    }
---
> 	int nCryClu1 = nCryClu[jCluster1];
> 	
> 	for(int kBuffer=0; kBuffer<bufferDepth; kBuffer++) {//=======Loop over OTHER events====================
> 	  bool sameEventCheck = false;
> 	  if(currentEvent == eventNumberCluster[kBuffer]) {
> 	    sameEventCheck = true;
> 	  }
> 	  
> 	  int previousAcceptedNumber = countAcceptedCluster[kBuffer];
> 	  if(sameEventCheck && currentAcceptedClusterNumber != previousAcceptedNumber) {
> 	    cerr << "\n Programming error, same event cluster numbers are not the same";
> 	    cerr << ";  currentAcceptedClusterNumber " << currentAcceptedClusterNumber;
> 	    cerr << ",  previousAcceptedNumber " << previousAcceptedNumber;
> 	    cerr << ",  currentEvent = " << currentEvent;
1489,1557c1049,1059
< 					
< 	  if(sameEventCheck && jCluster2<=jCluster1)
< 	    continue;
< 					
< 	  if(sameEventCheck)
< 	    countSameEvents++;
< 					
< 	  countMixedClusterExamined++;
< 					
< 	  float ptCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustPt;
< 	  float etaCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustEta;
< 	  float enrCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustEnr;
< 	  float phiCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustPhi;
< 					
< 	  float p2x = ptCluster2*cos(phiCluster2);
< 	  float p2y = ptCluster2*sin(phiCluster2);
< 	  float p2z = enrCluster2*cos(2.0*atan(exp(-etaCluster2)));
< 	  double clust2Theta = 2.0*atan(exp(-etaCluster2));
< 					
< 	  float pxsum = p1x + p2x;
< 	  float pysum = p1y + p2y;
< 	  float pi0Pt = sqrt(pxsum*pxsum + pysum*pysum);
< 
< 	  int nCryClu2 = acceptedClusterInformationArray[kBuffer][jCluster2].nCryClu;
< 	  //
< 	  // Check for cluster crystal limits
< 	  //
< 	  if(useClusterCrystalLimit_ && useClusterCrystalLimitLowPtOnly_  && pi0Pt < clusterCrystalLimitLowPtOnly_ && 
< 	     (nCryClu1 < lowCrystalLimit_ || nCryClu1 > highCrystalLimit_ ||
< 	      nCryClu2 < lowCrystalLimit_ || nCryClu2 > highCrystalLimit_))
< 	    continue; // reject this pair because of the cluster crystal limits check
< 
< 	  float pi0Phi = atan2(pysum, pxsum); 
< 	  float pzsum = p1z + p2z;
< 	  float totalMomentum = sqrt(pi0Pt*pi0Pt + pzsum*pzsum);
< 	  float pi0Theta = acos(pzsum/totalMomentum);
< 	  float pi0Eta = -log(tan(pi0Theta/2.));
< 					
< 	  float xCluster2 = rECal*cos(phiCluster2);
< 	  float yCluster2 = rECal*sin(phiCluster2);
< 	  float zCluster2 = rECal/tan(clust2Theta);
< 					
< 	  float dSeparationSquared = (xCluster2 - xCluster1)*(xCluster2- xCluster1) +
< 	    (yCluster2 - yCluster1)*(yCluster2- yCluster1) +
< 	    (zCluster2 - zCluster1)*(zCluster2- zCluster1);
< 					
< 	  if(dSeparationSquared < minimumSeparationSquared) {
< 	    continue;
< 	  } // check for passing absolute minimum separation cut
< 					
< 	  if(usePtDependentSeparation && pi0Pt > 0.0 ) {
< 	    // Parameterization result is in cm, but need meters for checking
< 	    double predictedMinimumDistance = 0.01*rescaleSeparationFactor*(aSeparationCoefficient/pi0Pt + bSeparationCoefficient/(pi0Pt*pi0Pt));
< 	    if(dSeparationSquared < predictedMinimumDistance*predictedMinimumDistance) {
< 	      countSeparationPtCut++;
< 	      continue;
< 	    } // check for passing pT dependent separation cut
< 	  }
< 					
< 	  float pi0Energy = enrCluster1 + enrCluster2;
< 	  float combinedEventPi0Mass = sqrt(pi0Energy*pi0Energy - totalMomentum*totalMomentum);	  
< 					
< 	  if(useClusterEnergyAsymmetryCut && combinedEventPi0Mass < maximumPi0MassForHistogram) {  // asymmetry cut for pi0 mass only
< 	    float clusterEnergySum = enrCluster2 + enrCluster1;
< 						
< 	    if(clusterEnergySum <= 0.0) {
< 	      cerr << "\n Reconstruction error, cluster energy sum = " << clusterEnergySum;
< 	      cerr << "\n  Cluster1 energy = " <<  enrCluster1;
< 	      cerr << "\n  Cluster2 energy = " <<  enrCluster2;
---
> 	  
> 	  for(int jCluster2=0; jCluster2<previousAcceptedNumber; jCluster2++) {//=============loop over clusters in kbuffer==
> 	    
> 	    Long64_t previousEvent = acceptedClusterInformationArray[kBuffer][jCluster2].thisEvent;
> 	    if(previousEvent == currentEvent && !sameEventCheck) {
> 	      cerr << "\n Programming error: trying to mix clusters with the same event number " << currentEvent;
> 	      cerr << ",  kBuffer = " << kBuffer << ", clusters in previous event " << previousAcceptedNumber;
> 	      for(unsigned int jBuffer=0; jBuffer<bufferDepth; jBuffer++) {
> 		cout << "\n jBuffer " << jBuffer << ",  eventNumber " << eventNumberCluster[jBuffer];
> 		cout << ", clusters in event " << countAcceptedCluster[jBuffer];
> 	      }
1560,1564d1061
< 	    } // safety check on cluster energy sum
< 	    float clusterEnergyAsymmetry = fabs(enrCluster2 - enrCluster1)/clusterEnergySum;
< 	    if(clusterEnergyAsymmetry >  clusterEnergyAsymmetryCut) {
< 							
< 	      continue;  // skip this combination
1566,1641c1063,1173
< 						
< 	  } // check on using cluster energy asymmetry cut
< 					
< 	  double cosOpenAngle = cos(clust1Theta)*cos(clust2Theta) + sin(clust1Theta)*sin(clust2Theta)*cos(phiCluster2 - phiCluster1);
< 	  float openAngle = acos(cosOpenAngle);
< 					
< 	  if(combinedEventPi0Mass > 0.0 && combinedEventPi0Mass < maximumPi0MassForHistogram) {
< 						
< 	    // Checks for combinations in the pi0 mass range
< 						
< 	    bool failOpeningAngleCut = false;
< 	    if(useFixedOpeningAngleCut)
< 	      failOpeningAngleCut = true;
< 						
< 	    if(useFixedOpeningAngleCut) {
< 							
< 	      // opening angle cut according to pT-Dependent parameterization
< 							
< 	      float pTDependentOpenAngleCut = aOpenAngleCutParameter/pi0Pt + bOpenAngleCutParameter/(pi0Pt*pi0Pt);
< 	      if(openAngle > pTDependentOpenAngleCut)
< 		failOpeningAngleCut = false;
< 	    } // check on using pT-dependent opening angle parameterization
< 						
< 	    if(failOpeningAngleCut) {
< 	      continue; // skip this combination
< 	    } // check on passing opening angle cut, either same-event or mixed-event
< 						
< 	  }// check on being  inside pi0 mass histogram region 
< 					
< 	  if(pi0Pt < lowPtCut || pi0Pt > highPtCut)
< 	    continue;
< 	  if(pi0Eta <= lowEtaLimit || pi0Eta >= highEtaLimit)
< 	    continue;
< 					
< 	  if(combinedEventPi0Mass > 0.0 && combinedEventPi0Mass < maximumPi0MassForHistogram) {
< 	    if(sameEventCheck) {
< 	      pi0MassHistSameEvent->Fill(combinedEventPi0Mass);
< 	      pi0PhiTrueHist->Fill(pi0Phi);
< 	      pi0EtaTrueHist->Fill(pi0Eta);
< 							
< 	      char histogramName1[200];
< 	      char histogramName2[200];
< 	      for(int kPt=0; kPt<bins1; kPt++) {
< 		if(pi0Pt > NptBins_[kPt] && pi0Pt <= NptBins_[kPt+1])
< 		  {
< 		    sprintf(histogramName1, "pi0MassSameEventPtBin%d", kPt);
< 		    pi0MassHistSameEventvsPt[histogramName1]->Fill(combinedEventPi0Mass);
< 		    sprintf(histogramName2, "pi0pT%d", kPt);
< 		    pi0MeanPt[histogramName2]->Fill(pi0Pt);
< 		    if(printPairContributors && kPt == 0 && countPairContributors_ < 2000 && combinedEventPi0Mass < 0.30 && 
< 		       tHighPurityTracks_ >= 120 && tHighPurityTracks_ <150) {
< 		      countPairContributors_++;
< 		      cout << "\n " << countPairContributors_ << ") ";
< 		      cout << " Cluster1 = " << acceptedClusterInformationArray[kBuffer][jCluster1].kCluster;;
< 		      cout << ", with energy = " << enrCluster1;
< 		      cout << ";  Cluster2 = " << acceptedClusterInformationArray[kBuffer][jCluster2].kCluster;; ;
< 		      cout << ", with energy = " << enrCluster2;
< 		      cout << "; pair mass = " << combinedEventPi0Mass;
< 		      cout << ", with pT = " << pi0Pt;
< 		      cout << ", in event = " << currentEvent;
< 		      cout << "    [printContributors]";
< 		    } // check on printout
< 		    break;
< 		  } // check on pT bin
< 	      } // loop over pT bins
< 							
< 	      if(combinedEventPi0Mass >= lowInvMassCut_ && combinedEventPi0Mass < highInvMassCut_) {
< 		//Used to calculate the correlation function from the side-band
< 		_pi0Spectrum->Fill(pi0Eta, pi0Pt, occ);
< 		pi0PtTrueHist->Fill(pi0Pt);
< 
< 		if(pi0HadronCorrelations_) {
< 		  TVector3 pvectorPi0;
< 		  pvectorPi0.SetPtEtaPhi(pi0Pt,pi0Eta,pi0Phi);
< 		  pVect_trg.push_back(pvectorPi0);
< 		}
---
> 	    
> 	    if(sameEventCheck && jCluster2<=jCluster1)
> 	      continue;
> 	    
> 	    if(sameEventCheck)
> 	      countSameEvents++;
> 	    
> 	    countMixedClusterExamined++;
> 	    
> 	    float ptCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustPt;
> 	    float etaCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustEta;
> 	    float enrCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustEnr;
> 	    float phiCluster2 = acceptedClusterInformationArray[kBuffer][jCluster2].clustPhi;
> 	    
> 	    float p2x = ptCluster2*cos(phiCluster2);
> 	    float p2y = ptCluster2*sin(phiCluster2);
> 	    float p2z = enrCluster2*cos(2.0*atan(exp(-etaCluster2)));
> 	    double clust2Theta = 2.0*atan(exp(-etaCluster2));
> 	    
> 	    float pxsum = p1x + p2x;
> 	    float pysum = p1y + p2y;
> 	    float pi0Pt = sqrt(pxsum*pxsum + pysum*pysum);
> 
> 	    int nCryClu2 = nCryClu[jCluster2];
> 	    //                                                                                                                    
> 	    // Check for cluster crystal limits                                                                                   
> 	    //                                                                                                                    
> 	    if(useClusterCrystalLimit_ && useClusterCrystalLimitLowPtOnly_  && pi0Pt < clusterCrystalLimitLowPtOnly_ &&
> 	       (nCryClu1 < lowCrystalLimit_ || nCryClu1 > highCrystalLimit_ ||
> 		nCryClu2 < lowCrystalLimit_ || nCryClu2 > highCrystalLimit_))
> 	      continue; // reject this pair because of the cluster crystal limits check  	    
> 	    
> 	    float pi0Phi = atan2(pysum, pxsum); 
> 	    float pzsum = p1z + p2z;
> 	    float totalMomentum = sqrt(pi0Pt*pi0Pt + pzsum*pzsum);
> 	    float pi0Theta = acos(pzsum/totalMomentum);
> 	    float pi0Eta = -log(tan(pi0Theta/2.));
> 	    
> 	    float xCluster2 = rECal*cos(phiCluster2);
> 	    float yCluster2 = rECal*sin(phiCluster2);
> 	    float zCluster2 = rECal/tan(clust2Theta);
> 	    
> 	    float dSeparationSquared = (xCluster2 - xCluster1)*(xCluster2- xCluster1) +
> 	      (yCluster2 - yCluster1)*(yCluster2- yCluster1) +
> 	      (zCluster2 - zCluster1)*(zCluster2- zCluster1);
> 	    
> 	    if(dSeparationSquared < minimumSeparationSquared) {
> 	      continue;
> 	    } // check for passing absolute minimum separation cut
> 	    
> 	    if(usePtDependentSeparation && pi0Pt > 0.0 ) {
> 	      // Parameterization result is in cm, but need meters for checking
> 	      double predictedMinimumDistance = 0.01*rescaleSeparationFactor*(aSeparationCoefficient/pi0Pt + bSeparationCoefficient/(pi0Pt*pi0Pt));
> 	      if(dSeparationSquared < predictedMinimumDistance*predictedMinimumDistance) {
> 		countSeparationPtCut++;
> 		continue;
> 	      } // check for passing pT dependent separation cut
> 	    }
> 	    
> 	    float pi0Energy = enrCluster1 + enrCluster2;
> 	    float combinedEventPi0Mass = sqrt(pi0Energy*pi0Energy - totalMomentum*totalMomentum);
> 	    
> 	    if(useClusterEnergyAsymmetryCut && combinedEventPi0Mass < maximumPi0MassForHistogram) {  // asymmetry cut for pi0 mass only
> 	      float clusterEnergySum = enrCluster2 + enrCluster1;
> 	      
> 	      if(clusterEnergySum <= 0.0) {
> 		cerr << "\n Reconstruction error, cluster energy sum = " << clusterEnergySum;
> 		cerr << "\n  Cluster1 energy = " <<  enrCluster1;
> 		cerr << "\n  Cluster2 energy = " <<  enrCluster2;
> 		cerr << endl;
> 		return;
> 	      } // safety check on cluster energy sum
> 	      float clusterEnergyAsymmetry = fabs(enrCluster2 - enrCluster1)/clusterEnergySum;
> 	      if(clusterEnergyAsymmetry >  clusterEnergyAsymmetryCut) {
> 		
> 		continue;  // skip this combination
> 	      }
> 	      
> 	    } // check on using cluster energy asymmetry cut
> 	    
> 	    
> 	    double cosOpenAngle = cos(clust1Theta)*cos(clust2Theta) + sin(clust1Theta)*sin(clust2Theta)*cos(phiCluster2 - phiCluster1);
> 	    float openAngle = acos(cosOpenAngle);
> 	    
> 	    if(combinedEventPi0Mass > 0.0 && combinedEventPi0Mass < maximumPi0MassForHistogram) {
> 	      
> 	      // Checks for combinations in the pi0 mass range
> 	      
> 	      bool failOpeningAngleCut = false;
> 	      if(useFixedOpeningAngleCut)
> 		failOpeningAngleCut = true;
> 	      
> 	      if(useFixedOpeningAngleCut) {
> 		
> 		// opening angle cut according to pT-Dependent parameterization
> 		
> 		float pTDependentOpenAngleCut = aOpenAngleCutParameter/pi0Pt + bOpenAngleCutParameter/(pi0Pt*pi0Pt);
> 		if(openAngle > pTDependentOpenAngleCut)
> 		  failOpeningAngleCut = false;
> 	      } // check on using pT-dependent opening angle parameterization
> 	      
> 	      if(failOpeningAngleCut) {
> 		continue; // skip this combination
> 	      } // check on passing opening angle cut, either same-event or mixed-event
> 	      
> 	    }// check on being  inside pi0 mass histogram region 
> 	    
> 	    if(pi0Pt < lowpi0PtCut_ || pi0Pt > highpi0PtCut_)
> 	      continue;
> 	    if(pi0Eta <= lowEtaLimit || pi0Eta >= highEtaLimit)
> 	      continue;
1642a1175,1225
> 	    double effpi0 = effhisto_pi0->GetBinContent(effhisto_pi0->FindBin(pi0Pt,pi0Eta));
> 	    
> 	    if(combinedEventPi0Mass > 0.0 && combinedEventPi0Mass < maximumPi0MassForHistogram) {
> 	      if(sameEventCheck) {
> 		pi0MassHistSameEvent->Fill(combinedEventPi0Mass);
> 		pi0PhiTrueHist->Fill(pi0Phi);
> 		pi0EtaTrueHist->Fill(pi0Eta,1.0/effpi0);
> 		
> 		char histogramName1[200];
> 		char histogramName2[200];
> 		for(int kPt=0; kPt<bins1; kPt++) {
> 		  if(pi0Pt > NptBins_[kPt] && pi0Pt <= NptBins_[kPt+1])
> 		    {
> 		      sprintf(histogramName1, "pi0MassSameEventPtBin%d", kPt);
> 		      pi0MassHistSameEventvsPt[histogramName1]->Fill(combinedEventPi0Mass);
> 		      sprintf(histogramName2, "pi0pT%d", kPt);
> 		      pi0MeanPt[histogramName2]->Fill(pi0Pt,1.0/effpi0);
> 		    }
> 		}
> 	       
> 		//		if(combinedEventPi0Mass >=0.10 && combinedEventPi0Mass <= 0.17) {
> 		if(combinedEventPi0Mass >=0.90 && combinedEventPi0Mass <= 0.18) {
> 		//		if(combinedEventPi0Mass >=0.03 && combinedEventPi0Mass < 0.09) {
> 		//		if(combinedEventPi0Mass >=0.18 && combinedEventPi0Mass < 0.24) {
> 		//		if(combinedEventPi0Mass >=0.22 && combinedEventPi0Mass < 0.28) {
> 		  //Used to calculate the correlation function from the side-band
> 		  _pi0Spectrum->Fill(pi0Eta, pi0Pt, occ);
> 		  pi0PtTrueHist->Fill(pi0Pt);
> 		  		  
> 		  if(pi0HadronCorrelations_) {
> 		    TVector3 pvectorPi0;
> 		    pvectorPi0.SetPtEtaPhi(pi0Pt,pi0Eta,pi0Phi);
> 		    pVect_trg.push_back(pvectorPi0);
> 		  }
> 		  
> 		  ///// For di-pion correlations //////
> 		  /*		TVector3 pvector;
> 		    pvector.SetPtEtaPhi(pi0Pt,pi0Eta,pi0Phi);
> 		    
> 		    if(pi0Eta<=etaMax_ass_ && pi0Eta>=etaMin_ass_
> 		    && pi0Pt<=ptMax_ass_ && pi0Pt>=ptMin_ass_)
> 		    {
> 		    pVect_ass.push_back(pvector);
> 		    tPt_->Fill(pi0Pt);
> 		    tEta_->Fill(pi0Eta);
> 		    tPhi_->Fill(pi0Phi);
> 		    }*/
> 		  /////////////////////////////////////
> 		  
> 		}
> 		
1650,1907d1232
< 	      
< 	      } // check the invariant mass window
< 							
< 	    } // same event check
< 	    else {
< 							
< 	      pi0MassHistMixed->Fill(combinedEventPi0Mass);
< 							
< 	      char histogramName3[200];
< 	      for(int kPt=0; kPt<bins1; kPt++) {
< 		if(pi0Pt > NptBins_[kPt] && pi0Pt <= NptBins_[kPt+1])
< 		  {
< 		    sprintf(histogramName3, "pi0MassMixedEventPtBin%d", kPt);
< 		    pi0MassHistMixedEventvsPt[histogramName3]->Fill(combinedEventPi0Mass);
< 		  }
< 	      } // loop over pT bins
< 							
< 	    } // check for mixed event mode
< 	  } // check histogram mass window
< 					
< 	} // loop over previous event clusters
< 				
<       } // loop over event buffer
< 			
<     } // loop over current clusters
<     if(printPairContributors) {
<       cout << endl;
<     }
< 		
<     currentBufferEventIndexCluster++;
<     if(currentBufferEventIndexCluster == bufferDepth)
<       currentBufferEventIndexCluster = 0;  // roll back to the start of the buffer for filling with the next event
< 		
<     if(currentBufferEventIndexCluster >= bufferDepth) {
<       cerr << "\n Programming error: attempting to set an index beyond the event limit in the buffer";
<       cerr << endl;
<       return;
<     }
< 		
<   } //// check for minimum number of clusters in this event
< 	
<   /////// Finally for pi0-hadron correlations //////////////////
< 
<   /////// Calculating the reco signal first, within the event loop ////////////////
< 	
<   int nMult_trg = (int)pVect_trg.size();
<   int nMult_ass = (int)pVect_ass.size();
< 	
<   for(int ntrg=0; ntrg<nMult_trg; ++ntrg) // loop over the pi0
<     {
<       TVector3 pvector_trg = (pVect_trg)[ntrg];
<       double eta_trg = pvector_trg.Eta();
<       double phi_trg = pvector_trg.Phi();
<       double pt_trg = pvector_trg.Pt(); //correction
< 	
<       for(int nass=0; nass<nMult_ass; nass++) // loop over the charged particles
< 	{
< 	  TVector3 pvector_ass = (pVect_ass)[nass];
< 	  double eta_ass = pvector_ass.Eta();
< 	  double phi_ass = pvector_ass.Phi();
< 
< 	  double deltaEta = eta_ass - eta_trg;
< 	  //
< 	  // How does this code different from the standard CMS function for Delta-Phi?
< 	  //
< 	  double deltaPhi = phi_ass - phi_trg;
< 	  if(deltaPhi > M_PI) deltaPhi = deltaPhi - 2*M_PI;
< 	  if(deltaPhi < -M_PI) deltaPhi = deltaPhi + 2*M_PI;
< 	  if(deltaPhi > -M_PI && deltaPhi < -M_PI/2.0) deltaPhi = deltaPhi + 2*M_PI;
< 			
< 	  // deltaPhi values > 4 are being computed ??
< 
< 	  if(deltaEta == 0 && deltaPhi == 0) continue;
< 
< 	  //
< 	  // Monika's hSignal histogram filling
< 	  //
< 
< 	  if(pi0HadronCorrelations_ || etaHadronCorrelations_) {
< 	    char histogramName5[200];
< 	    for(int kPt=0; kPt<bins1; kPt++) {
< 	      if(pt_trg > NptBins_[kPt] && pt_trg <= NptBins_[kPt+1]) //correction
< 		{
< 
< 		  sprintf(histogramName5, "hSignalPtBin%d", kPt);
< 		  hSignal[histogramName5]->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hSignal[histogramName5]->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hSignal[histogramName5]->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hSignal[histogramName5]->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hSignal[histogramName5]->Fill(fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hSignal[histogramName5]->Fill(-fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg); 
< 
< 		  break; // no need to check remaining pT bins
< 
< 		} // check pt_trg
< 
< 	    } // loop over pT bins
< 
< 	  } // check pi0HadronCorrelations or etaHadronCorrelations
< 
< 	  if(diHadronCorrelations_) {
< 	    hSignal1->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hSignal1->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hSignal1->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hSignal1->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hSignal1->Fill(fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hSignal1->Fill(-fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg); 
< 	  } // check diHadronCorrelations
< 
< 	} // Loop over nass		
< 			
<     } // loop over ntrg
<   pVectVect_trg.push_back(pVect_trg);
<   pVectVect_ass.push_back(pVect_ass);
<   zvtxVect.push_back(zVertexEventSelected); 
< 
<   /// mc truth
<   bool isMC = !iEvent.isRealData();
< 	
<   // get MC info from hiGenParticleCandidates, change to genParticles for pPb 2013 analysis 
<   Handle<GenParticleCollection> genParticles;
<   if(isMC) iEvent.getByLabel("genParticles", genParticles);
< 
<   if(isMC) {
<    for(size_t i=0; i<genParticles->size(); i++) {
< 			
<      const GenParticle & p = (*genParticles)[i];
<      int thisPdgId = p.pdgId();
<      float thisEta = p.eta();
<      float thisPt = p.pt();
<      float thisPhi = p.phi();
< 
<      bool allowedChargedParticle = false;
<      if(thisPt >= ptMin_ass_ && thisPt <= ptMax_ass_ && fabs(thisEta) < 2.4) {
<        allowedChargedParticle = thisPdgId==211 || thisPdgId==-211 || thisPdgId==321 || thisPdgId==-321 || thisPdgId==2212 || thisPdgId==-2212;
<      }
<      if(allowedChargedParticle) { // storing allowed charged particles
<        //
<        // Store kinematics of this generator charged particle
<        //
<        TVector3 pvectorCharge;
<        pvectorCharge.SetPtEtaPhi(thisPt, thisEta, thisPhi);
<        pGenVect_ass.push_back(pvectorCharge);
<      } // check for allowed charged particles
< 
<      if(thisPdgId == 111 && fabs(thisEta)<1.49 && thisPt >= ptMin_trg_ && thisPt <= ptMax_trg_) { // check for pi0
<        TVector3 pvectorPi0;
<        pvectorPi0.SetPtEtaPhi(thisPt, thisEta, thisPhi);
<        pGenVect_trg.push_back(pvectorPi0);
<      } // check for pi0
< 
<    } // loop over generator particles
<   } // check isMc
< 
<   // Now the generator signal
< 	
<   nMult_trg = (int)pGenVect_trg.size();
<   nMult_ass = (int)pGenVect_ass.size();
< 		
<   for(int ntrg=0; ntrg<nMult_trg; ++ntrg) // loop over the pi0
<     {
<       TVector3 pvector_trg = (pGenVect_trg)[ntrg];
<       double eta_trg = pvector_trg.Eta();
<       double phi_trg = pvector_trg.Phi();
<       double pt_trg = pvector_trg.Pt(); //correction
< 				
<       for(int nass=0; nass<nMult_ass; nass++) // loop over the charged particles
< 	{
< 	  TVector3 pvector_ass = (pGenVect_ass)[nass];
< 	  double eta_ass = pvector_ass.Eta();
< 	  double phi_ass = pvector_ass.Phi();
< 		
< 	  double deltaEta = eta_ass - eta_trg;
< 
< 	  //
< 	  // How does this code different from the standard CMS function for Delta-Phi?
< 	  //
< 	  double deltaPhi = phi_ass - phi_trg;
< 	  if(deltaPhi > M_PI) deltaPhi = deltaPhi - 2*M_PI;
< 	  if(deltaPhi < -M_PI) deltaPhi = deltaPhi + 2*M_PI;
< 	  if(deltaPhi > -M_PI && deltaPhi < -M_PI/2.0) deltaPhi = deltaPhi + 2*M_PI;
< 
< 	  // deltaPhi values > 4 are being computed ??
< 	  // cout << "\n nass " << nass << " eta " << eta_ass << " phi " << phi_ass << " deltaEta " << deltaEta << " deltaPhi " << deltaPhi << endl;
< 			
< 	  if(deltaEta == 0 && deltaPhi == 0) continue;
< 
< 	  //
< 	  // Monika's hSignal histogram filling
< 	  //
< 
< 	  if(pi0HadronCorrelations_ || etaHadronCorrelations_) {
< 	    char histogramName5[200];
< 	    for(int kPt=0; kPt<bins1; kPt++) {
< 	      if(pt_trg > NptBins_[kPt] && pt_trg <= NptBins_[kPt+1]) //correction
< 		{
< 
< 		  sprintf(histogramName5, "hGenSignalPtBin%d", kPt);
< 
< 		  hGenSignal[histogramName5]->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hGenSignal[histogramName5]->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hGenSignal[histogramName5]->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hGenSignal[histogramName5]->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hGenSignal[histogramName5]->Fill(fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 		  hGenSignal[histogramName5]->Fill(-fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg); 
< 
< 		  break;  // no need to check the remaining pT bins
< 
< 		} // check pt_trg
< 
< 	    } // loop over pT bins
< 
< 	  } // check pi0HadronCorrelations or etaHadronCorrelations
< 
< 	  if(diHadronCorrelations_) {
< 	    hGenSignal1->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hGenSignal1->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hGenSignal1->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hGenSignal1->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hGenSignal1->Fill(fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg);
< 	    hGenSignal1->Fill(-fabs(deltaEta),2*M_PI-fabs(deltaPhi),1.0/4.0/nMult_trg); 
< 	  } // check diHadronCorrelations
< 
< 	} // Loop over nass		
< 			
<     } // loop over ntrg
<   
<   pGenVectVect_trg.push_back(pGenVect_trg);
<   pGenVectVect_ass.push_back(pGenVect_ass);
< 	
<   ///////////////////////////////////////////////////////////////////////////
< 	
< 	
<   // get GEANT sim tracks and vertices (includes conversions)
<   Handle<SimTrackContainer> simTracks_h;
<   const SimTrackContainer* simTracks;
<   if( isMC ) iEvent.getByLabel("g4SimHits", simTracks_h);
<   simTracks = (simTracks_h.isValid()) ? simTracks_h.product() : 0;
< 	
<   Handle<SimVertexContainer> simVert_h;
<   const SimVertexContainer* simVertices;
<   if( isMC ) iEvent.getByLabel("g4SimHits", simVert_h);
<   simVertices = (simVert_h.isValid()) ? simVert_h.product() : 0;
<   nSimTracks = 1;
< 
<   mergedTrackTruthSize = 1;
<   kMerge[0] = -1;
<   numberDecayVerticesMerge[0] = -1;
<   pdgIdMerge[0] = -1;
< 	
<   if( isMC ) 
<     {
< 		
<       size_t simTracksSize = -2;
<       if(simTracks)
< 	simTracksSize =  simTracks_h->size();
< 		
<       nSimTracks = simTracksSize;
1909,1921c1234,1235
<       size_t simVerticesSize = -2;
<       if(simVertices)
< 	simVerticesSize = simVert_h->size();
< 		
<       genSize = genParticles->size();
< 		
<       Handle<TrackingParticleCollection> mergedTrackTruth;
<       int mergedTrackTruthSizeOriginal = 0;
<       if(mergedTrackTruthStore_) {
< 	iEvent.getByLabel("mergedtruth", "MergedTrackTruth", mergedTrackTruth);
< 	mergedTrackTruthSizeOriginal = mergedTrackTruth->size();
<       }
<       mergedTrackTruthSize = mergedTrackTruthSizeOriginal;
---
> 	      } // same event check
> 	      else {
1923,1942c1237
<       if(mergedTrackTruthSize > 0 && mergedTrackTruthStore_) {
< 	int countTrueTrack = 0;
< 			
< 	for (TrackingParticleCollection::const_iterator iTrack = mergedTrackTruth->begin(); iTrack!=mergedTrackTruth->end(); ++iTrack) {
< 				
< 	  int thisPdgId = iTrack->pdgId();
< 	  bool allowedParticle = false;
< 	  allowedParticle = thisPdgId==22 || thisPdgId==130 || thisPdgId==310 || thisPdgId==111 || thisPdgId==311;
< 	  if(!allowedParticle)
< 	    continue;
< 				
< 	  kMerge[countTrueTrack] = countTrueTrack;
< 	  numberDecayVerticesMerge[countTrueTrack] = (iTrack->decayVertices()).size();
< 	  pdgIdMerge[countTrueTrack] = thisPdgId;
< 	  numberEarlyDecayMerge[countTrueTrack] = 0;
< 				
< 	  xDecayVertexMerge[countTrueTrack] = 0.0;
< 	  yDecayVertexMerge[countTrueTrack] = 0.0;
< 	  rDecayVertexMerge[countTrueTrack] = 0.0;
< 	  zDecayVertexMerge[countTrueTrack] = 0.0;
---
> 		pi0MassHistMixed->Fill(combinedEventPi0Mass);
1944,2081c1239,1245
< 	  if(numberDecayVerticesMerge[countTrueTrack] > 0) {
< 	    bool decayVertexLimit = false;
< 	    for (TrackingVertexContainer::const_iterator iTV = (iTrack->decayVertices()).begin(); iTV != (iTrack->decayVertices()).end(); ++iTV) {
< 						
< 	      // float rDecayVertex = ((**iTV).position()).R();  // This is sqrt(x*x + y*y + z*z)
< 	      float xDecayVertex = ((**iTV).position()).X();
< 	      float yDecayVertex = ((**iTV).position()).Y();
< 	      float rDecayVertex = sqrt(xDecayVertex*xDecayVertex + yDecayVertex*yDecayVertex);
< 	      float zDecayVertex = ((**iTV).position()).Z();
< 
< 	      // cout << "\n    True track count " << countTrueTrack;
< 	      // cout << "\n    Number decay vertices " << numberDecayVerticesMerge[countTrueTrack];
< 	      // cout << "\n    Decay vertex R " << rDecayVertex << ", decay vertex Z " << zDecayVertex; 
< 						
< 	      if( rDecayVertex < 129. && fabs(zDecayVertex) < 304.) {
< 							
< 		numberEarlyDecayMerge[countTrueTrack] += 1;
< 							
< 		xDecayVertexMerge[countTrueTrack] = xDecayVertex;
< 		yDecayVertexMerge[countTrueTrack] = yDecayVertex;
< 		rDecayVertexMerge[countTrueTrack] = rDecayVertex;
< 		zDecayVertexMerge[countTrueTrack] = zDecayVertex;
< 							
< 		decayVertexLimit = true;
< 							
< 	      } // check on early decay vertex
< 						
< 	      if(decayVertexLimit)
< 		break;
< 						
< 	    } // loop over decay vertices
< 	  } // check for non-zero number of decay vertices
< 				
< 	  const TrackingVertexRef& trackVertex = iTrack->parentVertex(); // returns a TLorentz Vector object
< 	  double xParentVertex = (trackVertex->position()).X();
< 	  double yParentVertex = (trackVertex->position()).Y();
< 	  double rParentVertex = sqrt(xParentVertex*xParentVertex + yParentVertex*yParentVertex);
< 	  double zParentVertex = (trackVertex->position()).Z();
< 				
< 	  xParentVertexMerge[countTrueTrack] = xParentVertex;
< 	  yParentVertexMerge[countTrueTrack] = yParentVertex;
< 	  rParentVertexMerge[countTrueTrack] = rParentVertex;
< 	  zParentVertexMerge[countTrueTrack] = zParentVertex;
< 				
< 	  if(fabs(rParentVertexMerge[countTrueTrack] - rPrimaryVertex) < rPrimaryCut &&
< 	     fabs(zParentVertexMerge[countTrueTrack] - zPrimaryVertex) < zPrimaryCut) {
< 	    primaryTrackMerge[countTrueTrack] = 1;
< 	  }
< 	  else {
< 	    primaryTrackMerge[countTrueTrack] = 0;
< 	  }
< 				
< 	  double xMomentum = ((*iTrack).momentum()).X();
< 	  double yMomentum = ((*iTrack).momentum()).Y();
< 	  double zMomentum = ((*iTrack).momentum()).Z();
< 	  double phi = atan2(yMomentum, xMomentum);
< 	  double totalMomentum = iTrack->p();
< 				
< 	  double theta = acos(zMomentum/totalMomentum);
< 	  double eta = -log(tan(theta/2.));
< 	  double pt = totalMomentum*sin(theta);
< 				
< 	  if(primaryTrackMerge[countTrueTrack] == 1 && 
< 	     ((eta < -etaCutForMerge || eta > etaCutForMerge) ||
< 	      ((*iTrack).charge() !=0 && pt < ptCutForMerge))) {
< 	    continue;  // this skips the increment of the countTrueTrack variable for primary particles outside of the etaCutForMerge or ptCutForMerge windows;
< 	  }
< 				
< 	  bestEcalAngleMatch[countTrueTrack] = -999.0;
< 	  bestEcalSeedTimeMatch[countTrueTrack] = -999.0;
< 	  bestEcalPhiMatch[countTrueTrack] = 0.0;
< 	  bestEcalDPhiMatch[countTrueTrack] = 0.0;
< 	  bestEcalDEtaMatch[countTrueTrack] = 0.0;
< 	  bestEcalPtMatch[countTrueTrack] = 0.0;
< 				
< 	  ptMerge[countTrueTrack] = pt;
< 	  etaMerge[countTrueTrack] = eta;
< 	  phiMerge[countTrueTrack] = phi;
< 				
< 	  float bestAngleMatch = 999.0;
< 	  float bestPtMatch = 0.0;
< 	  float bestEtaMatch = 0.0;
< 	  float bestPhiMatch = 0.0;
< 	  int bestPdgIdMatch = -1;
< 	  int bestGenIndexMatch = -1;
< 				
< 	  if(primaryTrackMerge[countTrueTrack] == 1) {
< 					
< 	    //
< 	    // Search for genParticle match, according to momentum
< 	    //
< 	    for(size_t i=0; i<genParticles->size(); i++) {
< 						
< 	      const GenParticle & p = (*genParticles)[i];
< 						
< 	      float ptGen = p.pt();
< 	      float etaGen = p.eta();
< 	      float phiGen = p.phi();
< 	      if(fabs(pt - ptGen)/ptGen < ptPrimaryCut) {
< 		float testAngleMatch = sqrt((etaGen - eta)*(etaGen - eta) + (phiGen - phi)*(phiGen - phi));
< 		if(testAngleMatch < bestAngleMatch) {
< 		  bestAngleMatch = testAngleMatch;
< 		  bestEtaMatch = etaGen;
< 		  bestPhiMatch = phiGen;
< 		  bestPtMatch = ptGen;
< 		  bestPdgIdMatch = p.pdgId();
< 		  bestAngleMatch = testAngleMatch;
< 		  bestGenIndexMatch = i;
< 		} // check for better angle match
< 	      } // check for good momentum match
< 						
< 	    } // loop over generator particles
< 	    //
< 	    // Search for matches of unconverted primary photons to ECAL, using Delta-Phi and Delta-Eta
< 	    //
< 	    if(pdgIdMerge[countTrueTrack] == 22) { // check for photon, already have selected primary particles
< 	      double bestEAngleMatch = 999.0;
< 	      double bestEPhiMatch = 0.0;
< 	      double bestEDPhiMatch = 0.0;
< 	      double bestEDEtaMatch = 0.0;
< 	      double bestEPtMatch = 0.0;
< 	      double bestESeedTimeMatch = -999.0;
< 	      int bestEIndexMatch = -1;
< 	      //
< 	      // Check for best cluster match
< 	      //
< 	      for(int jClu=0; jClu<nClu; jClu++) {
< 		double phiDelta = deltaPhi(phiClu[jClu], phi);
< 		double etaDelta = etaClu[jClu] - eta;
< 		double testMatch = sqrt(phiDelta*phiDelta + etaDelta*etaDelta);
< 		if(testMatch < bestEAngleMatch) {
< 		  bestEAngleMatch = testMatch;
< 		  bestEPhiMatch = phiClu[jClu];
< 		  bestEDPhiMatch = phiDelta;
< 		  bestEDEtaMatch = etaDelta;
< 		  bestEPtMatch = ptClu[jClu];
< 		  bestESeedTimeMatch = seedTimeClu[jClu];
< 		  bestEIndexMatch = jClu;
---
> 		char histogramName3[200];
> 		for(int kPt=0; kPt<bins1; kPt++) {
> 		  if(pi0Pt > NptBins_[kPt] && pi0Pt <= NptBins_[kPt+1])
> 		    {
> 		      sprintf(histogramName3, "pi0MassMixedEventPtBin%d", kPt);
> 		      pi0MassHistMixedEventvsPt[histogramName3]->Fill(combinedEventPi0Mass);
> 		    }
2083,2111d1246
< 	      } // loop over reconstructed clusters
< 						
< 	      bestEcalAngleMatch[countTrueTrack] = bestEAngleMatch;
< 	      bestEcalPhiMatch[countTrueTrack] = bestEPhiMatch;
< 	      bestEcalDPhiMatch[countTrueTrack] = bestEDPhiMatch;
< 	      bestEcalDEtaMatch[countTrueTrack] = bestEDEtaMatch;
< 	      bestEcalPtMatch[countTrueTrack] = bestEPtMatch;
< 	      bestEcalIndexMatch[countTrueTrack] = bestEIndexMatch;
< 	      bestEcalSeedTimeMatch[countTrueTrack] = bestESeedTimeMatch;
< 						
< 	    } // select photons from mergeTrackTruth
< 	  }
< 	  else {
< 	    primaryTrackMerge[countTrueTrack] = 0;
< 	  }
< 				
< 	  bestAngleMatchMerge[countTrueTrack] = bestAngleMatch;
< 	  bestPtMatchMerge[countTrueTrack] = bestPtMatch;
< 	  bestEtaMatchMerge[countTrueTrack] = bestEtaMatch;
< 	  bestPhiMatchMerge[countTrueTrack] = bestPhiMatch;
< 	  bestPdgIdMatchMerge[countTrueTrack] = bestPdgIdMatch;
< 	  bestGenIndexMatchMerge[countTrueTrack] = bestGenIndexMatch;
< 				
< 	  countTrueTrack++;
< 	} // loop over mergedTrackTruth
< 			
< 	mergedTrackTruthSize = countTrueTrack;  // this will be less than the orignal mergedTrackTruthSize because of the etaCutForMerge
< 			
<       } // check for mergedTrackTruthSize > 0
2113,2121c1248,1265
<       if(mergedTrackTruthDebug && eventn < 30) {
< 	cout << "\n For Event " << eventn;
< 	cout << " the generator has " << genSize << " particles";
< 	cout << ", and the mergedTrackTruth size is " << mergedTrackTruthSize;
< 	cout << "\n The number of HI reconstructed tracks is " << nHITracks;
< 	cout << " and the number of high purity tracks size is " << tHighPurityTracks_;
< 	cout << "\n The size of simTracks is " << simTracksSize;
< 	cout << " and the size of simVertices is " << simVerticesSize;
< 	cout << endl;
---
> 	      } // check for mixed event mode
> 	    } // check histogram mass window
> 	    
> 	  } // loop over previous event clusters
> 	  
> 	} // loop over event buffer
> 	
>       } // loop over current clusters
>    
>           
>       currentBufferEventIndexCluster++;
>       if(currentBufferEventIndexCluster == bufferDepth)
> 	currentBufferEventIndexCluster = 0;  // roll back to the start of the buffer for filling with the next event
>       
>       if(currentBufferEventIndexCluster >= bufferDepth) {
> 	cerr << "\n Programming error: attempting to set an index beyond the event limit in the buffer";
> 	cerr << endl;
> 	return;
2122a1267,1269
>       
>     }//// check for minimum number of clusters in the this event
>  
2124,2176d1270
<       // 
<       // Code to fill the charged meson part of the tree
<       //
<       int kChMesonCount = 0;
<       for(size_t i=0; i<genParticles->size(); i++) {
< 			
< 	const GenParticle & p = (*genParticles)[i];
< 	int thisPdgId = p.pdgId();
< 	float mesonEta = p.eta();
< 	float mesonPt = p.pt();
< 	bool allowedMeson = false;
< 	if(mesonPt >= ptMin_ass_ && mesonPt <=  ptMax_ass_ && fabs(mesonEta) < 2.4) {
< 	  allowedMeson = thisPdgId==211 || thisPdgId==-211 || thisPdgId==321 || thisPdgId==-321 || thisPdgId==2212 || thisPdgId==-2212;
< 	}
< 	if(allowedMeson) { // storing allowed charged mesons 
< 	  kChMeson[kChMesonCount] = kChMesonCount;
< 	  pdgIdChMeson[kChMesonCount] = thisPdgId;
< 	  statusChMeson[kChMesonCount] = p.status();
< 	  genPartIndexChMeson[kChMesonCount] = i;
< 
< 	  const Candidate *mom = p.mother();
< 	  if(mom)
< 	    motherIdChMeson[kChMesonCount] = mom->pdgId();
< 	  else
< 	    motherIdChMeson[kChMesonCount] = -1;
< 	  ptChMeson[kChMesonCount] = p.pt();
< 	  etaChMeson[kChMesonCount] = mesonEta;  
< 	  phiChMeson[kChMesonCount] = p.phi();
< 
< 	  kChMesonCount++;
< 
< 	} // check on allowed meson
< 
<       } // loop over all generated particles, check for charged particles
<       nChMesonSize = kChMesonCount; // number of accepted charged particles
<       cout << "\n nChMesonSize = " << nChMesonSize << endl;
< 
<       //
<       // Code to fill the neutral meson part of the tree
<       //
<       int kMesonCount = 0;
<       int countAllowedMesons = 0;
<       int countDisAllowedMesons = 0;
< 		
<       for(size_t i=0; i<genParticles->size(); i++) {
< 			
< 	const GenParticle & p = (*genParticles)[i];
< 	int thisPdgId = p.pdgId();
< 	float mesonEta = p.eta();
< 	bool allowedMeson = false;
< 	if(fabs(mesonEta) < 1.49) {
< 	  allowedMeson = thisPdgId==130 || thisPdgId==310 || thisPdgId==311 || thisPdgId==111 || thisPdgId==221 || thisPdgId==213 || thisPdgId==-213 || thisPdgId==223 || thisPdgId==313 || thisPdgId==-313 || thisPdgId==331;
< 	}
2178,2409c1272,1273
< 	if(!allowedMeson)
< 	  countDisAllowedMesons++;
< 	if(allowedMeson) { // storing allowed mesons 
< 	  countAllowedMesons++;
< 	  kMeson[kMesonCount] = kMesonCount;
< 	  pdgIdMeson[kMesonCount] = thisPdgId;
< 	  statusMeson[kMesonCount] = p.status();
< 	  genPartIndexMeson[kMesonCount] = i;
< 	  const Candidate *mom = p.mother();
< 	  if(mom)
< 	    motherIdMeson[kMesonCount] = mom->pdgId();
< 	  else
< 	    motherIdMeson[kMesonCount] = -1;
< 	  ptMeson[kMesonCount] = p.pt();
< 	  etaMeson[kMesonCount] = mesonEta;  
< 	  phiMeson[kMesonCount] = p.phi();
< 				
< 	  int numberOfDaughters = 0;
< 	  float ptDaughter[3];
< 	  float etaDaughter[3];
< 	  float phiDaughter[3];
< 	  int   pdgIdDaughter[3];
< 	  const GenParticleRefVector& daughterRefs = p.daughterRefVector();
< 	  for(reco::GenParticleRefVector::const_iterator idr = daughterRefs.begin(); idr!= daughterRefs.end(); ++idr) {
< 					
< 	    // cout <<"    - Daughter "<<(*idr).key()<<" "<<(*idr)->pdgId()<<endl;
< 					
< 	    if(numberOfDaughters < 3) {
< 	      ptDaughter[numberOfDaughters] = (*idr)->pt();
< 	      etaDaughter[numberOfDaughters] = (*idr)->eta();
< 	      phiDaughter[numberOfDaughters] = (*idr)->phi();
< 	      pdgIdDaughter[numberOfDaughters] = (*idr)->pdgId();
< 	    }
< 	    numberOfDaughters++;
< 	  } // loop over genParticleRefVector
< 				
< 	  //
< 	  // A reconstructed meson entry will be made when
< 	  //   a) there are two daughter photons
< 	  //   b) each daughter photon is found as a primary
< 	  //   c) both primary daughter photons do not convert
< 	  //
< 	  massRecoMeson[kMesonCount] = 0.;
< 	  ptRecoMeson[kMesonCount] = 0.;
< 	  etaRecoMeson[kMesonCount] = 0.;
< 	  phiRecoMeson[kMesonCount] = 0.;
< 	  mergeDecay1Angle[kMesonCount] = -1.0;
< 	  mergeDecay2Angle[kMesonCount] = -1.0;
< 	  mergeDecay3Angle[kMesonCount] = -1.0;
< 				
< 	  daughtersFromMeson[kMesonCount] = numberOfDaughters;
< 	  ptDecay1Meson[kMesonCount] = 0;
< 	  ptDecay2Meson[kMesonCount] = 0;
< 	  ptDecay3Meson[kMesonCount] = 0;
< 	  etaDecay1Meson[kMesonCount] = 0;
< 	  etaDecay2Meson[kMesonCount] = 0;
< 	  etaDecay3Meson[kMesonCount] = 0;
< 	  phiDecay1Meson[kMesonCount] = 0;
< 	  phiDecay2Meson[kMesonCount] = 0;
< 	  phiDecay3Meson[kMesonCount] = 0;
< 	  pdgIdDecay1Meson[kMesonCount] = 0;
< 	  convertDecay1Meson[kMesonCount] = -1;
< 	  pdgIdDecay2Meson[kMesonCount] = 0;
< 	  convertDecay2Meson[kMesonCount] = -1;
< 	  pdgIdDecay3Meson[kMesonCount] = 0;
< 	  convertDecay3Meson[kMesonCount] = -1;
< 	  //
< 	  // Known anomalies: Event 329 has nMesonSize = 2 with a 0 for mergeDecay1Meson at kMesonCount = 0?
< 	  //                  Event 159 has nMesonSize = 12 with a 0 for mergeDecay2Meson at kMesonCount = 0?
< 	  // Are all of these mergeDecay photon matches primaries?
< 	  // Some (mostly low momentum) decay photons are showing up with no mergedTrackTruth primary photon
< 	  //
< 	  //
< 	  mergeDecay1Meson[kMesonCount] = -1;
< 	  mergeDecay2Meson[kMesonCount] = -1;
< 	  mergeDecay3Meson[kMesonCount] = -1;
< 	  if(numberOfDaughters > 0) {
< 	    ptDecay1Meson[kMesonCount] = ptDaughter[0];
< 	    etaDecay1Meson[kMesonCount] = etaDaughter[0];
< 	    phiDecay1Meson[kMesonCount] = phiDaughter[0];
< 	    pdgIdDecay1Meson[kMesonCount] = pdgIdDaughter[0];
< 	    float ptTest =  ptDaughter[0];
< 	    float ptError = 0.01*ptTest;
< 	    if(ptError < 0.002)
< 	      ptError = 0.002;
< 	    float etaTest =  etaDaughter[0];
< 	    float phiTest =  phiDaughter[0];
< 	    for(int jMerge=0; jMerge<mergedTrackTruthSize; jMerge++) {
< 	      if(pdgIdMerge[jMerge] == 22) {
< 		if(fabs(ptTest - ptMerge[jMerge]) < ptError &&
< 		   fabs(etaTest - etaMerge[jMerge]) < 0.01 &&
< 		   fabs(deltaPhi(phiTest, phiMerge[jMerge])) < 0.01) {
< 		  mergeDecay1Meson[kMesonCount] = jMerge;
< 		  convertDecay1Meson[kMesonCount] =  numberDecayVerticesMerge[jMerge];
< 		} // check for analog match
< 	      }  // check on photon ID
< 	    } // loop over merge array
< 	    //
< 	    // search for this photon in the merge array (should be a primary photon)
< 	    //
< 	    if(numberOfDaughters > 1) {
< 	      ptDecay2Meson[kMesonCount] = ptDaughter[1];
< 	      etaDecay2Meson[kMesonCount] = etaDaughter[1];
< 	      phiDecay2Meson[kMesonCount] = phiDaughter[1];
< 	      pdgIdDecay2Meson[kMesonCount] = pdgIdDaughter[1];
< 	      //
< 	      // search for this photon in the merge array (should be a primary photon)
< 	      //
< 	      float ptTest =  ptDaughter[1];
< 	      float ptError = 0.01*ptTest;
< 	      if(ptError < 0.002)
< 		ptError = 0.002;
< 	      float etaTest =  etaDaughter[1];
< 	      float phiTest =  phiDaughter[1];
< 	      for(int jMerge=0; jMerge<mergedTrackTruthSize; jMerge++) {
< 		if(pdgIdMerge[jMerge] == 22) {
< 		  if(fabs(ptTest - ptMerge[jMerge]) < ptError &&
< 		     fabs(etaTest - etaMerge[jMerge]) < 0.01 &&
< 		     fabs(deltaPhi(phiTest, phiMerge[jMerge])) < 0.01) {
< 		    mergeDecay2Meson[kMesonCount] = jMerge;
< 		    convertDecay2Meson[kMesonCount] =  numberDecayVerticesMerge[jMerge];
< 		  } // check for analog match
< 		}  // check on photon ID
< 	      } // loop over merge array
< 	      if(numberOfDaughters > 2) {
< 		ptDecay3Meson[kMesonCount] = ptDaughter[2];
< 		etaDecay3Meson[kMesonCount] = etaDaughter[2];
< 		phiDecay3Meson[kMesonCount] = phiDaughter[2];
< 		pdgIdDecay3Meson[kMesonCount] = pdgIdDaughter[2];
< 		//
< 		// search for this photon in the merge array (should be a primary photon)
< 		//
< 		float ptTest = ptDaughter[2];
< 		float ptError = 0.01*ptTest;
< 		if(ptError < 0.002)
< 		  ptError = 0.002;
< 		float etaTest =  etaDaughter[2];
< 		float phiTest =  phiDaughter[2];
< 		for(int jMerge=0; jMerge<mergedTrackTruthSize; jMerge++) {
< 		  if(pdgIdMerge[jMerge] == 22) {
< 		    if(fabs(ptTest - ptMerge[jMerge]) < ptError &&
< 		       fabs(etaTest - etaMerge[jMerge]) < 0.01 &&
< 		       fabs(deltaPhi(phiTest, phiMerge[jMerge])) < 0.01) {
< 		      mergeDecay3Meson[kMesonCount] = jMerge;
< 		      convertDecay3Meson[kMesonCount] =  numberDecayVerticesMerge[jMerge];
< 		      mergeDecay3Angle[kMesonCount] = bestEcalAngleMatch[jMerge];
< 		    } // check for analog match
< 		  }  // check on photon ID
< 		} // loop over merge array
< 	      } // check if 3 or more daughters
< 	      if(numberOfDaughters == 2 && mergeDecay1Meson[kMesonCount] >= 0 && convertDecay1Meson[kMesonCount] == 0 &&
< 		 mergeDecay2Meson[kMesonCount] >= 0 && convertDecay2Meson[kMesonCount] == 0) {
< 		int jMerge1 = mergeDecay1Meson[kMesonCount];
< 		int jMerge2 = mergeDecay2Meson[kMesonCount];
< 		//
< 		// Check for a reco match to the merge photon
< 		//
< 		mergeDecay1Angle[kMesonCount] = bestEcalAngleMatch[jMerge1];
< 		mergeDecay2Angle[kMesonCount] = bestEcalAngleMatch[jMerge2];
< 		mergeDecay1Time[kMesonCount] = bestEcalSeedTimeMatch[jMerge1];
< 		mergeDecay2Time[kMesonCount] = bestEcalSeedTimeMatch[jMerge2];
< 		//
< 		// Some non-conversion matches (non-primary??) have poor bestEcalAngleMatch values ??
< 		//
< 		if(bestEcalAngleMatch[jMerge1] < 0.03 && bestEcalAngleMatch[jMerge2] < 0.03) {
< 								
< 		  float ecalEta1 = bestEcalDEtaMatch[jMerge1] + etaMerge[jMerge1];
< 		  float theta1 =  2.0*atan(exp(-ecalEta1));
< 		  float sinTheta1 = sin(theta1);
< 		  float cosTheta1 = cos(theta1);
< 		  float phi1 =  bestEcalPhiMatch[jMerge1];
< 		  float cosPhi1 = cos(phi1);
< 		  float sinPhi1 = sin(phi1);
< 		  float pt1 =  bestEcalPtMatch[jMerge1];
< 		  float energy1 = pt1/sinTheta1;
< 								
< 		  float ecalEta2 = bestEcalDEtaMatch[jMerge2] + etaMerge[jMerge2];
< 		  float theta2 =  2.0*atan(exp(-ecalEta2));
< 		  float sinTheta2 = sin(theta2);
< 		  float cosTheta2 = cos(theta2);
< 		  float phi2 =  bestEcalPhiMatch[jMerge2];
< 		  float cosPhi2 = cos(phi2);
< 		  float sinPhi2 = sin(phi2);
< 		  float pt2 = bestEcalPtMatch[jMerge2];
< 		  float energy2 = pt2/sinTheta2;
< 								
< 		  float cosOpenAngle = cosTheta1*cosTheta2 + sinTheta1*sinTheta2*cos(phi1 - phi2);
< 		  float recoMassTest = 2.0*energy1*energy2*(1.0 - cosOpenAngle);
< 		  if(recoMassTest > 0.0) {
< 									
< 		    massRecoMeson[kMesonCount] = sqrt(recoMassTest);
< 									
< 		    float px1 = pt1*cosPhi1;
< 		    float py1 = pt1*sinPhi1;
< 		    float pz1 = energy1*cosTheta1;
< 									
< 		    float px2 = pt2*cosPhi2;
< 		    float py2 = pt2*sinPhi2;
< 		    float pz2 = energy2*cosTheta2;
< 									
< 		    float pxMeson = px1 + px2;
< 		    float pyMeson = py1 + py2;
< 		    float pzMeson = pz1 + pz2;
< 									
< 		    float ptMeson = sqrt(pxMeson*pxMeson + pyMeson*pyMeson);
< 		    float momentumMeson = sqrt(ptMeson*ptMeson + pzMeson*pzMeson);
< 		    float thetaMeson = acos(pzMeson/momentumMeson);
< 									
< 		    float etaMeson = -log(tan(thetaMeson/2));
< 		    float phiMeson = atan2(pxMeson, pyMeson);
< 									
< 		    ptRecoMeson[kMesonCount] = ptMeson;
< 		    etaRecoMeson[kMesonCount] = etaMeson;
< 		    phiRecoMeson[kMesonCount] = phiMeson;
< 									
< 		  }
< 								
< 		} // check all reco-merge matches											     
< 							
< 	      } // check for only 2 daughters, a merge match, and no conversions
< 	    } // check for second daughter
< 	  } // check for first daughter
< 				
< 	  kMesonCount++;
< 	  if(kMesonCount >= MESONMAXSIZE)
< 	    break;  // safety check
< 				
< 	} // check for storing this particle in the meson tree
< 			
<       } // loop over the generator particles to store pi0 and eta-meson
< 		
<       nMesonSize = kMesonCount;
---
>     /////// Finally for pi0-hadron correlations //////////////////
>     /////// Calculating the signal first ////////////////
2411,2496c1275,1276
< 		
<       if(nMesonSize < 1)
< 	nMesonSize = 1;
< 		
<       //
<       // Code to fill the photon part of the tree
<       //
<       int kPhotonCount = 0;
<       for(size_t i=0; i<genParticles->size(); i++) {
< 			
< 	int genIndex = int(i);
< 	const GenParticle & p = (*genParticles)[i];
< 	if(p.pdgId() == 22) {
< 				
< 	  float photonEta = p.eta();
< 	  if(fabs(photonEta) < 1.5) {
< 					
< 	    float thisPt = p.pt();
< 	    float thisEta = p.eta();
< 	    float thisPhi = p.phi();
< 	    kPhotonGen[kPhotonCount] = kPhotonCount;
< 	    ptPhotonGen[kPhotonCount] = thisPt;
< 	    etaPhotonGen[kPhotonCount] = thisEta;
< 	    phiPhotonGen[kPhotonCount] = thisPhi;
< 					
< 	    //
< 	    // Check for the mother of this photon
< 	    //
< 	    if (p.numberOfMothers() > 0) {
< 	      const Candidate *mom = p.mother();
< 	      motherPdgIdPhotonGen[kPhotonCount] = mom->pdgId();
< 	      ptMotherPhotonGen[kPhotonCount] = mom->pt();
< 	    }
< 	    else {
< 	      motherPdgIdPhotonGen[kPhotonCount] = 0;
< 	      ptMotherPhotonGen[kPhotonCount] = 0.0;
< 	    }
< 	    //
< 	    // Look for this photon in the mergedTrackTruthCollection
< 	    //
< 	    mergeIndexPhotonGen[kPhotonCount] = -1;
< 	    clusterIndexPhotonGen[kPhotonCount] = -1;
< 	    convertPhotonGen[kPhotonCount] = -1;
< 	    ptRecoPhotonGen[kPhotonCount] = 0.;
< 	    etaRecoPhotonGen[kPhotonCount] = 0.;
< 	    phiRecoPhotonGen[kPhotonCount] = 0.;
< 	    angleRecoPhotonGen[kPhotonCount] = 0.;
< 	    for(int jMerge=0; jMerge<mergedTrackTruthSize; jMerge++) {
< 	      if(genIndex == bestGenIndexMatchMerge[jMerge]) {
< 		mergeIndexPhotonGen[kPhotonCount] = jMerge;
< 		int jClu =  bestEcalIndexMatch[jMerge];
< 		clusterIndexPhotonGen[kPhotonCount] = jClu;
< 		convertPhotonGen[kPhotonCount] = numberDecayVerticesMerge[jMerge];
< 		angleRecoPhotonGen[kPhotonCount] = bestEcalAngleMatch[jMerge];
< 		if(jClu >=0 && jClu < nClu) {
< 		  ptRecoPhotonGen[kPhotonCount] = ptClu[jClu];
< 		  etaRecoPhotonGen[kPhotonCount] = etaClu[jClu];
< 		  phiRecoPhotonGen[kPhotonCount] = phiClu[jClu];
< 		}
< 		break;
< 	      }
< 	    } // loop over merged track truth array
< 					
< 	    kPhotonCount++;
< 					
< 	  } // check eta of photon
< 				
< 	} // check for photon
< 			
<       } // loop over generator particles
< 		
<       nPhotonSize = kPhotonCount;
< 		
<       nMC = nSim = 0;                // nSim is never incremented for simulations? (June 24)
<       njSim = 0;
<       for(int j=0; j<nMaxMC; j++) {
< 	kMC[j] = -999;   // default to make sure that all the kMC are actually filled
<       }
<       int current_particle = -1;
<       set<int> mothers;
<       map<const GenParticle*, int> mapMC;
<       map<const GenParticle*, int>::iterator mapMC_it;
<       //int where_isM_PI0_mother(0);  //debug
<       int p_count(0);
<       int motherIDMC_temp = -1;
<       int genPartPDGArray[10000];
---
>     int nMult_trg = (int)pVect_trg.size();
>     int nMult_ass = (int)pVect_ass.size();
2498,2607c1278
<       //cout << endl << "event" << endl;
<       for (GenParticleCollection::const_iterator p = genParticles->begin(); p != genParticles->end(); ++p, ++p_count) 
< 	{
< 			
< 	  if(p_count < 10000)
< 	    genPartPDGArray[p_count] =  p->pdgId();
< 			
< 	  if ( nMC >= (nMaxMC-1) ) continue;
< 			
< 	  // looking for mother particle of the current generator particle
< 	  motherIDMC_temp = -1;   // default to no mother
< 	  if (p->numberOfMothers() > 0) 
< 	    {
< 	      const Candidate * mom = p->mother();
< 	      for (size_t j = 0; j != genParticles->size(); ++j) 
< 		{
< 		  const Candidate * ref = &((*genParticles)[j]);
< 		  if (mom==ref)
< 		    {
< 		      motherIDMC_temp = j; 
< 		    }
< 		}
< 	    }  // check on this generator particle having non-zero number of mothers 
< 			
< 	  if ( p->status()==1  && p->pt()>0.100 ) // look at stable particles with pT higher than 100 MeV/c
< 	    {
< 	      kMC[nMC] = nMC;               // Previous coding problem in that all the kMC did not get reset from the default value of -999?
< 	      pdgIdMC[nMC] = p->pdgId();
< 	      statusMC[nMC] = p->status();  // status is initially 1 for all particles, but changed to 2 below if the particle decays in generator (like the pi0 or eta or omega)
< 	      ptMC[nMC] = p->pt();
< 	      eMC[nMC] = p->energy();
< 	      etaMC[nMC] = p->eta(); 
< 	      phiMC[nMC] = p->phi(); 
< 	      mapMC[&(*p)] = nMC;
< 	      convertedMC[nMC] = false;    // the code to change this value has been previously commented out  (June 24)
< 	      motherIDMC[nMC] = -1;        // The value can change from -1 in the code below
< 	      motherIndexMC[nMC] = -1;     // The value can change from -1 in the code below (must have motherIDMC and motherIndexMC both equal to -1, or both not equal to -1)
< 	      current_particle = nMC;      // This variable is used in the code below
< 	      ++nMC; 
< 				
< 	      // if stable photon/electron, find parent
< 	      //
< 	      // Conversions occur outside of the generator, so these electrons/positrons are from Dalitz decays inside genertor?
< 	      //
< 	      if (p->status() == 1 && motherIDMC_temp != -1 && (p->pdgId() == kPhoton || fabs(p->pdgId()) == kElectron ) ) // condition that status = 1 is redundant inside this branch 
< 		{
< 		  const GenParticle *mom = (const GenParticle*)p->mother();
< 					
< 		  // saving the mother pdgId 
< 		  motherIDMC[current_particle] = mom->pdgId();
< 					
< 		  if ( mom->status() == 2 &&  (mom->pdgId()<81 || mom->pdgId()>100)) // avoid to store partons and MC internal
< 		    {
< 		      // check if the mother particle is found for the first time
< 		      if(mothers.find(motherIDMC_temp) == mothers.end())
< 			{
< 			  mothers.insert(motherIDMC_temp);
< 			  if (nMC>=nMaxMC) continue;
< 			  pdgIdMC[nMC] = mom->pdgId();
< 			  statusMC[nMC] = mom->status();
< 			  ptMC[nMC] = mom->pt();
< 			  eMC[nMC] = mom->energy();
< 			  etaMC[nMC] = mom->eta();
< 			  phiMC[nMC] = mom->phi(); 
< 			  mapMC[mom] = nMC;
< 			  motherIDMC[nMC] = -2;        // These new motherIDMC and motherIndexMC were left unassigned previously?
< 			  motherIndexMC[nMC] = -2;     // These new motherIDMC and motherIndexMC were left unassigned previously?
< 			  kMC[nMC] = nMC;     
< 			  ++nMC;
< 			}
< 		    }
< 					
< 		  mapMC_it =  mapMC.find(mom);
< 		  if(mapMC_it != mapMC.end())
< 		    motherIndexMC[current_particle] = mapMC_it->second;
< 					
< 		  //cout << "   myM_PI0::" << motherIndexMC[current_particle] << endl;
< 					
< 		} // photon or electron/positron has parents 
< 	    } // particle selection (photon or electron/positron which has an identified partent
< 			
< 	} // loop over particles in genParticle collection
< 		
< 		
<       //----- Figure out the particle decays in tracker volume  ------
< 		
<       // Vertices only return trackID of their parent SimTrack
<       // Figure out the mapping from trackID to SimTrack
<       map<unsigned int, const SimTrack*> trackMap;
< 		
<       bool simTrackPrint = false;
<       if(simTrackDebug && eventn < 30) {
< 	simTrackPrint = true;
< 	cout << "\n\n For Event " << eventn << " debug information for simTracks with size " <<  simTracksSize;
< 	cout << "; nSimTracks = " << nSimTracks << " with zVertex " << zPrimaryVertex;
< 	cout << "; generator p_count = " << p_count;
< 	cout << endl;
<       }
< 		
<       //
<       // Code for daughter array initializations
<       //
<       for (int mSim=0; mSim<nMaxSim; mSim++) {
< 	nDaughtersSim[mSim] = 0;      // initialization for the number of daughters for each particle
< 	kDaughtersSim[mSim][0] = -1;  // initialization for kSim index of the first daughter
< 	kDaughtersSim[mSim][1] = -2;  // initialization for kSim index of the second daughter
< 	kDaughtersSim[mSim][2] = -3;  // initialization for kSim index of the third daughter
< 	kSim[mSim] = -1;
< 	bestNoConvertEcalIndexSim[mSim] = -1;
<       }
---
>     double nMult_trg_eff_pi0=0;
2609,2627c1280,1292
<       highestMatchedGenSimTrack = -1;
<       lowestDaughterSimTrack = 100000000;
<       int jSim = 0;
<       int iiSim = 0;
<       for (SimTrackContainer::const_iterator iSim = simTracks->begin(); iSim != simTracks->end(); ++iSim) {
< 		
< 	//
< 	// Store sim tracks only within the eta range enclosing the ECAL barrel
< 	//
< 	double xMomentum = (iSim->momentum()).X();
< 	double yMomentum = (iSim->momentum()).Y();
< 	double zMomentum = (iSim->momentum()).Z();
< 	double totalMomentum = sqrt(xMomentum*xMomentum + yMomentum*yMomentum + zMomentum*zMomentum);
< 
< 	double etaParticle = -999.0;
< 
< 	if(totalMomentum > 0.0) {
< 	  double thetaParticle = acos(zMomentum/totalMomentum);
< 	  etaParticle = -log(tan(thetaParticle/2.0));
---
>     for(int ntrg=0; ntrg<nMult_trg; ++ntrg)
>       {
> 	TVector3 pvector_trg = (pVect_trg)[ntrg];
> 	double eta_trg = pvector_trg.Eta();
> 	double pt_trg = pvector_trg.Pt(); 
> 
> 	if(doEffCorrections_){
> 	float effCorrFactor = efficiencyCorrections(pt_trg);
> 	double effpi0 = effhisto_pi0->GetBinContent(effhisto_pi0->FindBin(pt_trg,eta_trg));
> 	//	cout<<"pT trig = "<<pt_trg<<'\t'<<"eta_trg"<<eta_trg<<endl;
> 	//	cout<<"Efficiency correction factor = "<<effCorrFactor<<'\t'<<"Efficiency = "<<effpi0<<endl;
> 	nMult_trg_eff_pi0 = nMult_trg_eff_pi0 + 1.0*effCorrFactor/effpi0;
> 	//nMult_trg_eff_pi0 = nMult_trg_eff_pi0 + 1.0/effpi0;
2630,2634d1294
< 	int simPdgId = iSim->type();
< 
< 	if(etaParticle < -1.55 || etaParticle > 1.55) {
< 	  storeThisSimTrack[iiSim] = false;
< 	}
2636,2643c1296,1300
< 	  storeThisSimTrack[iiSim] = true;
< 	}
< 
< 	if(jSim >= nMaxSim)
< 	  continue;
< 
< 	kSim[jSim] = jSim;
< 	double eMomentum =  (iSim->momentum()).E();
---
>           double effpi0 = 1.0;
>           float effCorrFactor = 1.0;
> 	  nMult_trg_eff_pi0 = nMult_trg_eff_pi0 + 1.0*effCorrFactor/effpi0;
>         }
>       }
2645,2652c1302
< 	etaSim[jSim] = etaParticle;
< 	phiSim[jSim] = atan2(yMomentum, xMomentum);
< 	ptSim[jSim] = sqrt(xMomentum*xMomentum + yMomentum*yMomentum);
< 	eSim[jSim] = eMomentum;
< 
< 	noVertexSim[jSim] = 1;
< 	pdgIdSim[jSim] = simPdgId;
< 	trackIdSim[jSim] = iSim->trackId();
---
>     //	cout<<"Uncorrected multiplicity  = "<<nMult_trg<<'\t'<<"corrected efficiency multiplicity = "<<nMult_trg_eff_pi0<<endl;
2654,2670c1304,1318
< 	//
< 	// Set defaults for the absence of parents or grandparents
< 	//
< 	parentKSim[jSim] = -2;      // New variable to contain the kSim index number of the parent particle
< 	parentIdSim[jSim] = -2000002;     // Maguire change from previous 0 value for variable named noParentID, now will be the particle PDG ID
< 	parentTrackSim[jSim] = -2;  // New variable to contain the simulation track number of the parent particle
< 	gParentKSim[jSim] = -2;      // New variable to contain the kSim index number of the grandparent particle
< 	gParentIdSim[jSim] = -2000002;     // New variable for the grandparent PDG ID
< 	gParentTrackSim[jSim] = -2;  // New variable to contain the simulation track number of the grandparent particle
< 
< 	rSim[jSim] = -999.0;
< 	zSim[jSim] = -999.0;
< 			
< 	if(iSim->noGenpart()) {
< 	  genPartIndexSim[jSim] = -2;
< 	  genPartPdgIdSim[jSim] = -3;
< 	} // no Genpart value for this particle
---
>     for(int ntrg=0; ntrg<nMult_trg; ++ntrg)
>       {
> 	TVector3 pvector_trg = (pVect_trg)[ntrg];
> 	double eta_trg = pvector_trg.Eta();
> 	double phi_trg = pvector_trg.Phi();
> 	double pt_trg = pvector_trg.Pt(); 
> 	
> 	float effCorrFactor;
> 	double effpi0;
> 
> 	if(doEffCorrections_){
> 	effCorrFactor = efficiencyCorrections(pt_trg);
> 	//	cout<<"pT trig = "<<pt_trg<<'\t'<<"Correction factor = "<<effCorrFactor<<endl;
> 	effpi0 = effhisto_pi0->GetBinContent(effhisto_pi0->FindBin(pt_trg,eta_trg));
> 	}
2672,2674c1320,1322
< 	  int genPartIndex = iSim->genpartIndex();
< 	  genPartIndexSim[jSim] = genPartIndex;
< 	  if(genPartIndex >=0 && genPartIndex < int(genSize) && genPartIndex < 10000 ) {
---
> 	  effpi0 = 1.0;
> 	  effCorrFactor = 1.0;
> 	}
2676,2677c1324,1333
< 	    genPartPdgIdSim[jSim] = genPartPDGArray[genPartIndex]; // this value is not correct ?? 
< 	    //genPartPdgIdSim[jSim]= (&(*genParticles)[iSim->genpartIndex()-1])->pdgId(); // this is OK for the first few values, and then it fails ??
---
> 	for(int nass=0; nass<nMult_ass; nass++)
> 	  {
> 	    TVector3 pvector_ass = (pVect_ass)[nass];
> 	    double eta_ass = pvector_ass.Eta();
> 	    double phi_ass = pvector_ass.Phi();
> 	    double pt_ass = pvector_ass.Pt();
> 	    
> 	    double effweight_ass;
> 	    if(doEffCorrections_) effweight_ass = effhisto->GetBinContent(effhisto->FindBin(eta_ass,pt_ass));
> 	    else effweight_ass = 1.0;
2679,2703c1335,1363
< 	  }
< 	  else {
< 	    genPartPdgIdSim[jSim] = -4;
< 	  }
< 	}
< 			
< 	if (!iSim->noVertex()) {
< 	  assert(trackMap.find(iSim->trackId())==trackMap.end());  // check that iSim->trackId()) is not already in trackMap (unique track ID)
< 				
< 	  noVertexSim[jSim] = 0;
< 	  trackMap[iSim->trackId()] = &(*iSim);
< 				
< 	  if(simTrackPrint) {
< 	    cout << "\n For jSim = " << jSim << " there is a vertex for trackId " << iSim->trackId() << " and trackMap size " << trackMap.size();
< 	    if(iSim->noGenpart()) {
< 	      cout << "; there is no genPart";
< 	    }
< 	    else {
< 	      cout << ", genPart has index " << iSim->genpartIndex();
< 	      if(iSim->genpartIndex() < int(genSize)) {
< 		const GenParticle* iGen = &(*genParticles)[iSim->genpartIndex()-1];
< 		cout << ", genParticle pdgID = " << iGen->pdgId() << " and gen pT " << iGen->pt();
< 	      }
< 	      else {
< 		cout << " (index exceeds genSize)";
---
> 	    double deltaEta = eta_ass - eta_trg;
> 	    double deltaPhi = phi_ass - phi_trg;
> 	    if(deltaPhi > _pi) deltaPhi = deltaPhi - 2*_pi;
> 	    if(deltaPhi < -_pi) deltaPhi = deltaPhi + 2*_pi;
> 	    if(deltaPhi > -_pi && deltaPhi < -_pi/2.0) deltaPhi = deltaPhi + 2*_pi;
> 	    
> 	    if(deltaEta == 0 && deltaPhi == 0) continue;
> 	    
> 	    if(pi0HadronCorrelations_ || etaHadronCorrelations_) {
> 	      
> 	      char histogramName5[200];
> 	      for(int kPt=0; kPt<bins1; kPt++) {
> 		if(pt_trg > NptBins_[kPt] && pt_trg <= NptBins_[kPt+1]) //correction
> 		  {
> 		    sprintf(histogramName5, "hSignalPtBin%d", kPt);
> 		    
> 		    //		  hSignal[histogramName5]->Fill(deltaEta,deltaPhi,1.0/nMult_trg/nMult_ass);
> 		    //		  hSignal[histogramName5]->Fill(deltaEta,2*_pi - deltaPhi,1.0/nMult_trg/nMult_ass); 
> 		    //		    cout<<"pT min = "<<NptBins_[kPt]<<" pT max = "<<NptBins_[kPt+1]<<endl;
> 		    // cout<<"Correction factor = "<<effCorrFactor<<endl;
> 		    // cout<<"Delta eta = "<<deltaEta<<'\t'<<"Delta phi = "<<deltaPhi<<'\t'<<1.0/4.0/nMult_trg_eff_pi0/effpi0/effweight_ass<<'\t'<<1.0*effCorrFactor/4.0/nMult_trg_eff_pi0/effpi0/effweight_ass<<endl;
> 		    double weight = effCorrFactor/4.0/nMult_trg_eff_pi0/effpi0/effweight_ass;
> 		    hSignal[histogramName5]->Fill(fabs(deltaEta),fabs(deltaPhi),weight);
> 		    hSignal[histogramName5]->Fill(-fabs(deltaEta),fabs(deltaPhi),weight);
> 		    hSignal[histogramName5]->Fill(fabs(deltaEta),-fabs(deltaPhi),weight);
> 		    hSignal[histogramName5]->Fill(-fabs(deltaEta),-fabs(deltaPhi),weight);
> 		    hSignal[histogramName5]->Fill(fabs(deltaEta),2*_pi-fabs(deltaPhi),weight);
> 		    hSignal[histogramName5]->Fill(-fabs(deltaEta),2*_pi-fabs(deltaPhi),weight);
> 		  }
2705c1365,1373
< 	      cout << ", simTracks pdgID = " << iSim->type();
---
> 	    }
> 	    
> 	    if(diHadronCorrelations_) {
> 	      hSignal1->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg/effweight_ass);
> 	      hSignal1->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/4.0/nMult_trg/effweight_ass);
> 	      hSignal1->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg/effweight_ass);
> 	      hSignal1->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/4.0/nMult_trg/effweight_ass);
> 	      hSignal1->Fill(fabs(deltaEta),2*_pi-fabs(deltaPhi),1.0/4.0/nMult_trg/effweight_ass);
> 	      hSignal1->Fill(-fabs(deltaEta),2*_pi-fabs(deltaPhi),1.0/4.0/nMult_trg/effweight_ass); 
2708,2727d1375
< 	}
< 	else {
< 	  if(simTrackPrint)
< 	    cout << "\n For jSim = " << jSim << " there is no vertex for trackId " << iSim->trackId() << " and trackMap size " << trackMap.size();
< 	}
< 	
< 	if(storeThisSimTrack[iiSim]) {
< 	  jSim++;
< 	}
< 	else {
< 	  kSim[jSim] = -2;
< 	}
< 	iiSim++;
< 			
<       } // end first loop over SimTrackContainer
<       int njSimCheck = jSim;
< 
<       if(simTrackPrint) {
< 	cout << "\n Completed initial loop over SimTrackContainer with final trackMap size at " << trackMap.size() << endl;
< 	cout << "\n Starting second loop over SimTrackContainer for inter-generation mappings";
2729,2820c1377,1432
< 		
<       // Find all SimTracks that come from decays before the ECAL
<       // and find their parent SimTracks
<       map<const SimTrack*, const SimTrack*> promptParent; // daughter->mother
<       map<const SimTrack*, set<const SimTrack*> > promptDecays; // m->ds
<       map<const SimTrack*, const SimVertex*> promptVertex; // daughter->vertex
< 		
<       jSim = 0;
<       iiSim = 0;
<       for (SimTrackContainer::const_iterator iSim = simTracks->begin(); iSim != simTracks->end(); ++iSim) {
< 
< 	if (!iSim->noVertex()) {
< 				
< 	  // Find the parent vertex and see if it classifies as an early decay
< 	  // Exclude the primary vertex (noParent)
< 	  SimVertex const& vtx = (*simVertices)[iSim->vertIndex()];
< 				
< 	  if(simTrackPrint)
< 	    cout << "\n jSim = " << jSim << " has a vertex for trackId " << iSim->trackId();
< 				
< 	  rSim[jSim] = vtx.position().Rho();
< 	  zSim[jSim] =  vtx.position().z();
< 				
< 	  if(vtx.noParent()) {
< 					
< 	    parentKSim[jSim] = -1;      // New variable to contain the kSim index number of the parent particle
< 	    parentIdSim[jSim] = -2000001;     // Maguire change from previous 0 value for variable named noParentID,now will be the particle PDG ID
< 	    parentTrackSim[jSim] = -1;  // New variable to contain the simulation track number of the parent particle
< 	    gParentKSim[jSim] = -1;      // New variable to contain the kSim index number of the grandparent particle
< 	    gParentIdSim[jSim] = -2000001;     // New variable to contain the grandparent particle PDG ID
< 	    gParentTrackSim[jSim] = -1;  // New variable to contain the simulation track number of the grandparent particle
< 					
< 	    if(simTrackPrint)
< 	      cout << "; no parent vertex for current vertex (R, Z) = (" << vtx.position().Rho() << ", " << vtx.position().z() << ")";  
< 	  }
< 				
< 	  if (!vtx.noParent() && vtx.position().Rho() < 129 && fabs(vtx.position().z()) < 304) {
< 	    // Find parent SimParticle that produced this vertex
< 	    // vtx->parentIndex is NOT a vector index :( so use trackMap
< 	    assert(trackMap.find(vtx.parentIndex())!=trackMap.end());
< 	    const SimTrack* p = trackMap[vtx.parentIndex()]; // simTracks iterator for the parent of this track
< 	    promptParent[&(*iSim)] = p;        // first element is the current simTracks iterator value; second element is the parent iterator
< 	    promptDecays[p].insert(&(*iSim));  // first element is the parent of the current simTracks; second element is the current simTracks iterator
< 	    promptVertex[&(*iSim)] = &vtx;     // first element is the current simTracks iterator value; second element is the current vertex
< 	
< 	    if(trackIdSim[jSim] < lowestDaughterSimTrack)
< 	      lowestDaughterSimTrack = trackIdSim[jSim];
< 
< 	    parentIdSim[jSim] = p->type(); // Maguire change to make this variable function more useful carrying the actual parent ID
< 	    int parentSimulationTrackNumber = p->trackId();
< 	    parentTrackSim[jSim] = parentSimulationTrackNumber;
< 
< 
< 	    //
< 	    // Look for previous Sim entry with this simulation track number
< 	    // Loop backward since it is more likely that the previous Sim entry is recent
< 	    //
< 	    parentKSim[jSim] = -3;
< 	    gParentKSim[jSim] = -3;
< 	    gParentTrackSim[jSim] = -2000003;
< 	    gParentIdSim[jSim] = -2000003; 
< 	    if(jSim > 0) {
< 	      int jjSimMax = jSim - 1;
< 	      for(int jjSim=jjSimMax; jjSim>0; jjSim--) {
< 		if(trackIdSim[jjSim] == parentSimulationTrackNumber) {
< 		  parentKSim[jSim] = jjSim;
< 		  //
< 		  // Obtain the grandparent
< 		  //
< 		  gParentKSim[jSim] = parentKSim[jjSim];
<                   if(parentKSim[jjSim] >= 0) {
< 		    gParentTrackSim[jSim] = parentTrackSim[jjSim];
< 		    gParentIdSim[jSim] = parentIdSim[jjSim];
< 		  }
< 		  else {
< 		    gParentTrackSim[jSim] = -5;
< 		    gParentIdSim[jSim] = -2000005;
< 		  }
< 		  //
< 		  // Store the daughters information in the parent particle
< 		  //
< 		  if(nDaughtersSim[jjSim] < 0) {
< 		    cerr << "\n Number of daughters < 0 ?? with jjSim = " << jjSim << endl;
< 		    return;
< 		  }
< 		  if(nDaughtersSim[jjSim] < 3) {
< 		    int currentNumberOfDaughters = nDaughtersSim[jjSim];
< 		    kDaughtersSim[jjSim][currentNumberOfDaughters] = jSim;
< 		    nDaughtersSim[jjSim]++;
< 		  }
< 		  else {
< 		    nDaughtersSim[jjSim]++;
---
>     pVectVect_trg.push_back(pVect_trg);
>     pVectVect_ass.push_back(pVect_ass);
>     zvtxVect.push_back(zVertexEventSelected); 
>     
>     
>     ///////////////////////////////////////////////////////////////////////////
>     
>     /// mc truth
>     isMC = !iEvent.isRealData();
>     
>     // get MC info from hiGenParticleCandidates 
>     Handle<GenParticleCollection> hiGenParticles;
>     if(isMC) iEvent.getByLabel("hiGenParticles", hiGenParticles);
>     
>     // get GEANT sim tracks and vertices (includes conversions)
>     Handle<SimTrackContainer> simTracks_h;
>     const SimTrackContainer* simTracks;
>     if( isMC ) iEvent.getByLabel("g4SimHits", simTracks_h);
>     simTracks = (simTracks_h.isValid()) ? simTracks_h.product() : 0;
>     
>     Handle<SimVertexContainer> simVert_h;
>     const SimVertexContainer* simVertices;
>     if( isMC ) iEvent.getByLabel("g4SimHits", simVert_h);
>     simVertices = (simVert_h.isValid()) ? simVert_h.product() : 0;
>     
>     if( isMC ) 
>       {
> 	nMC = nSIM = 0;
> 	int current_particle = -1;
> 	set<int> mothers;
> 	map<const GenParticle*, int> mapMC;
> 	map<const GenParticle*, int>::iterator mapMC_it;
> 	//int where_is_pi0_mother(0);  //debug
> 	int p_count(0);
> 	int motherIDMC_temp = -1;
> 	
> 	//cout << endl << "event" << endl;
> 	for (GenParticleCollection::const_iterator p = hiGenParticles->begin(); p != hiGenParticles->end(); ++p, ++p_count) 
> 	  {
> 	    if ( nMC >= (nMaxMC-1) ) continue;
> 	    
> 	    // looking for mother particle
> 	    motherIDMC_temp = -1;
> 	    //where_is_pi0_mother = -1; // debug
> 	    if (p->numberOfMothers() > 0) 
> 	      {
> 		const Candidate * mom = p->mother();
> 		for (size_t j = 0; j != hiGenParticles->size(); ++j) 
> 		  {
> 		    const Candidate * ref = &((*hiGenParticles)[j]);
> 		    if (mom==ref)
> 		      {
> 			motherIDMC_temp = j; 
> 			//if(mom->pdgId()==kPi0)//debug
> 			//   where_is_pi0_mother = j; // debug
> 		      }
2822,2836c1434,1503
< 		  break;
< 		} // check for simulation track number equality
< 	      } // loop over previously stored simulation track numbers
< 	    }
< 
< 	    if(simTrackPrint) {
< 	      cout << ", parent exists for early vertex position (R, Z) = (" << vtx.position().Rho() << ", " << vtx.position().z() << ")";
< 	      cout << "; parent ID " << p->type() << " and current ID " << iSim->type();
< 	    }
< 					
< 	  } // early decay
< 				
< 	  if (!vtx.noParent() && (vtx.position().Rho() >= 129 || fabs(vtx.position().z()) >= 304)) {
< 	    if(simTrackPrint)
< 	      cout << "; parent exists for late vertex for position (R, Z) = (" << vtx.position().Rho() << ", " << vtx.position().z() << ")";
---
> 	      } 
> 	    
> 	    // Neutral particles kept with >100 MeV 
> 	    if ( p->status()==1  && p->pt()>0.100 )//|| (p->charge()!=0 && p->pt()>0.075)) ) 
> 	      {
> 		pdgIdMC[nMC] = p->pdgId();
> 		statusMC[nMC] = p->status();
> 		ptMC[nMC] = p->pt();
> 		eMC[nMC] = p->energy();
> 		etaMC[nMC] = p->eta(); 
> 		phiMC[nMC] = p->phi(); 
> 		mapMC[&(*p)] = nMC;
> 		convertedMC[nMC] = false;
> 		motherIDMC[nMC] = -1; //((const hiGenParticle*)p->mother())->pdgId(); 
> 		motherIndexMC[nMC] = -1; //hic::check
> 		current_particle = nMC;
> 		++nMC; 
> 		
> 		// if stable photon/electron, find parent
> 		if (p->status() == 1 && motherIDMC_temp != -1 && (p->pdgId() == kPhoton || fabs(p->pdgId()) == kElectron ) ) //|| p->pdgId() == 221)) // 221=eta0 
> 		  {
> 		    const GenParticle *mom = (const GenParticle*)p->mother();
> 		    
> 		    // saving the mother pdgId 
> 		    motherIDMC[current_particle] = mom->pdgId();
> 		    
> 		    if ( mom->status() == 2 &&  (mom->pdgId()<81 || mom->pdgId()>100)) // avoid to store partons and MC internal
> 		      {
> 			// if the mother particle is found for the first time
> 			if(mothers.find(motherIDMC_temp) == mothers.end())
> 			  {
> 			    mothers.insert(motherIDMC_temp);
> 			    if (nMC>=nMaxMC) continue;
> 			    pdgIdMC[nMC] = mom->pdgId();
> 			    statusMC[nMC] = mom->status();
> 			    ptMC[nMC] = mom->pt();
> 			    eMC[nMC] = mom->energy();
> 			    etaMC[nMC] = mom->eta();
> 			    phiMC[nMC] = mom->phi(); 
> 			    mapMC[mom] = nMC;
> 			    //motherIndexMC[nMC-1] = nMC;
> 			    ++nMC;
> 			  }
> 			//else
> 			//{
> 			//motherIndexMC[nMC-1] = mapMC.find(mom)->second;
> 			//}
> 		      }
> 		    
> 		    mapMC_it =  mapMC.find(mom);
> 		    if(mapMC_it != mapMC.end())
> 		      motherIndexMC[current_particle] = mapMC_it->second;
> 		    //cout << "   my_pi0::" << motherIndexMC[current_particle] << endl;
> 		  } // stable particle has parents 
> 	      } // particle selection
> 	  } // loop over particles
> 	
> 	
> 	//----- Figure out the particle decays in tracker volume  ------
> 	
> 	// Vertices only return trackID of their parent SimTrack
> 	// Figure out the mapping from trackID to SimTrack
> 	map<unsigned int, const SimTrack*> trackMap;
> 	for (SimTrackContainer::const_iterator iSim = simTracks->begin(); iSim != simTracks->end(); ++iSim) 
> 	  {
> 	    if (!iSim->noVertex()) 
> 	      {
> 		assert(trackMap.find(iSim->trackId())==trackMap.end());
> 		trackMap[iSim->trackId()] = &(*iSim);
> 	      }
2838,2843d1504
< 				
< 	}  // check for simTrack having a vertex
< 	else {
< 	  if(simTrackPrint)
< 	    cout << "\n For jSim = " << jSim << "there is no vertex for trackId " << iSim->trackId();
< 	}
2845,2967c1506,1568
< 	if(storeThisSimTrack[iiSim]) {
< 	  jSim++;
< 	}
< 	iiSim++;
< 			
<       } // end second loop over simContainer
<       njSim = jSim;
< 
<       cout << "\n\n The meson tree size is " << nMesonSize << ", genSize " << genSize;
<       cout << ", countDisAllowedMesons " << countDisAllowedMesons;
<       cout << ", countAllowedMesons " << countAllowedMesons;
<       cout << "\n The njSim size is " << njSim << " with simTracksSize " << simTracksSize;
<       cout << endl << endl;
< 
<       if(njSim != njSimCheck) {
< 	cerr << "\n\n jSim check fail: njSimCheck = " << njSimCheck << ",  njSim = " << nSim  << endl << endl;
< 	return;
<       } // safety check
< 
<       //
<       // Make new correspondence betweem genParticle and simTrack (Maguire, August 2013)
<       //
<       for(int jSim=0; jSim<njSim; jSim++) {
< 
< 	//
< 	// Particles with a parent should not find a matched, but the loop is made anyway to confirm this effect
< 	//
< 
< 	int simPdgId = pdgIdSim[jSim];
< 
< 	float simPt = ptSim[jSim];
< 	float simEta = etaSim[jSim];
< 	float simPhi = phiSim[jSim];
< 	int simTrackTest = trackIdSim[jSim];
< 	float rSimTest = rSim[jSim];
< 	float zSimTest = zSim[jSim];
< 	float kSimTest = kSim[jSim];
< 
< 	bool canTestThisSimTrack = false;
< 	if(rSimTest < 1.0 && fabs(zSimTest) < 30.0 && kSimTest >= 0)
< 	  canTestThisSimTrack = true;
< 
< 	int bestGenIndexMatch = -1;
< 	float bestAngleMatch = 100.0;
< 	float bestPtMatch = -1.0;
< 	float bestEtaMatch = -100.0;
< 	float bestPhiMatch = -100.0;
< 	motherGenIdSim[jSim] = -2;
< 	motherGenIndexSim[jSim] = -2;
< 	gMotherGenIdSim[jSim] = -2;
< 
< 	float acceptedDeltaPt = ptPrimaryCut*simPt;
< 	if(acceptedDeltaPt < 0.01)
< 	  acceptedDeltaPt = 0.01;
< 
< 	for(size_t i=0; i<genParticles->size(); i++) {
< 						
< 	  const GenParticle & p = (*genParticles)[i];
< 
< 	  if(p.pdgId() != simPdgId)
< 	    continue;
< 
< 	  float ptGen = p.pt();
< 	  if(fabs(ptGen - simPt) > acceptedDeltaPt)
< 	    continue;
< 
< 	  float etaGen = p.eta();
< 	  float phiGen = p.phi();
< 
< 	  float phiDelta = deltaPhi(phiGen, simPhi);
< 	  float testAngleMatch = sqrt((etaGen - simEta)*(etaGen - simEta) + phiDelta*phiDelta);
< 	  if(testAngleMatch < bestAngleMatch) {
< 	    bestAngleMatch = testAngleMatch;
< 	    bestPtMatch = ptGen;
< 	    bestEtaMatch = etaGen;
< 	    bestPhiMatch = phiGen;
< 	    bestGenIndexMatch = i;
< 	    if(canTestThisSimTrack && bestAngleMatch < 0.01 && simTrackTest > highestMatchedGenSimTrack)
< 	      highestMatchedGenSimTrack = simTrackTest;
< 	  }
< 	} // loop over GenParticle collection
< 
< 	genPartPdgIdSim[jSim] = simPdgId; // forced 
< 	genPartIndexSim[jSim] = bestGenIndexMatch;
< 	bestAngleMatchGenSim[jSim] = bestAngleMatch;
< 	bestPtMatchGenSim[jSim] = bestPtMatch;
< 	bestEtaMatchGenSim[jSim] = bestEtaMatch;
< 	bestPhiMatchGenSim[jSim] = bestPhiMatch;
< 	if(bestGenIndexMatch > -1) {
< 	  //
< 	  // Get mother ID for this generator particle
< 	  //
< 	  const GenParticle & p = (*genParticles)[bestGenIndexMatch];
< 	  const Candidate *mom = p.mother();
< 	  if(mom) {
< 	    motherGenIdSim[jSim] = mom->pdgId();
< 	    int momIdTest =  motherGenIdSim[jSim];
< 	    float momPtTest = mom->pt();
< 	    float momEtaTest = mom->eta();
< 	    float momPhiTest = mom->phi();
< 	    bool momFound = false;
< 	    //
< 	    // Search for grandmother
< 	    //
< 	    for(size_t i=0; i<genParticles->size(); i++) {
< 	      const GenParticle & pp = (*genParticles)[i];
< 	      if(pp.pdgId() != momIdTest)
< 		continue;
< 	      if(pp.pt() != momPtTest)
< 		continue;
< 	      if(pp.eta() != momEtaTest)
< 		continue;
< 	      if(pp.phi() != momPhiTest)
< 		continue;
< 
< 	      momFound = true;
< 	      motherGenIndexSim[jSim] = i;
< 	      const Candidate *gmom = pp.mother();
< 	      if(gmom) {
< 		gMotherGenIdSim[jSim] = gmom->pdgId();
< 	      }
< 	      else {
< 		gMotherGenIdSim[jSim] = -3;
---
> 	
> 	// Find all SimTracks that come from decays before the ECAL
> 	// and find their parent SimTracks
> 	map<const SimTrack*, const SimTrack*> promptParent; // daughter->mother
> 	map<const SimTrack*, set<const SimTrack*> > promptDecays; // m->ds
> 	map<const SimTrack*, const SimVertex*> promptVertex; // daughter->vertex
> 	
> 	for (SimTrackContainer::const_iterator iSim = simTracks->begin(); iSim != simTracks->end(); ++iSim) 
> 	  {
> 	    if (!iSim->noVertex()) 
> 	      {
> 		// Find the parent vertex and see if it classifies as an early decay
> 		// Exclude the primary vertex (noParent)
> 		SimVertex const& vtx = (*simVertices)[iSim->vertIndex()];
> 		if (!vtx.noParent() && vtx.position().Rho() < 129 && fabs(vtx.position().z()) < 304) 
> 		  {
> 		    // Find parent SimParticle that produced this vertex
> 		    // vtx->parentIndex is NOT a vector index :( so use trackMap
> 		    assert(trackMap.find(vtx.parentIndex())!=trackMap.end());
> 		    const SimTrack* p = trackMap[vtx.parentIndex()];
> 		    promptParent[&(*iSim)] = p;
> 		    promptDecays[p].insert(&(*iSim));
> 		    promptVertex[&(*iSim)] = &vtx;
> 		  } // early decay
> 	      } // has vertex
> 	  } // for simTracks
> 	
> 	// Find grandparent SimTracks all the way up the chain
> 	map<const SimTrack*, const SimTrack*> chainParents;// g.daughter->grandma
> 	map<const SimTrack*, set<const SimTrack*> > chainDecays; // gm->gds
> 	
> 	for (map<const SimTrack*, const SimTrack*>::const_iterator iSim = promptParent.begin(); iSim != promptParent.end(); ++iSim) 
> 	  {
> 	    // Check that the SimTrack has no daughters itself (=grandchild)
> 	    if (promptDecays.find(iSim->first)==promptDecays.end())
> 	      {
> 		// Find the first SimTrack in the parentage chain (=grandparent)
> 		const SimTrack *p = iSim->second;
> 		while (promptParent.find(p) != promptParent.end())
> 		  p = promptParent[p];
> 		chainParents[iSim->first] = p;
> 		chainDecays[p].insert(iSim->first);
> 	      } // is grandchild
> 	  } // for promptParent
> 	
> 	// Associate grandParents to hiGenParticles
> 	map<const GenParticle*, const SimTrack*> decayedSims;
> 	map<const SimTrack*, const GenParticle*> decayedGens;
> 	
> 	for (map<const SimTrack*, set<const SimTrack*> >::const_iterator iSim = chainDecays.begin(); iSim != chainDecays.end(); ++iSim) 
> 	  {
> 	    if (iSim->first->noGenpart()) 
> 	      continue;
> 	    
> 	    // Make sure the decay chain wasn't already pruned out
> 	    if (promptDecays.find(iSim->first)!=promptDecays.end() && promptDecays[iSim->first].size()!=0) 
> 	      {
> 		// NB: genpartIndex offset by 1
> 		const GenParticle* iGen =
> 		  &(*hiGenParticles)[iSim->first->genpartIndex()-1];
> 		assert(iGen->pdgId()==iSim->first->type());
> 		decayedSims[iGen] = iSim->first;
> 		decayedGens[iSim->first] = iGen;
2969,3045c1570
< 
< 	      break; // found grandmother
< 
< 	    } // loop over genParticle collection
< 	    if(!momFound) {
< 	      motherGenIndexSim[jSim] = -1;
< 	      gMotherGenIdSim[jSim] = -1;
< 	    }
< 	  } // check for valid mother pointer
< 	  else {
< 	    motherGenIdSim[jSim] = -1;
< 	  } // no valid mother pointer found
< 	} // check for good matching genParticle index
< 
<       } // loop over simTrack collection to do correspondence with genParticle
< 
<       //
<       // Make correspondence betweem ECAL reco and simTrack (Maguire, August 2013)
<       //
<       for(int jSim=0; jSim<njSim; jSim++) {
< 	bestNoConvertEcalIndexSim[jSim] = -2;
< 	bestNoConvertEcalAngleSim[jSim] = -999.0;
< 	bestNoConvertEcalPtSim[jSim] = -999.0;
< 
< 	if(pdgIdSim[jSim] != 22)
< 	  continue;  // check only photons
< 
< 	if(nDaughtersSim[jSim] != 0)
< 	  continue; // check only unconverted photons
< 
< 	if(trackIdSim[jSim] > highestMatchedGenSimTrack)
< 	  continue;  // check only primary particles
< 
< 	float simEta = etaSim[jSim];
< 	float simPhi = phiSim[jSim];
< 
< 	float bestEAngleMatch = 999.0;
< 	float bestEPtMatch = -999.0;
< 	int bestIndexMatch = -1;
< 	for(int jClu=0; jClu<nClu; jClu++) {
< 
< 	  float phiDelta = deltaPhi(phiClu[jClu], simPhi);
< 	  float etaDelta = etaClu[jClu] - simEta;
< 	  float testMatch = sqrt(phiDelta*phiDelta + etaDelta*etaDelta);
< 
< 	  if(testMatch < bestEAngleMatch) {
< 	    bestEAngleMatch = testMatch;
< 	    bestIndexMatch = jClu;
< 	    bestEPtMatch = ptClu[jClu];
< 	  }
< 	} // loop over clusters
< 
< 	bestNoConvertEcalIndexSim[jSim] = bestIndexMatch;
< 	bestNoConvertEcalAngleSim[jSim] = bestEAngleMatch; 
< 	bestNoConvertEcalPtSim[jSim] = bestEPtMatch; 
< 
< 	if(countNoConvertSimMatchEcal[bestIndexMatch] == 0) {
< 	  //
< 	  // First time that this jClu has been matched with a jSim track
< 	  //
< 	  bestNoConvertSimIndexEcal[bestIndexMatch] = jSim;
< 	  bestNoConvertSimAngleEcal[bestIndexMatch] = bestEAngleMatch;
< 	  countNoConvertSimMatchEcal[bestIndexMatch] = 1;
< 	} // check for first time use of this jClu
< 	else {
< 	  //
< 	  // Check if previous match had a worse angle match
< 	  //
< 	  if(bestNoConvertSimAngleEcal[bestIndexMatch] > bestEAngleMatch) {
< 	    bestNoConvertSimIndexEcal[bestIndexMatch] = jSim;
< 	    bestNoConvertSimAngleEcal[bestIndexMatch] = bestEAngleMatch;
< 	  } // new match is better
< 
< 	  countNoConvertSimMatchEcal[bestIndexMatch]++;
< 	} // check quality of previous best angle match
< 
<       } // loop over simTrack collection to do correspondence with ECAL reco
---
> 	  } // for chainParents 
3047,3113c1572,1573
<       if(simTrackPrint) {
< 	cout << endl;
<       }
< 		
<       // Find grandparent SimTracks all the way up the chain
<       map<const SimTrack*, const SimTrack*> chainParents;      // granddaughter->grandmother
<       map<const SimTrack*, set<const SimTrack*> > chainDecays; // grandmother->granddaughters
< 		
<       for (map<const SimTrack*, const SimTrack*>::const_iterator iSim = promptParent.begin(); iSim != promptParent.end(); ++iSim) 
< 	{
< 	  // Check that the SimTrack has no daughters itself (=grandchild)
< 	  if (promptDecays.find(iSim->first)==promptDecays.end())
< 	    {
< 	      // Find the first SimTrack in the parentage chain (=grandparent)
< 	      const SimTrack *p = iSim->second;
< 	      while (promptParent.find(p) != promptParent.end())
< 		p = promptParent[p];
< 	      chainParents[iSim->first] = p;
< 	      chainDecays[p].insert(iSim->first);
< 	    } // is grandchild
< 	} // for promptParent
< 		
<       // Associate grandParents to genParticles
<       map<const GenParticle*, const SimTrack*> decayedSims;
<       map<const SimTrack*, const GenParticle*> decayedGens;
< 		
<       /*
<       //
<       // Loop code fails in the assertion test
<       //
<       for (map<const SimTrack*, set<const SimTrack*> >::const_iterator iSim = chainDecays.begin(); iSim != chainDecays.end(); ++iSim) 
<       {
<       if (iSim->first->noGenpart()) 
<       continue;
< 		 
<       // Make sure the decay chain wasn't already pruned out
<       if (promptDecays.find(iSim->first)!=promptDecays.end() && promptDecays[iSim->first].size()!=0) 
<       {
<       // NB: genpartIndex offset by 1
<       const GenParticle* iGen =
<       &(*genParticles)[iSim->first->genpartIndex()-1];
< 		 
<       if(iGen->pdgId() != (iSim->first)->type()) {
<       cerr << "\n\n Pre-assertion failure";
<       cerr << "\n iGen->pdgId() = " << iGen->pdgId();
<       cerr << "\n  (iSim->first)->type() = " <<  (iSim->first)->type();
<       cerr << endl;
<       }
< 		 
<       assert(iGen->pdgId()==iSim->first->type());
<       decayedSims[iGen] = iSim->first;
<       decayedGens[iSim->first] = iGen;
<       }
<       } // for chainParents 
<       */
< 		
<       /*
< 		 
<       ///// Save conversions 
<       for (map<const GenParticle*, const SimTrack*>::const_iterator iGen = decayedSims.begin(); iGen != decayedSims.end(); ++iGen) 
<       {
<       const GenParticle *p = iGen->first;
< 		 
<       if the photon comes from pi0 or eta
<       if (p->pdgId()==22 && p->mother()->status()==2 && p->mother()->pdgId()==111) 
<       if (p->pdgId()==22 && (p->mother()->pdgId()==111 ||  // pi0 
<       p->mother()->pdgId()==221)) // eta
---
>       } // if isMC 
>     else
3115,3125c1575,1595
<       find the mother gen-particle index in the gen-particle vector
<       mapMC_it =  mapMC.find(p);
<       int mother_gen_index = -1;
<       if(mapMC_it != mapMC.end())mother_gen_index = mapMC_it->second;
<       if(mother_gen_index > 0) convertedMC[mother_gen_index] = true;
< 		 
<       //save the decay chain
<       bool saved = printChildren(decayedSims[p], promptDecays,  promptVertex, 0, true, mother_gen_index);
< 		 
<       if (saved && mapMC.find(p)!=mapMC.end()) {
<       statusMC[mapMC[p]] *= -1;
---
> 	nMC = 1;
> 	pdgIdMC[0] = -99999;
> 	statusMC[0] = -99999;
> 	motherIndexMC[0] = -99999;
> 	motherIDMC[0] = -99999;
> 	ptMC[0] = -99999;
> 	eMC[0] = -99999;
> 	etaMC[0] = -99999;
> 	phiMC[0] = -99999;
> 	convertedMC[0] = 0;
> 	
> 	nSIM = 1;
> 	pdgIdSIM[0] = -99999;
> 	statusSIM[0] = -99999;
> 	motherGenIndexSIM[0] = -99999;
> 	ptSIM[0] = -99999;
> 	eSIM[0] = -99999;
> 	etaSIM[0] = -99999;
> 	phiSIM[0] = -99999;
> 	rSIM[0] = -99999;
> 	zSIM[0] = -99999;
3127,3160c1597,1599
<       } // is primary photon
<       } // for iGen
<       ///// End of commented conversions code 
<       */
< 		
<     } // if isMC 
<   else
<     {
<       //
<       // Not simulation
<       //
< 		
<       //
<       // Setting null values for these "global event" parameters in the output tree
<       //
<       genSize = 1;
<       nSimTracks = 1;
<       mergedTrackTruthSize = 1;
<       nMesonSize = 1;
<       nPhotonSize = 1;
< 		
<       nMC = 1;
<       pdgIdMC[0] = -99999;   // these MC arrays are actually obsolete (July 2013)
<       statusMC[0] = -99999;
<       motherIndexMC[0] = -99999;
<       motherIDMC[0] = -99999;
<       ptMC[0] = -99999;
<       eMC[0] = -99999;
<       etaMC[0] = -99999;
<       phiMC[0] = -99999;
<       convertedMC[0] = 0;
< 		
<       nSim = 1;
<       njSim = 1;
---
>     
> }
> 
3162,3183d1600
<       ptSim[0] = -99999;
<       eSim[0] = -99999;
<       etaSim[0] = -99999;
<       phiSim[0] = -99999;
<       rSim[0] = -99999;
<       zSim[0] = -99999;
< 
<       pdgIdSim[0] = -99999; 
<       // statusSim[0] = -99999;
<       motherGenIndexSim[0] = -99999;
<   
<     }
< 	
<   //
<   // The generation and content of an ouptut tree is controlled by the python parameters
<   // 
<   if(m_tree) {
<     m_tree->Fill();
<   }
< 	
< 	
< } // end of analyze method
3189c1606
< 	
---
> 
3199c1616
< 	
---
> 
3201c1618
< 	
---
> 
3206c1623
< 	
---
> 
3211c1628
< 	
---
> 
3216c1633
< 	
---
> 
3220c1637
< 	
---
> 
3225,3276d1641
< 	
< } // end of beginJob method
< 
< // ------------ method called once each job just after ending the event loop  ------------
< void EcalFlowNtp::endJob() {
< 	
<   ////////////////// Calculating background for reconstructed pi0-hadron correlations //////////
<   int nevttotal_trg = (int)pVectVect_trg.size();  // the trg are the pi0
<   int nevttotal_ass = (int)pVectVect_ass.size();  // the ass are the charged particles
< 	
<   cout << "\n\n EcalFlowNTP::endJob() <I>  nevttotal_trg = " << nevttotal_trg;
<   cout << ",  nevttotal_ass = " << nevttotal_ass;
<   cout << ", totalEventsThisJob " <<  totalEventsThisJob;
<   cout << endl;
< 	
<   unsigned int nBackgroundFill = 0;
<   int totalTakeAssociated = 0;
<   int minimumTakeAssociated = 1000;
<   if(nevttotal_ass > 1 && nevttotal_trg > 1 && totalEventsThisJob > 1) {
< 		
<     cout << "\n Will check the Z-vertex differences";
<     cout << endl;
< 
<     unsigned int countAcceptedTriggerEvents = 0;
<     bool *acceptedTriggerEvents = new bool [nevttotal_trg];
<     //
<     // Look at Z-Vertex differences
<     //
<     for(int nevt_trg=0; nevt_trg<nevttotal_trg; nevt_trg++) {
<       acceptedTriggerEvents[nevt_trg] = false;
<       for(int nevt_ass=0; nevt_ass<nevttotal_ass; nevt_ass++) {
< 				
< 	if(nevt_trg == nevt_ass)
< 	  continue;  // don't use the same event
< 				
< 	if(fabs((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass])<=2.0) {
< 	  acceptedTriggerEvents[nevt_trg] = true;
< 	  countAcceptedTriggerEvents++;
< 	  break; // found at least one partner event with a close enough Z vertex
< 	}
< 				
<       } // loop over associated events
<     } // loop over trigger events
<     cout << "\n Number of trigger events with at least one partner event = " << countAcceptedTriggerEvents;
<     cout << endl;
< 		
<     for(int nevt_trg=0; nevt_trg<nevttotal_trg; nevt_trg++) {
< 			
<       if(!acceptedTriggerEvents[nevt_trg])
< 	continue;  // skip this trigger event which has no partner event close enough in Z
< 	      
<       nBackgroundFill++;
3278,3367c1643,1651
<       int countGoodAssociated = 0;
< 	
<       for(int nevt_ass=0; nevt_ass<nevttotal_ass; nevt_ass++) {
< 				
< 	if(nevt_trg == nevt_ass) { // check if the random trigger event matches this assocated event
< 	  continue;    // go to the next associated track
< 	}
< 				
< 	if(fabs((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass])>2.0){  // check if the Z vertex of the trigger and associated are separated by more than 2 cm
< 	  continue;    // go to the next associated event
< 	}
< 
< 	countGoodAssociated++;
< 
<       }
< 
<       if(countGoodAssociated < 1) {
< 	cout << "\n For nevt_trg " << nevt_trg << " the number of good associated events = " << countGoodAssociated << endl;
< 	continue;
<       }
< 
<       int takeRandomInterval = 1;
<       if(countGoodAssociated > 10)
< 	takeRandomInterval = countGoodAssociated/10 + 1 ;
< 
<       int takeAssociated = 0;
<       for(int nevt_ass=0; nevt_ass<nevttotal_ass; nevt_ass += takeRandomInterval) {
< 
<         if(nevt_trg == nevt_ass) { // check if the random trigger event matches this assocated event   
<           continue;    // go to the next associated track         
<         }
< 
< 	if(fabs((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass])>2.0){  // check if the Z vertex of the trigger and associated are separated by more than 2 cm
< 	  continue;    // go to the next associated event                                                                             
<         }
<        
< 	takeAssociated++;
< 	if(takeAssociated > 10)
< 	  break;
< 			
< 	_DeltazVertex->Fill((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass]);
< 				
< 	vector<TVector3> pVectTmp_trg = (pVectVect_trg)[nevt_trg];
< 	vector<TVector3> pVectTmp_ass = (pVectVect_ass)[nevt_ass];
< 	int nMult_trg1 = pVectTmp_trg.size();
< 	int nMult_ass1 = pVectTmp_ass.size();
< 				
< 	for(int ntrg=0; ntrg<nMult_trg1; ++ntrg) {
< 	  TVector3 pvectorTmp_trg = pVectTmp_trg[ntrg];
< 	  double eta_trg = pvectorTmp_trg.Eta();
< 	  double phi_trg = pvectorTmp_trg.Phi();
< 	  double pt_trg = pvectorTmp_trg.Pt();
< 				
< 	  for(int nass=0; nass<nMult_ass1; ++nass) {
< 						
< 	    TVector3 pvectorTmp_ass = pVectTmp_ass[nass];
< 	    double eta_ass = pvectorTmp_ass.Eta();
< 	    double phi_ass = pvectorTmp_ass.Phi();
< 						
< 	    double deltaEta = eta_ass - eta_trg;
< 	    //
< 	    // How does this code different from the standard CMS function for Delta-Phi?
< 	    //
< 	    double deltaPhi = phi_ass - phi_trg;
< 	    if(deltaPhi > M_PI) deltaPhi = deltaPhi - 2*M_PI;
< 	    if(deltaPhi < -M_PI) deltaPhi = deltaPhi + 2*M_PI;
< 	    if(deltaPhi > -M_PI && deltaPhi < -M_PI/2.0) deltaPhi = deltaPhi + 2*M_PI;
< 						
< 	    if(deltaEta == 0 && deltaPhi == 0) continue;
< 							    
< 	    if(pi0HadronCorrelations_ || etaHadronCorrelations_) {
< 
< 	      char histogramName6[200];
< 	      for(int kPt=0; kPt<bins1; kPt++) {
< 		if(pt_trg > NptBins_[kPt] && pt_trg <= NptBins_[kPt+1]) {
<     
< 		  sprintf(histogramName6, "hBackgroundPtBin%d", kPt);
< 
< 		  hBackground[histogramName6]->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hBackground[histogramName6]->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hBackground[histogramName6]->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hBackground[histogramName6]->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hBackground[histogramName6]->Fill(fabs(deltaEta),2*M_PI  - fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hBackground[histogramName6]->Fill(-fabs(deltaEta),2*M_PI - fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 
< 		  break; // no need to check the remaining pT bins
< 
< 		}  // check on pt_trg
< 
< 	      } // loop over kPt
---
>   TFile * file = new TFile("/home/sharmam/CMSSW_5_3_8_HI_patch2/src/Pi0Analysis/EcalFlowNtp/pPbRun2013/PAHighPt/pbsCrab/TrackCorrections_HIJING_538_OFFICIAL_Mar24.root","r");
>   //  edm::FileInPath fip("TrackCorrections_HIJING_538_OFFICIAL_Mar24.root");
>   //  TFile f(fip.fullPath().c_str(),"READ");
>   effhisto = (TH2F*)file->Get("rTotalEff3D");
> 
>   TFile * file1 = new TFile("/home/sharmam/CMSSW_5_3_8_HI_patch2/src/Pi0Analysis/EcalFlowNtp/pPbRun2013/PAHighPt/pbsCrab/efficiencyPi0.root","r");
>   //  edm::FileInPath fip1("efficiencyPi0.root");
>   // TFile ff(fip1.fullPath().c_str(),"READ");
>   effhisto_pi0 = (TH2D*)file1->Get("efficiencyPi0Yields");
3369,3397c1653
< 	    } // check on pi0HadronCorrelations_
< 
< 	    // Uncomment the above two line for analyzing pPb data
< 		
< 	    if(diHadronCorrelations_) {
< 	      hBackground1->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hBackground1->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hBackground1->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hBackground1->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hBackground1->Fill(fabs(deltaEta),2*M_PI- fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hBackground1->Fill(-fabs(deltaEta),2*M_PI- fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	    } // diHadronCorrelations_ check
< 		
< 	  } // loop over nass
< 
< 	} // loop over ntrg
< 
<       } // loop over nevt_ass
< 
<      if(takeAssociated < minimumTakeAssociated)
< 	minimumTakeAssociated = takeAssociated;
< 
<       totalTakeAssociated += takeAssociated;
< 			
<     } // loop over nevt_trg
< 		
<     delete [] acceptedTriggerEvents;
< 		
<   } // check for more than one trigger event, more than one associated event, and more than one event
---
> }
3399,3405c1655,1656
<   unsigned int nGenBackgroundFill = 0;
<   int totalGenTakeAssociated = 0;
<   int minimumGenTakeAssociated = 1000;
< 	
<   //
<   // Background for generated particles
<   //
---
> // ------------ method called once each job just after ending the event loop  ------------
> void EcalFlowNtp::endJob() {
3407c1658,1660
<   int nGenHistBackgroundFill[10] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
---
>   ////////////////// Calculating background for pi0-hadron correlations //////////
>   int nevttotal_trg = (int)pVectVect_trg.size();
>   int nevttotal_ass = (int)pVectVect_ass.size();
3409,3412c1662
<   nevttotal_trg = (int)pGenVectVect_trg.size();  // the trg are the pi0
<   nevttotal_ass = (int)pGenVectVect_ass.size();  // the ass are the charged particles
< 	
<   cout << "\n\n EcalFlowNTP::endJob() <I>  Generator: nevttotal_trg = " << nevttotal_trg;
---
>   cout << "\n\n EcalFlowNTP::endJob() <I>  nevttotal_trg = " << nevttotal_trg;
3413a1664
>   cout << "\n Will check the Z-vertex differences";
3415c1666,1667
< 	
---
> 
>   unsigned int nBackgroundFill = 0;
3417c1669,1689
< 		
---
> 
>     unsigned int countAcceptedTriggerEvents = 0;
>     bool *acceptedTriggerEvents = new bool [nevttotal_trg];
> 
>     // Look at Z-Vertex differences                                                                     
>     for(int nevt_trg=0; nevt_trg<nevttotal_trg; nevt_trg++) {
>       acceptedTriggerEvents[nevt_trg] = false;
>       for(int nevt_ass=0; nevt_ass<nevttotal_ass; nevt_ass++) {
> 
>         if(nevt_trg == nevt_ass)
>           continue;  // don't use the same event         
> 	if(fabs((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass])<=2.0) {
>           acceptedTriggerEvents[nevt_trg] = true;
>           countAcceptedTriggerEvents++;
>           break; // found at least one partner event with a close enough Z vertex                                      
>         }
>       } // loop over associated events              
>     } // loop over trigger events                                                                     
>     cout << "\n Number of trigger events with at least one partner event = " << countAcceptedTriggerEvents;
>     cout << endl;
> 
3419,3420c1691,1694
< 				      
<       nGenBackgroundFill++;
---
> 
>       if(!acceptedTriggerEvents[nevt_trg])
> 	continue;  // skip this trigger event which has no partner event close enough in Z 
>       nBackgroundFill++;
3423c1697
< 	
---
> 
3425,3430c1699,1701
< 				
< 	if(nevt_trg == nevt_ass) { // check if the random trigger event matches this assocated event
< 	  continue;    // go to the next associated track
< 	}
< 				
< 	countGoodAssociated++;
---
>         if(nevt_trg == nevt_ass) { // check if the random trigger event matches this assocated event   
>           continue;    // go to the next associated track         
>         }
3432c1703,1705
<       }
---
> 	if(fabs((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass])>2.0){  // check if the Z vertex of the trigger and associated are separated by more than 2 cm
>         continue;    // go to the next associated event                                                                             
>         }
3433a1707,1709
> 	countGoodAssociated++;
>       }
>       
3435,3436c1711,1712
< 	cout << "\n For nevt_trg " << nevt_trg << " the number of good associated events = " << countGoodAssociated << endl;
< 	continue;
---
>         cout << "\n For nevt_trg " << nevt_trg << " the number of good associated events = " << countGoodAssociated << endl;
>         continue;
3441,3442c1717,1718
< 	takeRandomInterval = countGoodAssociated/10 + 1 ;
< 
---
>         takeRandomInterval = countGoodAssociated/10 + 1 ;
>       
3445,3447c1721,1723
< 
<         if(nevt_trg == nevt_ass) { // check if the random trigger event matches this assocated event   
<           continue;    // go to the next associated track         
---
> 	
>         if(nevt_trg == nevt_ass) { // check if the random trigger event matches this assocated event                               
>           continue;    // go to the next associated track                                                                          
3449,3455c1725,1737
<        
< 	takeAssociated++;
< 	if(takeAssociated > 10)
< 	  break;
< 							
< 	vector<TVector3> pVectTmp_trg = (pGenVectVect_trg)[nevt_trg];
< 	vector<TVector3> pVectTmp_ass = (pGenVectVect_ass)[nevt_ass];
---
> 	
>         if(fabs((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass])>2.0){  // check if the Z vertex of the trigger and associated are separated by more than 2 cm                                                                
> 	  continue;    // go to the next associated event                                            
> 	    }
> 
>         takeAssociated++;
>         if(takeAssociated > 10)
>           break;
> 	
> 	_DeltazVertex->Fill((zvtxVect)[nevt_trg] - (zvtxVect)[nevt_ass]);
> 	
> 	vector<TVector3> pVectTmp_trg = (pVectVect_trg)[nevt_trg];
> 	vector<TVector3> pVectTmp_ass = (pVectVect_ass)[nevt_ass];
3458,3466c1740,1769
< 				
< 	for(int ntrg=0; ntrg<nMult_trg1; ++ntrg) {
< 	  TVector3 pvectorTmp_trg = pVectTmp_trg[ntrg];
< 	  double eta_trg = pvectorTmp_trg.Eta();
< 	  double phi_trg = pvectorTmp_trg.Phi();
< 	  double pt_trg = pvectorTmp_trg.Pt();
< 				
< 	  for(int nass=0; nass<nMult_ass1; ++nass) {
< 						
---
> 
> 	double nMult_trg_pi0_eff=0;
> 
> 	for(int ntrg=0; ntrg<nMult_trg1; ++ntrg)
> 	  {
> 	    TVector3 pvectorTmp_trg = pVectTmp_trg[ntrg];
> 	    double eta_trg = pvectorTmp_trg.Eta();
> 	    double pt_trg = pvectorTmp_trg.Pt();
> 
> 	    float effCorrFactor;
> 	    double effpi0;
> 
> 	    if(doEffCorrections_){
> 	      effCorrFactor = efficiencyCorrections(pt_trg);
> 	      effpi0 = effhisto_pi0->GetBinContent(effhisto_pi0->FindBin(pt_trg,eta_trg));
> 	      nMult_trg_pi0_eff = nMult_trg_pi0_eff + 1.0*effCorrFactor/effpi0;
> 	      //	      nMult_trg_pi0_eff = nMult_trg_pi0_eff + 1.0/effpi0;
> 	    }
> 	    else {
> 	      effpi0 = 1.0;
> 	      effCorrFactor = 1.0;
> 	      nMult_trg_pi0_eff = nMult_trg_pi0_eff + 1.0*effCorrFactor/effpi0;
> 	    }
> 
> 	  }
> 	
> 	double nMult_ass_ch_eff=0;
> 	for(int nass=0; nass<nMult_ass1; ++nass)
> 	  {
> 	    
3469,3482c1772
< 	    double phi_ass = pvectorTmp_ass.Phi();
< 						
< 	    double deltaEta = eta_ass - eta_trg;
< 	    //
< 	    // How does this code different from the standard CMS function for Delta-Phi?
< 	    //
< 	    double deltaPhi = phi_ass - phi_trg;
< 	    if(deltaPhi > M_PI) deltaPhi = deltaPhi - 2*M_PI;
< 	    if(deltaPhi < -M_PI) deltaPhi = deltaPhi + 2*M_PI;
< 	    if(deltaPhi > -M_PI && deltaPhi < -M_PI/2.0) deltaPhi = deltaPhi + 2*M_PI;
< 						
< 	    if(deltaEta == 0 && deltaPhi == 0) continue;				
< 	    
< 	    if(pi0HadronCorrelations_ || etaHadronCorrelations_) {
---
> 	    double pt_ass = pvectorTmp_ass.Pt();
3484,3492c1774,1776
< 	      char histogramName6[200];
< 	      for(int kPt=0; kPt<bins1; kPt++) {
< 		if(pt_trg > NptBins_[kPt] && pt_trg <= NptBins_[kPt+1]) {
< 		  
< 		  if(kPt < 10) {
< 		    nGenHistBackgroundFill[kPt]++;
< 		  }
<     
< 		  sprintf(histogramName6, "hGenBackgroundPtBin%d", kPt);
---
> 	    double effweight_ass;
> 	    if(doEffCorrections_) effweight_ass = effhisto->GetBinContent(effhisto->FindBin(eta_ass,pt_ass));
> 	    else effweight_ass = 1.0;	    
3494,3500c1778
< 		  hGenBackground[histogramName6]->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hGenBackground[histogramName6]->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hGenBackground[histogramName6]->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hGenBackground[histogramName6]->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hGenBackground[histogramName6]->Fill(fabs(deltaEta),2*M_PI  - fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		  hGenBackground[histogramName6]->Fill(-fabs(deltaEta),2*M_PI - fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 		}  // check on pt_trg
---
> 	    nMult_ass_ch_eff = nMult_ass_ch_eff + 1.0/effweight_ass;
3502c1780
< 	      } // loop over kPt
---
> 	  }
3504c1782,1839
< 	    } // check on pi0HadronCorrelations_
---
> 	for(int ntrg=0; ntrg<nMult_trg1; ++ntrg)
> 	  {
> 	    TVector3 pvectorTmp_trg = pVectTmp_trg[ntrg];
> 	    double eta_trg = pvectorTmp_trg.Eta();
> 	    double phi_trg = pvectorTmp_trg.Phi();
> 	    double pt_trg = pvectorTmp_trg.Pt();
> 
> 	    float effCorrFactor;
> 	    double effpi0;
> 
> 	    if(doEffCorrections_){
>                effCorrFactor = efficiencyCorrections(pt_trg);
>                effpi0 = effhisto_pi0->GetBinContent(effhisto_pi0->FindBin(pt_trg,eta_trg));
>             }
>             else {
>               effpi0 = 1.0;
>               effCorrFactor = 1.0;
>             }
> 	    
> 	    for(int nass=0; nass<nMult_ass1; ++nass)
> 	      {
> 		
> 		TVector3 pvectorTmp_ass = pVectTmp_ass[nass];
> 		double eta_ass = pvectorTmp_ass.Eta();
> 		double phi_ass = pvectorTmp_ass.Phi();
> 		double pt_ass = pvectorTmp_ass.Pt();
> 
> 		double effweight_ass;
> 		if(doEffCorrections_) effweight_ass = effhisto->GetBinContent(effhisto->FindBin(eta_ass,pt_ass));
> 		else effweight_ass = 1.0;
> 
> 		double deltaEta = eta_ass - eta_trg;
> 		double deltaPhi = phi_ass - phi_trg;
> 		if(deltaPhi > _pi) deltaPhi = deltaPhi - 2*_pi;
> 		if(deltaPhi < -_pi) deltaPhi = deltaPhi + 2*_pi;
> 		if(deltaPhi > -_pi && deltaPhi < -_pi/2.0) deltaPhi = deltaPhi + 2*_pi;
> 		
> 		if(deltaEta == 0 && deltaPhi == 0) continue;
> 		
> 		if(pi0HadronCorrelations_ || etaHadronCorrelations_) {
> 
> 		  char histogramName6[200];
> 		  for(int kPt=0; kPt<bins1; kPt++) {
> 		    if(pt_trg > NptBins_[kPt] && pt_trg <= NptBins_[kPt+1])
> 		      {
> 			sprintf(histogramName6, "hBackgroundPtBin%d", kPt);
> 
> 			//			hBackground[histogramName6]->Fill(deltaEta,deltaPhi,1.0/nMult_trg1/nMult_ass1);
> 			//hBackground[histogramName6]->Fill(deltaEta,2*_pi - deltaPhi,1.0/nMult_trg1/nMult_ass1);
> 			hBackground[histogramName6]->Fill(fabs(deltaEta),fabs(deltaPhi),1.0*effCorrFactor/nMult_trg_pi0_eff/effpi0/effweight_ass);
> 			hBackground[histogramName6]->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0*effCorrFactor/nMult_trg_pi0_eff/effpi0/effweight_ass);
> 			hBackground[histogramName6]->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0*effCorrFactor/nMult_trg_pi0_eff/effpi0/effweight_ass);
> 			hBackground[histogramName6]->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0*effCorrFactor/nMult_trg_pi0_eff/effpi0/effweight_ass);
> 			hBackground[histogramName6]->Fill(fabs(deltaEta),2*_pi - fabs(deltaPhi),1.0*effCorrFactor/nMult_trg_pi0_eff/effpi0/effweight_ass);
> 			hBackground[histogramName6]->Fill(-fabs(deltaEta),2*_pi - fabs(deltaPhi),1.0*effCorrFactor/nMult_trg_pi0_eff/effpi0/effweight_ass);
> 		      }
> 		  }
> 		}
3506c1841
< 	    // Uncomment the above two line for analyzing pPb data
---
> 		// Uncomment the above two line for analyzing pPb data
3508,3515c1843,1850
< 	    if(diHadronCorrelations_) {
< 	      hGenBackground1->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hGenBackground1->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hGenBackground1->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hGenBackground1->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hGenBackground1->Fill(fabs(deltaEta),2*M_PI- fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	      hGenBackground1->Fill(-fabs(deltaEta),2*M_PI- fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1);
< 	    } // diHadronCorrelations_ check
---
>        		if(diHadronCorrelations_) {
> 		  hBackground1->Fill(fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1/effweight_ass);
> 		  hBackground1->Fill(-fabs(deltaEta),fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1/effweight_ass);
> 		  hBackground1->Fill(fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1/effweight_ass);
> 		  hBackground1->Fill(-fabs(deltaEta),-fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1/effweight_ass);
> 		  hBackground1->Fill(fabs(deltaEta),2*_pi - fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1/effweight_ass);
> 		  hBackground1->Fill(-fabs(deltaEta),2*_pi - fabs(deltaPhi),1.0/nMult_trg1/nMult_ass1/effweight_ass);
> 		}
3517,3560c1852,1875
< 	  } // loop over nass
< 
< 	} // loop over ntrg
< 
<       } // loop over nevt_ass
< 
<      if(takeAssociated < minimumGenTakeAssociated)
< 	minimumGenTakeAssociated = takeAssociated;
< 
<       totalGenTakeAssociated += takeAssociated;
< 			
<     } // loop over nevt_trg
< 				
<   } // check for more than one trigger event, more than one associated event, and more than one event
< 	
< 
<   cout << endl << "--- RESULTS ---" << endl;
< 	
<   cout << "\n  Currently with pi0 mixed event entries = " << pi0MassHistMixed->GetEntries();
<   cout << ",  mixed clusters examined " << countMixedClusterExamined;
<   cout << ",  events containing at least one cluster " << totalEventsWithClusters++;
< 	
<   cout << "\n Number of hot channel seed crystals that were discarded " << hotChannelSeedsDiscarded;
<   cout << "\n Number of hot channel satellite crystals that were discarded " << hotChannelSatellitesDiscarded;
< 	
<   cout << "\n Maximum number of HI tracks for run " << runMaxTracksPerJob << " is " << maxTracksPerJob << " at event " << eventMaxTracksPerJob;
<   cout << "\n Maximum number clusters found for run " << runMaxClustersPerJob << " is "  << maxClustersPerJob  << " at event " << eventMaxClustersPerJob;
<   cout << "\n Maximum number crystals found for run " << runMaxCryPerJob << " is " << maxCryPerJob << " at event " << eventMaxCryPerJob;
<   cout << "\n Total events this run = " << totalEventsThisJob << " with accumulated events for all runs = " << totalEventsAllJobs;
<   cout << "\n Number of events with trigger particle (nevttotal_trg) = " << nevttotal_trg;
<   cout << "\n Number of events with associated particle (nevttotal_ass) = " << nevttotal_ass;
<   cout << "\n Number of background fills = " << nBackgroundFill; 
<   cout << "\n Total of takeAssociated events = " << totalTakeAssociated;
<   cout << "\n Minimum number of associated events for any trigger event = " << minimumTakeAssociated;
<   cout << "\n Number of generator background fills = " << nGenBackgroundFill; 
<   cout << "\n Total of generator takeAssociated events = " << totalGenTakeAssociated;
<   cout << "\n Minimum number of generator associated events for any trigger event = " << minimumGenTakeAssociated;
<   for(int kPt=0; kPt<bins1; kPt++) {
<     cout << "\n Number of fills for background histogram " << kPt << " = " << nGenHistBackgroundFill[kPt];
<   }
< 	
<   cout << endl;
< 	
< } // end of endJob method
---
> 	      }
> 	  }
>       }
>     }
>       
>       delete [] acceptedTriggerEvents;
>       
>     } // Check for event-mixing for more than one event. 
>     cout << endl << "--- RESULTS ---" << endl;
>     
>     cout << "\n  Currently with pi0 mixed event entries = " << pi0MassHistMixed->GetEntries();
>     cout << ",  mixed clusters examined " << countMixedClusterExamined;
>     cout << ",  events containing at least one cluster " << totalEventsWithClusters++;
>     
>     cout << "\n Maximum number of HI tracks for run " << runMaxTracksPerJob << " is " << maxTracksPerJob << " at event " << eventMaxTracksPerJob;
>     cout << "\n Maximum number clusters found for run " << runMaxClustersPerJob << " is "  << maxClustersPerJob  << " at event " << eventMaxClustersPerJob;
>     cout << "\n Maximum number crystals found for run " << runMaxCryPerJob << " is " << maxCryPerJob << " at event " << eventMaxCryPerJob;
>     cout << "\n Total events this run = " << totalEventsThisJob << " with accumulated events for all runs = " << totalEventsAllJobs;
>     cout << "\n Number of events with trigger particle (nevttotal_trg) = " << nevttotal_trg;
>     cout << "\n Number of events with associated particle (nevttotal_ass) = " << nevttotal_ass;
>     cout << "\n Number of background fills = " << nBackgroundFill;
>     cout << endl;
>   
> }
3564c1879
< 	
---
> 
3566,3567d1880
< 	
< 	
3569c1882
< 	
---
> 
3571c1884
< 	
---
> 
3575c1888
< 	
---
> 
3578c1891
< 	
---
> 
3584c1897
< 	
---
> 
3587c1900
< 	
---
> 
3590,3591c1903,1913
< 	
<   tDz_ = chTrkQA.make<TH1F>("tDz_", "Track quality variable",100, -3.0, 3.0);
---
> 
>   tPt_trg_ = chTrkQA.make<TH1F>("tPt_trg_", "p_{T} spectrum", 100, 0, 20);
>   tPt_trg_->GetXaxis()->SetTitle("p_{T} (GeV/c) of the trigger particle");
> 
>   tEta_trg_ = chTrkQA.make<TH1F>("tEta_trg_", "Pseudorapidity distribution", 50, -2.5, 2.5);
>   tEta_trg_->GetXaxis()->SetTitle("#eta distribution of the tracks");
> 
>   tPhi_trg_ = chTrkQA.make<TH1F>("tPhi_trg_", "Azimuthal distribution",100, -3.15, 3.15);
>   tPhi_trg_->GetXaxis()->SetTitle("#phi distribution of the tracks");
> 
>   tDz_ = chTrkQA.make<TH1F>("tDz_", "Track quality variable",100, -10.0, 10.0);
3593c1915
<   tDxy_ = chTrkQA.make<TH1F>("tDxy_", "Track quality variable",100, -3.0, 3.0);
---
>   tDxy_ = chTrkQA.make<TH1F>("tDxy_", "Track quality variable",100, -10.0, 10.0);
3595,3596c1917,1918
< 	
<   tPtQA_ = chTrkQA.make<TH1F>("tPtQA_", "Track quality variable",100, -0.1, 0.1);
---
> 
>   tPtQA_ = chTrkQA.make<TH1F>("tPtQA_", "Track quality variable",100, -0.5, 0.5);
3598c1920
< 	
---
> 
3601c1923
< 	
---
> 
3605c1927
< 	
---
> 
3609c1931
< 	
---
> 
3613c1935
< 	
---
> 
3617c1939
< 	
---
> 
3619,3730d1940
< 	
<   if(makeOutputTree_) {
<     cout << "\n\n  Attempt to create m_tree object " << endl;
<     m_tree = pi0Related.make<TTree>("hTree", "Pi0Eta Diagnostic Tree");
<     cout << "\n\n Return from m_tree creation attempt, with m_tree value " << m_tree <<  endl;
< 		
<     if(m_tree) { // parts of the global event information are not meaningful for data files
<       //
<       // Global event information
<       //
<       m_tree->Branch("Run",&runn,"Run/I");
<       m_tree->Branch("Event",&eventn,"Event/I");
<       m_tree->Branch("LumiSection",&ls,"LumiSection/I");
<       m_tree->Branch("xPrimaryVtx", &xPrimaryVertex, "xPrimaryVtx/F");
<       m_tree->Branch("yPrimaryVtx", &yPrimaryVertex, "yPrimaryVtx/F");
<       m_tree->Branch("rPrimaryVtx", &rPrimaryVertex, "rPrimaryVtx/F");
<       m_tree->Branch("zPrimaryVtx", &zPrimaryVertex, "zPrimaryVtx/F");
<       m_tree->Branch("nCry",&nCry,"nCry/I");
<       m_tree->Branch("nClu",&nClu,"nClu/I");
<       m_tree->Branch("nHITracks",&nHITracks,"nHITracks/I");
<       m_tree->Branch("nHighPurityTracks",&nHighPurityTracks,"nHighPurityTracks/I");
<       m_tree->Branch("nPairTracksSize", &nPairTracksSize, "nPairTracksSize/I");
<       //
<       // These parts of the global event component are not be meaningful for data files
<       //
<       m_tree->Branch("nMC",&nMC,"nMC/I");
<       m_tree->Branch("genSize",&genSize,"genSize/I");
<       m_tree->Branch("njSim",&njSim,"njSim/I");
<       m_tree->Branch("nSimTracks",&nSimTracks,"nSimTracks/I");
<       m_tree->Branch("lowestDaughterSimTrack", &lowestDaughterSimTrack, "lowestDaughterSimTrack/I");
<       m_tree->Branch("highestMatchedGenSimTrack", &highestMatchedGenSimTrack, "highestMatchedGenSimTrack/I");
<       m_tree->Branch("mergedTrackTruthSize",&mergedTrackTruthSize,"mergedTrackTruthSize/I");
<       m_tree->Branch("nMesonSize",&nMesonSize,"nMesonSize/I");
<       m_tree->Branch("nPhotonSize",&nPhotonSize,"nPhotonSize/I");
<       m_tree->Branch("nChMesonSize",&nChMesonSize,"nChMesonSize/I");
< 						
<       // crystal variables
<       if(crystalStore_) {  // all of these parts of the tree work for data files
< 	m_tree->Branch("kCry",&kCry,"kClu[nCry]/I");
< 	m_tree->Branch("eCry",&eCry,"eCry[nCry]/F");
< 	m_tree->Branch("ptCry",&ptCry,"ptCry[nCry]/F");
< 	m_tree->Branch("timeCry",&timeCry,"timeCry[nCry]/F");
< 	m_tree->Branch("flagCry",&flagCry,"flagCry[nCry]/I");
< 	m_tree->Branch("ietaCry",&ietaCry,"ietaCry[nCry]/I");
< 	m_tree->Branch("iphiCry",&iphiCry,"iphiCry[nCry]/I");
< 	m_tree->Branch("iCry",&iCry,"iCry[nCry]/I");
< 	m_tree->Branch("iSM",&iSM,"iSM[nCry]/I");
< 	m_tree->Branch("indexCluCry",&indexCluCry,"indexCluCry[nCry]/I");
< 				
< 	cout << "\n The crystal information is being stored in the hTree for this job";
< 				
<       }
<       else {
< 	cout << "\n No crystal information is being stored in the hTree for this job";
<       }
< 			
< 			
<       // basic cluster variables
<       if(clusterStore_) { // all of these parts work for data files
< 	m_tree->Branch("kClu",&kClu,"kClu[nClu]/I");
< 	m_tree->Branch("ptClu",&ptClu,"ptClu[nClu]/F");
< 	m_tree->Branch("etaClu",&etaClu,"etaClu[nClu]/F");
< 	m_tree->Branch("phiClu",&phiClu,"phiClu[nClu]/F");
< 	m_tree->Branch("nGoodRecoMatches",&nGoodRecoMatches, "nGoodRecoMatches[nClu]/I");
< 	m_tree->Branch("S4Clu",&S4Clu,"S4Clu[nClu]/F");
< 	m_tree->Branch("S9Clu",&S9Clu,"S9Clu[nClu]/F");
< 	m_tree->Branch("S25Clu",&S25Clu,"S25Clu[nClu]/F");
< 	m_tree->Branch("zClu",&zClu,"zClu[nClu]/F");
< 	m_tree->Branch("S1Clu",&S1Clu,"S1Clu[nClu]/F");
< 	m_tree->Branch("timeClu",&timeClu,"timeClu[nClu]/F");
< 	m_tree->Branch("nCryClu",&nCryClu,"nCryClu[nClu]/I");
< 	m_tree->Branch("indexCryClu",&indexCryClu,"indexCryClu[nClu][9]/I");
< 	//
< 	// Note these correspondence variables are only valid when the simTracks collection is used
< 	//
< 	m_tree->Branch("bestNoConvertSimIndexEcal",&bestNoConvertSimIndexEcal, "bestNoConvertSimIndexEcal[nClu]/I");
< 	m_tree->Branch("countNoConvertSimMatchEcal",&countNoConvertSimMatchEcal, "countNoConvertSimMatchEcal[nClu]/I");
< 	m_tree->Branch("bestNoConvertSimAngleEcal",&bestNoConvertSimAngleEcal, "bestNoConvertSimAngleEcal[nClu]/F");
< 
< 	m_tree->Branch("seedTimeClu",&seedTimeClu,"seedTimeClu[nClu]/F");
< 	m_tree->Branch("seedEnergyClu",&seedEnergyClu,"seedEnergyClu[nClu]/F");
< 	m_tree->Branch("recEnergySum",&recEnergySum,"recEnergySum[nClu]/F");
< 	m_tree->Branch("weightedTimeClu",&weightedTimeClu,"weightedTimeClu[nClu]/F");
< 	m_tree->Branch("s9WidthX",&s9WidthX,"s9WidthX[nClu]/F");
< 	m_tree->Branch("s9WidthY",&s9WidthY,"s9WidthY[nClu]/F");
< 	m_tree->Branch("s25WidthX",&s25WidthX,"s25WidthX[nClu]/F");
< 	m_tree->Branch("s25WidthY",&s25WidthY,"s25WidthY[nClu]/F");
< 		
< 	cout << "\n The basic cluster information is being stored in the hTree for this job";
<       }
<       else {
< 	cout << "\n No basic cluster information is being stored in the hTree for this job";
<       }			
< 			
<       if(clusterRecoTrackStore_) { // all of these parts work for data files
< 	m_tree->Branch("indexBestRecoMatch",&indexBestRecoMatch, "indexBestRecoMatch[nClu]/I");
< 	m_tree->Branch("valueBestAngleMatch",&valueBestAngleMatch, "valueBestAngleMatch[nClu]/F");
< 	m_tree->Branch("momentumBestTrackMatch",&momentumBestTrackMatch, "momentumBestTrackMatch[nClu]/F");
< 	m_tree->Branch("dxyVertexBestTrackMatch",&dxyVertexBestTrackMatch, "dxyVertexBestTrackMatch[nClu]/F");
< 	m_tree->Branch("dzVertexBestTrackMatch",&dzVertexBestTrackMatch, "dzVertexBestTrackMatch[nClu]/F");
< 	m_tree->Branch("sdxyVertexBestTrackMatch",&sdxyVertexBestTrackMatch, "sdxyVertexBestTrackMatch[nClu]/F");
< 	m_tree->Branch("sdzVertexBestTrackMatch",&sdzVertexBestTrackMatch, "sdzVertexBestTrackMatch[nClu]/F");
< 	m_tree->Branch("dPhiBestAngleMatch",&dPhiBestAngleMatch, "dPhiBestAngleMatch[nClu]/F");
< 	m_tree->Branch("dThetaBestAngleMatch",&dThetaBestAngleMatch, "dThetaBestAngleMatch[nClu]/F");
< 	m_tree->Branch("outerRadiusTrackMatch",&outerRadiusTrackMatch, "outerRadiusTrackMatch[nClu]/F");
< 	m_tree->Branch("outerPtTrackMatch",&outerPtTrackMatch, "outerPtTrackMatch[nClu]/F");
< 			
< 	cout << "\n The reco track-cluster information is being stored in the hTree for this job";
<       }
<       else {
< 	cout << "\n No reco track-cluster information is being stored in the hTree for this job";
<       }
3732,3737c1942,1944
<       // reconstructed tracks with only information for pairs correlations		
<       if(pairCorrTracksStore_) { // all of these parts work for data files
< 	m_tree->Branch("pairTrack",&pairTrack,"pairTrack[nPairTracksSize]/I");
< 	m_tree->Branch("recoPairPtTrack",&recoPairPtTrack,"recoPairPtTrack[nPairTracksSize]/F");
< 	m_tree->Branch("recoPairEtaTrack",&recoPairEtaTrack,"recoPairEtaTrack[nPairTracksSize]/F");
< 	m_tree->Branch("recoPairPhiTrack",&recoPairPhiTrack,"recoPairTrack[nPairTracksSize]/F");
---
>   ShowerShapeCut = pi0Related.make<TH1D>("ShowerShapeCut", "Shower-shape cut", nMassBins, 0.0, 2.0);
>   ShowerShapeCut->SetXTitle("S4/S9 ratio");
>   ShowerShapeCut->SetYTitle("# of entries");
3739,3988c1946,1948
< 	cout << "\n Only the reco tracks information for pairs correlations is being stored in the hTree for this job";
<       }
<       else {
< 	cout << "\n No reco tracks information only for pairs correlations is being stored in the hTree for this job";
<       }
< 			
<       // reconstructed tracks with all the information
<       if(recoTrackStore_) { // all of these parts work for data files
< 	m_tree->Branch("mTrack",&mTrack,"mTrack[nHITracks]/I");
< 	m_tree->Branch("recoPurityTrack",&recoPurityTrack,"recoPurityTrack[nHITracks]/I");
< 	m_tree->Branch("recoPhiDTrack",&recoPhiDTrack,"recoPhiDTrack[nHITracks]/F");
< 	m_tree->Branch("recoPtTrack",&recoPtTrack,"recoPtTrack[nHITracks]/F");
< 	m_tree->Branch("recoEtaTrack",&recoEtaTrack,"recoEtaTrack[nHITracks]/F");
< 	m_tree->Branch("recoPhiTrack",&recoPhiTrack,"recoPhiTrack[nHITracks]/F");
< 	m_tree->Branch("recoThetaTrack",&recoThetaTrack,"recoThetaTrack[nHITracks]/F");
< 	m_tree->Branch("recoVxTrack",&recoVxTrack,"recoVxTrack[nHITracks]/F");
< 	m_tree->Branch("recoVyTrack",&recoVyTrack,"recoVyTrack[nHITracks]/F");
< 	m_tree->Branch("recoVzTrack",&recoVzTrack,"recoVzTrack[nHITracks]/F");
< 	m_tree->Branch("recoDxyTrack",&recoDxyTrack,"recoDxyTrack[nHITracks]/F");
< 	m_tree->Branch("recoDzTrack",&recoDzTrack,"recoDzTrack[nHITracks]/F");
< 	m_tree->Branch("recoSdxyTrack",&recoSdxyTrack,"recoSdxyTrack[nHITracks]/F");
< 	m_tree->Branch("recoSdzTrack",&recoSdzTrack,"recoSdzTrack[nHITracks]/F");
< 	m_tree->Branch("recoOxTrack",&recoOxTrack,"recoOxTrack[nHITracks]/F");
< 	m_tree->Branch("recoOyTrack",&recoOyTrack,"recoOyTrack[nHITracks]/F");
< 	m_tree->Branch("recoOzTrack",&recoOzTrack,"recoOzTrack[nHITracks]/F");
< 	m_tree->Branch("recoChargeTrack",&recoChargeTrack,"recoChargeTrack[nHITracks]/I");
< 	m_tree->Branch("recoEcalTrack",&recoEcalTrack,"recoEcalTrack[nHITracks]/I");
< 	m_tree->Branch("recoNMatchTrack",&recoNMatchTrack,"recoNMatchTrack[nHITracks]/I");
<        				
< 	cout << "\n All the reco tracks information is being stored in the hTree for this job";				
<       }
<       else {
< 	cout << "\n No reco tracks complete information is being stored in the hTree for this job";
<       }
< 			
<       // mc truth
<       if(mcParticleStore_) { // none of these parts works for data files, and this 2010 MC collection is really obsolete in 2013
< 	m_tree->Branch( "kMC",           kMC,           "kMC[nMC]/I");
< 	m_tree->Branch( "pdgIdMC",       pdgIdMC,       "pdgIdMC[nMC]/I");
< 	m_tree->Branch( "motherIDMC",    motherIDMC,    "motherIDMC[nMC]/I");
< 	m_tree->Branch( "motherIndexMC", motherIndexMC, "motherIndexMC[nMC]/I");
< 	m_tree->Branch( "statusMC",      statusMC,      "statusMC[nMC]/I");
< 	m_tree->Branch( "ptMC",          ptMC,          "ptMC[nMC]/F");
< 	m_tree->Branch( "eMC",           eMC,           "eMC[nMC]/F");
< 	m_tree->Branch( "etaMC",         etaMC,         "etaMC[nMC]/F");
< 	m_tree->Branch( "phiMC",         phiMC,         "phiMC[nMC]/F");
< 				
< 	cout << "\n The mcParticle information is being stored in the hTree for this job";
< 				
<       }
<       else {
< 	cout << "\n No mcParticle information is being stored in the hTree for this job";
<       }
< 					
<       // simTrack information
<       if(simTrackStore_) { // none of these parts works for data files
< 	m_tree->Branch("kSim",&kSim,"kSim[nSimTracks]/I");
< 	m_tree->Branch("gMotherGenIdSim",&gMotherGenIdSim,"gMotherGenIdSim[nSimTracks]/I");
< 	m_tree->Branch("motherGenIndexSim",&motherGenIndexSim,"motherGenIndexSim[nSimTracks]/I");
< 	m_tree->Branch("motherGenIdSim",&motherGenIdSim,"motherGenIdSim[nSimTracks]/I");
< 	m_tree->Branch("pdgIdSim",&pdgIdSim,"pdgIdSim[nSimTracks]/I");
< 	if(!simSlimTrackStore_) {  // extended output for the simTrack branch
< 	  m_tree->Branch("noVertexSim",&noVertexSim,"noVertexSim[nSimTracks]/I");
< 	  m_tree->Branch("ptSim",&ptSim,"ptSim[nSimTracks]/F");
< 	  m_tree->Branch("eSim",&eSim,"eSim[nSimTracks]/F");
< 	  m_tree->Branch("etaSim",&etaSim,"etaSim[nSimTracks]/F");
< 	  m_tree->Branch("phiSim",&phiSim,"phiSim[nSimTracks]/F");
< 	  m_tree->Branch("trackIdSim",&trackIdSim,"trackIdSim[nSimTracks]/I");
< 	  m_tree->Branch("parentKSim",&parentKSim,"parentKSim[nSimTracks]/I");
< 	  m_tree->Branch("parentIdSim",&parentIdSim,"parentIdSim[nSimTracks]/I");
< 	  m_tree->Branch("parentTrackSim",&parentTrackSim,"parentTrackSim[nSimTracks]/I");
< 	  m_tree->Branch("gParentKSim",&gParentKSim,"gParentKSim[nSimTracks]/I");
< 	  m_tree->Branch("gParentIdSim",&gParentIdSim,"gParentIdSim[nSimTracks]/I");
< 	  m_tree->Branch("gParentTrackSim",&gParentTrackSim,"gParentTrackSim[nSimTracks]/I");
< 	  m_tree->Branch("nDaughtersSim",&nDaughtersSim,"nDaughtersSim[nSimTracks]/I");
< 	  m_tree->Branch("kDaughtersSim",&kDaughtersSim,"kDaughtersSim[nSimTracks][3]/I");
< 	  m_tree->Branch("rSim",&rSim,"rSim[nSimTracks]/F");
< 	  m_tree->Branch("zSim",&zSim,"zSim[nSimTracks]/F");
< 	  m_tree->Branch("genPartIndexSim",&genPartIndexSim,"genPartIndexSim[nSimTracks]/I");
< 	  //
< 	  // The genPartPdgIdSim matching algorithm has been changed (Maguire, August 2013)
< 	  //
< 	  m_tree->Branch("genPartPdgIdSim",&genPartPdgIdSim,"genPartPdgIdSim[nSimTracks]/I");
< 	  m_tree->Branch("bestAngleMatchGenSim",&bestAngleMatchGenSim,"bestAngleMatchGenSim[nSimTracks]/F");
< 	  m_tree->Branch("bestPtMatchGenSim",&bestPtMatchGenSim,"bestPtMatchGenSim[nSimTracks]/F");
< 	  m_tree->Branch("bestEtaMatchGenSim",&bestEtaMatchGenSim,"bestEtaMatchGenSim[nSimTracks]/F");
< 	  m_tree->Branch("bestPhiMatchGenSim",&bestPhiMatchGenSim,"bestPhiMatchGenSim[nSimTracks]/F");
< 	  m_tree->Branch("motherGenIndexSim",&motherGenIndexSim,"motherGenIndexSim[nSimTracks]/I");
< 	  m_tree->Branch("motherGenIdSim",&motherGenIdSim,"motherGenIdSim[nSimTracks]/I");
< 
< 	  m_tree->Branch("bestNoConvertEcalIndexSim",&bestNoConvertEcalIndexSim,"bestNoConvertEcalIndexSimSim[nSimTracks]/I");
< 	  m_tree->Branch("bestNoConvertEcalAngleSim",&bestNoConvertEcalAngleSim,"bestNoConvertEcalAngleSim[nSimTracks]/F");
< 	  m_tree->Branch("bestNoConvertEcalPtSim",&bestNoConvertEcalPtSim,"bestNoConvertEcalPtSim[nSimTracks]/F");
< 	} // check on !slimTrackStore+
< 
< 	if(simTrackStore_)
< 	  cout << "\n The full simTrack information is being stored in the hTree for this job";
< 	if(simSlimTrackStore_)
< 	  cout << "\n The slimmed simTrack information only is being stored in the hTree for this job";
< 				
<       }
<       else {
< 	cout << "\n No simTrack information is being stored in the hTree for this job";
<       }
< 			
<       // merged truth information
<       if(mergedTrackTruthStore_) { // none of these parts works for data files, and this is a new component in 2013
< 	m_tree->Branch("kMerge",&kMerge,"kMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("numberDecayVerticesMerge",&numberDecayVerticesMerge,"numberDecayVerticesMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("numberEarlyDecayMerge",&numberEarlyDecayMerge,"numberEarlyDecayMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("pdgIdMerge",&pdgIdMerge,"pdgIdMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("primaryTrackMerge",&primaryTrackMerge,"primaryTrackMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("xParentVertexMerge",&xParentVertexMerge,"xParentVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("yParentVertexMerge",&yParentVertexMerge,"yParentVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("rParentVertexMerge",&rParentVertexMerge,"rParentVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("zParentVertexMerge",&zParentVertexMerge,"zParentVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("ptMerge",&ptMerge,"ptMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("etaMerge",&etaMerge,"etaMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("phiMerge",&phiMerge,"phiMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("xDecayVertexMerge",&xDecayVertexMerge,"xDecayVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("yDecayVertexMerge",&yDecayVertexMerge,"yDecayVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("rDecayVertexMerge",&rDecayVertexMerge,"rDecayVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("zDecayVertexMerge",&zDecayVertexMerge,"zDecayVertexMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestAngleMatchMerge",&bestAngleMatchMerge,"bestAngleMatchMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestPtMatchMerge",&bestPtMatchMerge,"bestPtMatchMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestEtaMatchMerge",&bestEtaMatchMerge,"bestEtaMatchMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestPhiMatchMerge",&bestPhiMatchMerge,"bestPhiMatchMerge[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestPdgIdMatchMerge",&bestPdgIdMatchMerge,"bestPdgIdMatchMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("bestGenIndexMatchMerge",&bestGenIndexMatchMerge,"bestGenIndexMatchMerge[mergedTrackTruthSize]/I");
< 	m_tree->Branch("bestEcalIndexMatch",&bestEcalIndexMatch,"bestEcalIndexMatch[mergedTrackTruthSize]/I");
< 	m_tree->Branch("bestEcalAngleMatch",&bestEcalAngleMatch,"bestEcalAngleMatch[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestEcalSeedTimeMatch",&bestEcalSeedTimeMatch,"bestEcalSeedTimeMatch[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestEcalPhiMatch",&bestEcalPhiMatch,"bestEcalPhiMatch[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestEcalDPhiMatch",&bestEcalDPhiMatch,"bestEcalDPhiMatch[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestEcalDEtaMatch",&bestEcalDEtaMatch,"bestEcalDEtaMatch[mergedTrackTruthSize]/F");
< 	m_tree->Branch("bestEcalPtMatch",&bestEcalPtMatch,"bestEcalPtMatch[mergedTrackTruthSize]/F");
< 				
< 	cout << "\n The mergedTrackTruth information is being stored in the hTree for this job";
< 				
<       }
<       else {
< 	cout << "\n No mergedTrackTruth information is being stored in the hTree for this job";
<       }
< 			
< 			
<       // generator particle information
<       if(genParticleStore_) { // none of these parts would work for data files, and this is a 2010 component that is obsolete in 2013
< 	cout << "\n There is no genParticle information to store in the hTree";
<       }
<       else {
< 	cout << "\n No genParticle information is being stored in the hTree for this job";
<       }
<       if(chmesonStore_) { // none of these parts works for data files, and this is a new component in 2014
< 											
< 	m_tree->Branch("kChMeson",&kChMeson,"kChMeson[nChMesonSize]/I");
< 	m_tree->Branch("pdgIdChMeson",&pdgIdChMeson,"pdgIdChMeson[nChMesonSize]/I");
< 	m_tree->Branch("statusChMeson",&statusChMeson,"statusChMeson[nChMesonSize]/I");
<  	m_tree->Branch("genPartIndexChMeson",&genPartIndexChMeson,"genPartIndexChMeson[nChMesonSize]/I");
< 	m_tree->Branch("motherIdChMeson",&motherIdChMeson,"motherIdChMeson[nChMesonSize]/I"); 
< 	m_tree->Branch("ptChMeson",&ptChMeson,"ptChMeson[nChMesonSize]/F");       
< 	m_tree->Branch("etaChMeson",&etaChMeson,"etaChMeson[nChMesonSize]/F");         
< 	m_tree->Branch("phiChMeson",&phiChMeson,"phiChMeson[nChMesonSize]/F");    	
< 
< 	cout << "\n The charged particle truth information is being stored in the hTree for this job";
< 
<       } // charged meson information
<       else {
< 	cout << "\n No charged meson information is being stored in the hTree for this job";
<       }
< 			
<       // neutral meson generator and truth information
<       if(mesonStore_) { // none of these parts works for data files, and this is a new component in 2013
< 				
< 	m_tree->Branch("kMeson",&kMeson,"kMeson[nMesonSize]/I");
< 	m_tree->Branch("pdgIdMeson",&pdgIdMeson,"pdgIdMeson[nMesonSize]/I");
< 	m_tree->Branch("statusMeson",&statusMeson,"statusMeson[nMesonSize]/I");
<  	m_tree->Branch("genPartIndexMeson",&genPartIndexMeson,"genPartIndexMeson[nMesonSize]/I");
< 	m_tree->Branch("motherIdMeson",&motherIdMeson,"motherIdMeson[nMesonSize]/I"); 
< 	m_tree->Branch("ptMeson",&ptMeson,"ptMeson[nMesonSize]/F");       
< 	m_tree->Branch("etaMeson",&etaMeson,"etaMeson[nMesonSize]/F");         
< 	m_tree->Branch("phiMeson",&phiMeson,"phiMeson[nMesonSize]/F");    
< 	m_tree->Branch("daughtersFromMeson",&daughtersFromMeson,"daughtersFromMeson[nMesonSize]/I");    
< 	m_tree->Branch("pdgIdDecay1Meson",&pdgIdDecay1Meson,"pdgIdDecay1Meson[nMesonSize]/I"); 
< 	m_tree->Branch("ptDecay1Meson",&ptDecay1Meson,"ptDecay1Meson[nMesonSize]/F"); 
< 	m_tree->Branch("etaDecay1Meson",&etaDecay1Meson,"etaDecay1Meson[nMesonSize]/F"); 
< 	m_tree->Branch("phiDecay1Meson",&phiDecay1Meson,"phiDecay1Meson[nMesonSize]/F"); 
< 	m_tree->Branch("mergeDecay1Meson",&mergeDecay1Meson,"mergeDecay1Meson[nMesonSize]/I");
< 	m_tree->Branch("convertDecay1Meson",&convertDecay1Meson,"convertDecay1Meson[nMesonSize]/I"); 
< 	m_tree->Branch("mergeDecay1Angle",&mergeDecay1Angle,"mergeDecay1Angle[nMesonSize]/F");
< 	m_tree->Branch("mergeDecay1Time",&mergeDecay1Time,"mergeDecay1Time[nMesonSize]/F");
< 	m_tree->Branch("pdgIdDecay2Meson",&pdgIdDecay2Meson,"pdgIdDecay2Meson[nMesonSize]/I"); 
< 	m_tree->Branch("ptDecay2Meson",&ptDecay2Meson,"ptDecay2Meson[nMesonSize]/F"); 
< 	m_tree->Branch("etaDecay2Meson",&etaDecay2Meson,"etaDecay2Meson[nMesonSize]/F"); 
< 	m_tree->Branch("phiDecay2Meson",&phiDecay2Meson,"phiDecay2Meson[nMesonSize]/F");
< 	m_tree->Branch("mergeDecay2Meson",&mergeDecay2Meson,"mergeDecay2Meson[nMesonSize]/I");
< 	m_tree->Branch("convertDecay2Meson",&convertDecay2Meson,"convertDecay2Meson[nMesonSize]/I");
< 	m_tree->Branch("mergeDecay2Angle",&mergeDecay2Angle,"mergeDecay2Angle[nMesonSize]/F");
< 	m_tree->Branch("mergeDecay2Time",&mergeDecay2Time,"mergeDecay2Time[nMesonSize]/F");
< 	m_tree->Branch("pdgIdDecay3Meson",&pdgIdDecay3Meson,"pdgIdDecay3Meson[nMesonSize]/I"); 
< 	m_tree->Branch("ptDecay3Meson",&ptDecay3Meson,"ptDecay3Meson[nMesonSize]/F"); 
< 	m_tree->Branch("etaDecay3Meson",&etaDecay3Meson,"etaDecay3Meson[nMesonSize]/F"); 
< 	m_tree->Branch("phiDecay3Meson",&phiDecay3Meson,"phiDecay3Meson[nMesonSize]/F");
< 	m_tree->Branch("mergeDecay3Meson",&mergeDecay3Meson,"mergeDecay3Meson[nMesonSize]/I");
< 	m_tree->Branch("convertDecay3Meson",&convertDecay3Meson,"convertDecay3Meson[nMesonSize]/I");
< 	m_tree->Branch("mergeDecay3Angle",&mergeDecay3Angle,"mergeDecay3Angle[nMesonSize]/F");
< 	m_tree->Branch("massRecoMeson",&massRecoMeson,"massRecoMeson[nMesonSize]/F");
< 	m_tree->Branch("ptRecoMeson",&ptRecoMeson,"ptRecoMeson[nMesonSize]/F");
< 	m_tree->Branch("etaRecoMeson",&etaRecoMeson,"etaRecoMeson[nMesonSize]/F");
< 	m_tree->Branch("phiRecoMeson",&phiRecoMeson,"phiRecoMeson[nMesonSize]/F");
< 				
< 	cout << "\n The generator meson and reco truth information is being stored in the hTree for this job";
<       }
<       else {
< 				
< 	cout << "\n No generator meson and reco truth information is being stored in the hTree for this job";
<       }
< 			
< 			
<       // photon generator and truth information
<       if(photonStore_) { // none of these parts works for data files, and this is a new component in 2013
< 				
< 	m_tree->Branch("kPhotonGen",&kPhotonGen,"kPhotonGen[nPhotonSize]/I");
< 	m_tree->Branch("motherPdgIdPhotonGen",&motherPdgIdPhotonGen,"motherPdgIdPhotonGen[nPhotonSize]/I");
< 	m_tree->Branch("ptMotherPhotonGen",&ptMotherPhotonGen,"ptMotherPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("ptPhotonGen",&ptPhotonGen,"ptPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("etaPhotonGen",&etaPhotonGen,"etaPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("phiPhotonGen",&phiPhotonGen,"phiPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("mergeIndexPhotonGen",&mergeIndexPhotonGen,"mergeIndexPhotonGen[nPhotonSize]/I");
< 	m_tree->Branch("clusterIndexPhotonGen",&clusterIndexPhotonGen,"clusterIndexPhotonGen[nPhotonSize]/I");
< 	m_tree->Branch("convertPhotonGen",&convertPhotonGen,"convertPhotonGen[nPhotonSize]/I");
< 	m_tree->Branch("angleRecoPhotonGen",&angleRecoPhotonGen,"angleRecoPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("ptRecoPhotonGen",&ptRecoPhotonGen,"ptRecoPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("etaRecoPhotonGen",&etaRecoPhotonGen,"etaRecoPhotonGen[nPhotonSize]/F");
< 	m_tree->Branch("phiRecoPhotonGen",&phiRecoPhotonGen,"phiRecoPhotonGen[nPhotonSize]/F");
< 				
< 	cout << "\n The generator photon and reco truth information is being stored in the hTree for this job";
<       }
<       else {
< 				
< 	cout << "\n No generator photon and reco truth information is being stored in the hTree for this job";
<       }
< 			
<       cout << "\n\n Completed set up for the hTree contents (photon component is the last check)" << endl << endl;
< 			
<     }
<     else {
<       cerr  << "\n\n Unable to create m_tree object in initHistos method" << endl;
<     }
< 		
<   } // check on making an output tree
---
>   pi0MassHistSameEvent = pi0Related.make<TH1D>("pi0MassHistSameEvent", "#pi^{0} Peak in pPb Same Events", nMassBins, 0.0, maximumPi0MassForHistogram);
>   pi0MassHistSameEvent->SetXTitle("#gamma#gamma Invariant mass (GeV/c^{2})");
>   pi0MassHistSameEvent->SetYTitle(countsPerBin);
3999a1960,1970
>     sprintf(histogramName, "pi0MassSameEventPtBin%d", kPt);
>     sprintf(histogramTitle, "Same-event #pi^{0} for %5.2f < p_{T} < %5.2f ", NptBins_[kPt], NptBins_[kPt+1]);
>     pi0MassHistSameEventvsPt[histogramName] = pi0Related.make<TH1D>(histogramName, histogramTitle, nMassBins, 0.0, maximumPi0MassForHistogram);
> 
>     sprintf(histogramName2, "pi0MassMixedEventPtBin%d", kPt);
>     sprintf(histogramTitle2, "Mixed-event #pi^{0} for %5.2f < p_{T} < %5.2f ", NptBins_[kPt], NptBins_[kPt+1]);
>     pi0MassHistMixedEventvsPt[histogramName2] = pi0Related.make<TH1D>(histogramName2, histogramTitle2, nMassBins, 0.0, maximumPi0MassForHistogram);
> 
>   }
> 
>   for(int kPt=0; kPt<bins1; kPt++) {
4002a1974
> 
4004,4019c1976
< 	
<   pi0MassHistSameEvent = pi0Related.make<TH1D>("pi0MassHistSameEvent", "Photon-Pair Mass Peak in Same Events", nMassBins, 0.0, maximumPi0MassForHistogram);
<   pi0MassHistSameEvent->SetXTitle("#gamma#gamma Invariant mass (GeV/c^{2})");
<   pi0MassHistSameEvent->SetYTitle(countsPerBin);
< 	
<   for(int kPt=0; kPt<bins1; kPt++) {
<     sprintf(histogramName, "pi0MassSameEventPtBin%d", kPt);
<     sprintf(histogramTitle, "Photon-Pair Mass Peak in Same Events for %5.2f < p_{T} < %5.2f ", NptBins_[kPt], NptBins_[kPt+1]);
<     pi0MassHistSameEventvsPt[histogramName] = pi0Related.make<TH1D>(histogramName, histogramTitle, nMassBins, 0.0, maximumPi0MassForHistogram); // change bins to nMassBins
< 		
<     sprintf(histogramName2, "pi0MassMixedEventPtBin%d", kPt);
<     sprintf(histogramTitle2, "Photon-Pair Mass Peak in Mixed Events for %5.2f < p_{T} < %5.2f ", NptBins_[kPt], NptBins_[kPt+1]);
<     pi0MassHistMixedEventvsPt[histogramName2] = pi0Related.make<TH1D>(histogramName2, histogramTitle2, nMassBins, 0.0, maximumPi0MassForHistogram); // change bins to nMassBins
< 		
<   }
< 	
---
> 
4023c1980
< 	
---
> 
4026c1983
< 	
---
> 
4029c1986
< 	
---
> 
4032,4034d1988
< 	
<   TimingBefore = pi0Related.make<TH1D>("TimingBefore", "RecHit timing [ns] for all cells", 240, -60., 60.);
<   TimingBefore->SetXTitle("RecHit timing [ns]");
4036,4045c1990,2007
<   TimingBeforeEvsT = pi0Related.make<TH2D>("TimingBeforeEvsT", "Energy vs RecHit timing [ns] for all cells", 240, -60., 60., 100, 0., 5.0);
<   TimingBeforeEvsT->SetXTitle("RecHit timing [ns]");
<   TimingBeforeEvsT->SetYTitle("Energy [GeV]");
< 
<   TimingAfter = pi0Related.make<TH1D>("TimingAfter", "RecHit timing [ns] for cells in time cut", 240, -60., 60.);
<   TimingAfter->SetXTitle("RecHit timing [ns]");
< 
<   //
<   // Histogram definitions from Monika's code for EcalFlowNtp
<   //
---
>   PhotonClusterPt = pi0Related.make<TH1D>("PhotonClusterPt", "Photon cluster p_{T}", 100, 0, 100);
>   PhotonClusterPt->SetXTitle("Transverse momentum p_T (GeV/c)");
> 
>   EventsLeadPhotonPt = pi0Related.make<TH1D>("EventsLeadPhotonPt", "Leading Photon p_{T}", 100, 0, 100);
>   EventsLeadPhotonPt->SetXTitle("Transverse momentum p_T (GeV/c)");
> 
>   PFPhotonPt = pi0Related.make<TH1D>("PFPhotonPt", "PF Photon p_{T}", 100, 0, 100);
>   PFPhotonPt->SetXTitle("Transverse momentum p_T (GeV/c)");
> 
>   SwissCrossCut = pi0Related.make<TH1D>("SwissCrossCut", "Swiss cross cut", 100, 0.2, 1.2);
>   SwissCrossCut->SetXTitle("1 - E4/E1");
> 
>   Timing = pi0Related.make<TH1D>("Timing", "RecHit timing [ns]", 100, 0., 80.);
>   Timing->SetXTitle("RecHit timing [ns]");
> 
>   TimingInClustering = pi0Related.make<TH1D>("TimingInClustering", "RecHit timing in clustering [ns]", 100, 0., 80.);
>   Timing->SetXTitle("RecHit timing in clustering [ns]");
> 
4068c2030
<     hSignal[histogramName3] = pi0HadCorrFunc.make<TH2D>(histogramName3, histogramTitle3, 32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
---
>     hSignal[histogramName3] = pi0HadCorrFunc.make<TH2D>(histogramName3, histogramTitle3, 32+1,-5.0-0.15,5.0+0.15,32-1,-_pi/2+_pi/32,3*_pi/2-_pi/32);
4072,4085c2034
<     hBackground[histogramName4] = pi0HadCorrFunc.make<TH2D>(histogramName4, histogramTitle4, 32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
<   }
< 
<   hSignal1 = pi0HadCorrFunc.make<TH2D>("hSignal",";#Delta#eta;#Delta#phi",32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
<   hBackground1 = pi0HadCorrFunc.make<TH2D>("hBackground",";#Delta#eta;#Delta#phi",32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
< 
<   for(int kPt=0; kPt<bins1; kPt++) {
<     sprintf(histogramName3, "hGenSignalPtBin%d", kPt);
<     sprintf(histogramTitle3, "GEN: Same-event #pi^{0}-h 2D correlation function for %5.2f < p_{T} < %5.2f ", NptBins_[kPt], NptBins_[kPt+1]);
<     hGenSignal[histogramName3] = pi0HadCorrFunc.make<TH2D>(histogramName3, histogramTitle3, 32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
< 
<     sprintf(histogramName4, "hGenBackgroundPtBin%d", kPt);
<     sprintf(histogramTitle4, "GEN: Mixed-event #pi^{0}-h 2D Correlation runction for %5.2f < p_{T} < %5.2f ", NptBins_[kPt], NptBins_[kPt+1]);
<     hGenBackground[histogramName4] = pi0HadCorrFunc.make<TH2D>(histogramName4, histogramTitle4, 32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
---
>     hBackground[histogramName4] = pi0HadCorrFunc.make<TH2D>(histogramName4, histogramTitle4, 32+1,-5.0-0.15,5.0+0.15,32-1,-_pi/2+_pi/32,3*_pi/2-_pi/32);
4088,4089c2037,2038
<   hGenSignal1 = pi0HadCorrFunc.make<TH2D>("hGenSignal","GEN;#Delta#eta;#Delta#phi",32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
<   hGenBackground1 = pi0HadCorrFunc.make<TH2D>("hGenBackground","GEN;#Delta#eta;#Delta#phi",32+1,-5.0-0.15,5.0+0.15,32-1,-M_PI/2+M_PI/32,3*M_PI/2-M_PI/32);
---
>   hSignal1 = pi0HadCorrFunc.make<TH2D>("hSignal",";#Delta#eta;#Delta#phi",32+1,-5.0-0.15,5.0+0.15,32-1,-_pi/2+_pi/32,3*_pi/2-_pi/32);
>   hBackground1 = pi0HadCorrFunc.make<TH2D>("hBackground",";#Delta#eta;#Delta#phi",32+1,-5.0-0.15,5.0+0.15,32-1,-_pi/2+_pi/32,3*_pi/2-_pi/32);
4091c2040
< } // end of Histograms definitions
---
> }
4096c2045
< 	
---
> 
4103c2052
< 	
---
> 
4109c2058
< 	
---
>  
4115c2064
< 	
---
> 
4117,4118c2066,2067
< 	
< } // end of track quality cuts
---
> 
> }
4126c2075
< } // Vertex sorting
---
> }
4162,4165c2111,2114
< 				map<const SimTrack*, set<const SimTrack*> > const& ptokids,
< 				map<const SimTrack*, const SimVertex*> const& ptovtx,
< 				int level, bool save, int motherGenIndex) {
< 	
---
> 				  map<const SimTrack*, set<const SimTrack*> > const& ptokids,
> 				  map<const SimTrack*, const SimVertex*> const& ptovtx,
> 				  int level, bool save, int motherGenIndex) {
> 
4170,4171c2119,2120
< 	
<   // Save only Sim tracks not already in genParticle list
---
> 
>   // Save only SIM tracks not already in hiGenParticle list
4173,4180c2122,2129
<   if (save && level > 0 && nSim < nMaxSim) {
<     pdgIdSim[nSim] = p->type();
<     // statusSim[nSim] = (hasKids ? 2 : 1);
<     ptSim[nSim] = p->momentum().pt();
<     eSim[nSim] = p->momentum().energy();
<     etaSim[nSim] = p->momentum().eta();
<     phiSim[nSim] = p->momentum().phi();
<     motherGenIndexSim[nSim] = motherGenIndex;
---
>   if (save && level > 0 && nSIM < nMaxSIM) {
>     pdgIdSIM[nSIM] = p->type();
>     statusSIM[nSIM] = (hasKids ? 2 : 1);
>     ptSIM[nSIM] = p->momentum().pt();
>     eSIM[nSIM] = p->momentum().energy();
>     etaSIM[nSIM] = p->momentum().eta();
>     phiSIM[nSIM] = p->momentum().phi();
>     motherGenIndexSIM[nSIM] = motherGenIndex;
4182,4183c2131,2132
<       rSim[nSim] = ptovtx.find(p)->second->position().Rho();
<       zSim[nSim] = ptovtx.find(p)->second->position().z();
---
>       rSIM[nSIM] = ptovtx.find(p)->second->position().Rho();
>       zSIM[nSIM] = ptovtx.find(p)->second->position().z();
4186c2135
<       rSim[nSim] = zSim[nSim] = 0.;
---
>       rSIM[nSIM] = zSIM[nSIM] = 0.;
4190c2139
<     ++nSim;
---
>     ++nSIM;
4193c2142
< 	
---
> 
4196c2145
< 		
---
> 
4202c2151
< 	
---
> 
4205a2155,2172
> float EcalFlowNtp::efficiencyCorrections(double pTtrig) {
>   //This function takes the signal fraction into account for efficiency 
>   //corrections
>   const float SignalFraction[9] = {0.08, 0.24, 0.29, 0.46, 0.59, 0.68, 0.74, 0.76, 0.77};
> 
>   if(pTtrig < 1.0)  return SignalFraction[0];
>   if(pTtrig >= 1.0 && pTtrig<1.5)  return SignalFraction[1];
>   if(pTtrig >= 1.5 && pTtrig<2.0)  return SignalFraction[2];
>   if(pTtrig >= 2.0 && pTtrig<2.5)  return SignalFraction[3];
>   if(pTtrig >= 2.5 && pTtrig<3.0)  return SignalFraction[4];
>   if(pTtrig >= 3.0 && pTtrig<3.5)  return SignalFraction[5];
>   if(pTtrig >= 3.5 && pTtrig<4.0)  return SignalFraction[6];
>   if(pTtrig >= 4.0 && pTtrig<5.0)  return SignalFraction[7];
>   if(pTtrig >= 5.0)  return SignalFraction[8];
> 
>   return 0.6;
> }
> 
4207,4233c2174,2200
<   //
<   // Energy correction factors according to number of crystals in the cluster
<   // Clusters with crystal number 1 or 2 have a linear recalibration, i.e. first two numbers in crystalEnergyCorrection array are ignored
<   // Clusters with crystal number from 3 to 9 have a constant recalibration factor given by the crystalEnergyCorredtion array value
<   //
<   //  The recalibration numbers below are based on proccessing 200K MC events on August 1, 2013
<   //
<   const float crystalEnergyCorrection[9] = {0.283, 0.154, 0.0728, 0.0549, 0.0677, 0.0626, 0.0533, 0.0413, 0.0214};
< 	
<   const float singleCrystalIntercept = 0.3415;
<   const float singleCrystalSlope = -0.0927;
< 	
<   const float doubleCrystalIntercept = 0.15573;
<   const float doubleCrystalSlope = 0.015088;
< 	
<   const float secondOrderEnergyCorrection = 1.007;
< 	
<   if(indexCrystal == 0)
<     return secondOrderEnergyCorrection*(1.0 + singleCrystalIntercept + singleCrystalSlope*ecalEnergy);
< 	
<   if(indexCrystal == 1)
<     return secondOrderEnergyCorrection*(1.0 + doubleCrystalIntercept + doubleCrystalSlope*ecalEnergy);
< 	
<   if(indexCrystal > 1 && indexCrystal < 9)
<     return  secondOrderEnergyCorrection*(1.0 + crystalEnergyCorrection[indexCrystal]);
< 	
<   return 0.0; // default error value 
---
>   // Energy correction factors according to number of crystals in the cluster                                        
>   // Clusters with crystal number 1 or 2 have a linear recalibration, i.e. first two numbers in crystalEnergyCorrection array are ignored                                                                                                         
>   // Clusters with crystal number from 3 to 9 have a constant recalibration factor given by the crystalEnergyCorredtion array value    
>   //                                                                                                        
>   //  The recalibration numbers below are based on proccessing 200K MC events on August 1, 2013                       
>   //                                                                                                                        
> 
>  const float crystalEnergyCorrection[9] = {0.283, 0.154, 0.0728, 0.0549, 0.0677, 0.0626, 0.0533, 0.0413, 0.0214};
> 
>  const float singleCrystalIntercept = 0.3415;
>  const float singleCrystalSlope = -0.0927;
> 
>  const float doubleCrystalIntercept = 0.15573;
>  const float doubleCrystalSlope = 0.015088;
> 
>  const float secondOrderEnergyCorrection = 1.007;
> 
>  if(indexCrystal == 0)
>    return secondOrderEnergyCorrection*(1.0 + singleCrystalIntercept + singleCrystalSlope*ecalEnergy);
> 
>  if(indexCrystal == 1)
>    return secondOrderEnergyCorrection*(1.0 + doubleCrystalIntercept + doubleCrystalSlope*ecalEnergy);
> 
>  if(indexCrystal > 1 && indexCrystal < 9)
>    return  secondOrderEnergyCorrection*(1.0 + crystalEnergyCorrection[indexCrystal]);
> 
>  return 0.0; // default error value                                                                                                   
4238,4242c2205,2209
< 			    map<const SimTrack*, set<const SimTrack*> > & decays,
< 			    map<const SimTrack*, const SimTrack*> & parent,
< 			    map<const SimTrack*, const SimVertex*> & vertex,
< 			    int level) {
< 	
---
> 			      map<const SimTrack*, set<const SimTrack*> > & decays,
> 			      map<const SimTrack*, const SimTrack*> & parent,
> 			      map<const SimTrack*, const SimVertex*> & vertex,
> 			      int level) {
> 
4254c2221
< 		
---
> 
4263c2230
< 	
---
> 
4278c2245
< 	
---
> 
4281c2248
< 		
---
> 
4288c2255
< 		
---
> 
4293c2260
< 	
---
> 
